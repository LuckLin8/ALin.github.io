{"./":{"url":"./","title":"Introduction","keywords":"","body":"Study_Notes 日常总结的学习笔记 github：https://github.com/LuckLin8 email：linbowenwork@outlook.com 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"1.JAVA基础/JAVA容器/1.ArrayList与LinkedList.html":{"url":"1.JAVA基础/JAVA容器/1.ArrayList与LinkedList.html","title":"1.ArrayList与LinkedList","keywords":"","body":"1.1. ArrayList常见问题1.1.1. ArrayList构造器初始化了什么？数组在什么时候进行初始化？1.1.2. ArrayList是如何扩容的？1.1.3. ArrayList是线程安全的么？1.1.4. 什么情况下你会使用ArrayList？什么时候你会选择LinkedList？1.1.5. CopyOnWriteArrayList如何实现写时复制？1.1. ArrayList常见问题 1.1.1. ArrayList构造器初始化了什么？数组在什么时候进行初始化？ 无参构造器指定了一个空数组，在第一次add时，初始化10长度的数组 如果指定了初始长度，构造指定长度的空数组 1.1.2. ArrayList是如何扩容的？ ArrayList扩容后的大小等于扩容前大小的1.5倍，当ArrayList很大的时候，这样扩容还是挺浪费空间的，甚至会导致内存不足抛出OutOfMemoryError。 扩容的时候还需要对数组进行拷贝，这个也挺费时的。所以我们使用的时候要竭力避免扩容，提供一个初始估计容量参数，以免扩容对性能带来较大影响 1.1.3. ArrayList是线程安全的么？ 线程安全版本的数组容器是Vector。Vector的实现很简单，就是把所有的方法统统加上synchronized Collections.synchronizedList把一个普通ArrayList包装成一个线程安全版本的数组容器，原理同Vector是一样的，就是给所有的方法套上一层synchronized CopyOnWriteArrayList,写时复制集合，可以保障线程安全,底层采用volatile和ReentrantLock进行实现 1.1.4. 什么情况下你会使用ArrayList？什么时候你会选择LinkedList？ 频繁查询使用ArrayList，底层为数组，事件复杂度为O(1)，LinkedList时间复杂度为O(n) 频繁修改使用LinkedList，在ArrayList中增加或者删除某个元素，通常会调用System.arraycopy方法，很耗费性能 1.1.5. CopyOnWriteArrayList如何实现写时复制？ 使用全局ReentrantLock保证修改删除等操作的并发安全，volatile修饰数组，集合更新时，保证工作线程的可见性 具体细节如下： public boolean add(E e) { final ReentrantLock lock = this.lock; lock.lock(); try { Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); return true; } finally { lock.unlock(); } } 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"1.JAVA基础/JAVA容器/2.HashTable.html":{"url":"1.JAVA基础/JAVA容器/2.HashTable.html","title":"2.HashTable","keywords":"","body":"1.1. HashTable常见问题1.1.1. Hashtable的底层存储结构1.1.2. 默认的长度和加载因子1.1.3. 如何判断数组的索引1.1.4. 线程安全吗？为什么1.1.5. 如何扩容？插入元素是头插法吗？1.1.6. modCount快速失败机制1.1. HashTable常见问题 1.1.1. Hashtable的底层存储结构 数组+链表 1.1.2. 默认的长度和加载因子 hashtabel和hashmap一个不同点：hashmap数组在第一次put才进行初始化，hashtabel在构造阶段就已经进行初始化 /** * Constructs a new, empty hashtable with a default initial capacity (11) * and load factor (0.75). */ public Hashtable() { this(11, 0.75f); } 1.1.3. 如何判断数组的索引 int index = (hash & 0x7FFFFFFF) % tab.length; 与Integer的最大值进行与运算保证一定是正数 1.1.4. 线程安全吗？为什么 线程安全，所有涉及到线程安全的方法上都添加了独占锁，synchronized 1.1.5. 如何扩容？插入元素是头插法吗？ 判断当前真实容量是否大于阈值，大于阈值进行扩容，扩容为rehash()方法，将所有的节点取出，重新进行index运算，在存入新的数组，插入链表上的节点是头插法 1.1.6. modCount快速失败机制 modCount用于记录map的操作次数，在同时更改或者迭代中更改导致modCount值变化，抛出ConcurrentModificationException异常（并发修改异常） 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"1.JAVA基础/JAVA容器/3.HashMap.html":{"url":"1.JAVA基础/JAVA容器/3.HashMap.html","title":"3.HashMap","keywords":"","body":"1.1. HashMap常见问题1.1.1. HashMap的初始长度是多少？加载因子？，数组是在哪里进行初始化？1.1.2. hashmap的hash算法是什么？如何计算key的数组索引？这样有什么好处？1.1.3. jdk1.7和jdk1.8扩容迁移链表的区别？1.1.4. 查询链表的时间复杂度和红黑树查询的时间复杂度1.1.5. 多线程会出现哪些并发问题？1.1.6. 用可变类当HashMap的key有什么问题?1.1.7. 解决hash冲突的有几种方式？hashmap用的是哪种？1.1.8. 链地址法导致链表长度过深为什么不用二叉查找树而采用红黑树，为什么不一直使用红黑树？1.1. HashMap常见问题 https://mp.weixin.qq.com/s/p8gHKoLe8FyinhaRE8LfdQ 1.1.1. HashMap的初始长度是多少？加载因子？，数组是在哪里进行初始化？ public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted } public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor >> 1; n |= n >>> 2; n |= n >>> 4; n |= n >>> 8; n |= n >>> 16; return (n = MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; } hashmap无参构造器只会指定默认的加载因子为0.75 有参构造器会指定初始的加载因子0.75，以及调用tableSizeFor方法计算出比initialCapacity大的最接近的2的幂数 所以hashmap在构造阶段不会进行数组的初始化，数组的初始化在第一次put方法，默认长度为16 1.1.2. hashmap的hash算法是什么？如何计算key的数组索引？这样有什么好处？ static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16); } hash算法：高16位和低16位进行异或运算。 好处：扰动函数，让高位和地位都参与到hash运算中，减少hash碰撞的概率 计算数组索引位置：tab[i = (n - 1) & hash] 因为n的值总为2的次幂，所以(n - 1) & hash等价于取模运算，为什么不采用%运算，是因为位与运算更快 1.1.3. jdk1.7和jdk1.8扩容迁移链表的区别？ 1.7 中整个扩容过程就是一个取出数组元素（实际数组索引位置上的每个元素是每个独立单向链表的头部，也就是发生 Hash 冲突后最后放入的冲突元素）然后遍历以该元素为头的单向链表元素，依据每个被遍历元素的 hash 值计算其在新数组中的下标然后进行交换（即原来 hash 冲突的单向链表尾部变成了扩容后单向链表的头部） jdk1.8中由于扩容数组的长度是 2 倍关系，所以对于假设初始 tableSize = 4 要扩容到 8 来说就是 0100 到 1000 的变化（左移一位就是 2 倍），在扩容中只用(e.hash & oldCap) == 0，0 的话索引就不变，1 的话索引变成原索引加上扩容前数组。jdk1.8不会出现链表倒置 1.1.4. 查询链表的时间复杂度和红黑树查询的时间复杂度 若为树，则在树中通过key.equals(k)查找，O(logn)； 若为链表，则在链表中通过key.equals(k)查找，O(n)。 1.1.5. 多线程会出现哪些并发问题？ jdk1.7多线程扩容时，可能会阐释循环链表，在执行get的时候会触发死循环 jdk1.8 size属性并没有保证可见性和原子性，所以size值不准确 在put过程中，如果一个线程获取到链表的插入节点，另一个线程先进行插入，会造成数据的覆盖，导致数据丢失 1.1.6. 用可变类当HashMap的key有什么问题? hashcode可能发生改变，导致put进去的值，无法get出 1.1.7. 解决hash冲突的有几种方式？hashmap用的是哪种？ - 开放地址法 - 二次hash法 - 链地址法 - 建立公共溢出区 1.1.8. 链地址法导致链表长度过深为什么不用二叉查找树而采用红黑树，为什么不一直使用红黑树？ 二叉查找树在特定情况下会变成一条线性结构，降低性能。红黑树插入新数据有可能需要左旋右旋，在长度小于8的时候所需资源大于链表 二叉平衡树为了保证绝对的平衡，在插入数据时会耗费较多的时间，而红黑树是相对平衡插入的性能较好，而二者的查找时间复杂度都为O(logn) 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"1.JAVA基础/JAVA容器/4.ConcurrentHashMap.html":{"url":"1.JAVA基础/JAVA容器/4.ConcurrentHashMap.html","title":"4.ConcurrentHashMap","keywords":"","body":"1.1. ConcurrentHashMap常见问题1.1.1. 并发度1.7和1.8的区别1.1.2. 构造方法和HashMap有什么不同？1.1.3. hash算法和HashMap有什么不同？1.1.4. ConcurrentHashMap转换树和HashMap有什么区别?1.1.5. 分析一下，ConcurrentHashMap如何进行初始化数组1.1.6. 请对put()方法进行整体分析1.1.7. ConcurrentHashMap的size如何统计？如果是你会如何设计？1.1. ConcurrentHashMap常见问题 1.1.1. 并发度1.7和1.8的区别 Java 7 中，每个 Segment 独立加锁，最大并发个数就是 Segment 的个数，默认是 16。 但是到了 Java 8 中，锁粒度更细，理想情况下 table 数组元素的个数（也就是数组长度）就是其支持并发的最大个数，并发度比之前有提高。 1.1.2. 构造方法和HashMap有什么不同？ 无参构造器什么都不进行初始化 public ConcurrentHashMap() {} 初始容量的构造器调用tableSizeFor()的传参发生变化，传参为：initialCapacity + (initialCapacity >>> 1) + 1假设传参为32，初始容量为64 public ConcurrentHashMap(int initialCapacity) int cap = ((initialCapacity >= (MAXIMUM_CAPACITY >>> 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1)); public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) int cap = (size >= (long)MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)size); 添加了一个重要参数sizeCtl，默认为0，用来控制table的初始化和扩容操作 -1 代表table正在初始化,其他线程应该交出CPU时间片 -N 取-N对应的二进制的低16位数值为M，此时有M-1个线程进行扩容。 大于0且table未初始化，则表示table需要初始化的大小。 大于0且table已经初始化，表示table下次扩容的阈值 1.1.3. hash算法和HashMap有什么不同？ ```java static final int HASH_BITS = 0x7fffffff; int hash = spread(key.hashCode()); static final int spread(int h) { return (h ^ (h >>> 16)) & HASH_BITS; } ``` 同样是扰动函数，高16位与低16位进行异或运算，降低产生hash冲突的概率，不同点在于扰动运算后又与0x7fffffff进行了与运算。 0x7fffffff 为Integer的最大值，二进制为0111111......，进行与运算得出的值只会是正数 1.1.4. ConcurrentHashMap转换树和HashMap有什么区别? HashMap 如果链表长度大于8就会转换为红黑树 ConcurrentHashMap 链表大于8不会立刻转换红黑树，(if ((n = tab.length) 1.1.5. 分析一下，ConcurrentHashMap如何进行初始化数组 第一次的put的时候，进行table为空判断，为空进行初始化 sizeCtl 如果没有别的线程在进行初始化，则对sizeCtl进行cas修改为-1 //else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) cas成功后，进行数组的初始化，sc 为 cas前的sizeCtl值，为0表示没有初始容量，使用DEFAULT_CAPACITY = 10 初始化完成计算下次扩容的阈值 sc = n - (n >>> 2); 当前容量为n 则值为0.75n private final Node[] initTable() { Node[] tab; int sc; while ((tab = table) == null || tab.length == 0) { if ((sc = sizeCtl) 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(\"unchecked\") Node[] nt = (Node[])new Node[n]; table = tab = nt; sc = n - (n >>> 2); } } finally { sizeCtl = sc; } break; } } return tab; } 1.1.6. 请对put()方法进行整体分析 if (tab == null || (n = tab.length) == 0) tab = initTable(); 判断是否进行初始化 else if ((f = tabAt(tab, i = (n - 1) & hash)) == null)判断对应的桶是否为null,为null直接进行cas操作修改对应的值,多线程并发下，cas结果为false，重新循环插入链表 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f);如果对应桶的Node节点的hash值为 MOVED(-1)，说明有别的线程正在进行扩容，调用helpTransfer进行协同扩容 添加链表或红黑树的节点，使用独占锁synchronized (f)，这样相当于只锁住了一个桶，没有干扰到别的桶的正常操作 最后调用addCount()用于统计map的总数量 /** Implementation for put and putIfAbsent */ final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node[] tab = table;;) { Node f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) { if (casTabAt(tab, i, null, new Node(hash, key, value, null))) break; // no lock when adding to empty bin } else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else { V oldVal = null; synchronized (f) { if (tabAt(tab, i) == f) { if (fh >= 0) { binCount = 1; for (Node e = f;; ++binCount) { K ek; if (e.hash == hash && ((ek = e.key) == key || (ek != null && key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } Node pred = e; if ((e = e.next) == null) { pred.next = new Node(hash, key, value, null); break; } } } else if (f instanceof TreeBin) { Node p; binCount = 2; if ((p = ((TreeBin)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } } } if (binCount != 0) { if (binCount >= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } addCount(1L, binCount); return null; } 1.1.7. ConcurrentHashMap的size如何统计？如果是你会如何设计？ public int size() { long n = sumCount(); return ((n (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n); // 将 n 裁剪到 [0, Integer.MAX_VALUE] 内 } // 计算 baseCount 字段与所有 counterCells 数组的非空元素的和 final long sumCount() { CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) { for (int i = 0; i map中键值对的个数通过求 baseCount 与 counterCells 非空元素的value属性的和得到 ConcurrentHashMap 内部所有改变键值对个数的方法都会调用 addCount 方法更新键值对的变化 // 参数 x 表示键值对个数的变化值，如果为正，表示新增了元素，如果为负，表示删除了元素 private final void addCount(long x, int check) { CounterCell[] as; long b, s; // 如果 counterCells 为空，则直接尝试通过 CAS 将 x 累加到 baseCount 中 if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) { // counterCells 非空 // 或 counterCells 为空，但 CAS baseCount 失败都会来到这里 CounterCell a; long v; int m; boolean uncontended = true; // CAS 数组元素时，有没有发生线程争用的标志 // 如果当前线程探针哈希到的数组元素非空，则尝试将 x 累加到对应数组元素 if (as == null || (m = as.length - 1) = 0，则判断当前的 size 是否会触发扩容 if (check >= 0) { // 扩容相关的逻辑 Node[] tab, nt; int n, sc; while (s >= (long)(sc = sizeCtl) && (tab = table) != null && (n = tab.length) >> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex counterCells 数组未初始化 a. CAS 一次 baseCount b. 如果 CAS 失败，则调用 fullAddCount 方法 counterCells 数组已初始化 a. CAS 一次当前线程探针哈希到的数组元素 b. 如果 CAS 失败，则调用 fullAddCount 方法 // 只被 addCount 方法调用 // 如果 counterCells 数组未初始化 // 或者线程哈希到的 counterCells 数组元素未初始化 // 或者 CAS 数组元素失败，都会调用此方法 private final void fullAddCount(long x, boolean wasUncontended) { int h; // 判断线程探针哈希值是否初始化 if ((h = ThreadLocalRandom.getProbe()) == 0) { ThreadLocalRandom.localInit(); // force initialization h = ThreadLocalRandom.getProbe(); wasUncontended = true; // 重新假设未发生争用 } boolean collide = false; // 是否要给 counterCells 扩容的标志 for (;;) { CounterCell[] as; CounterCell a; int n; long v; if ((as = counterCells) != null && (n = as.length) > 0) { // 数组不为空且长度大于 0 if ((a = as[(n - 1) & h]) == null) { // 尝试初始化线程探针哈希到的数组元素 if (cellsBusy == 0) { // Try to attach new Cell // 注意，这里已经把 x 放入对象 CounterCell r = new CounterCell(x); // Optimistic create if (cellsBusy == 0 && // 准备初始化数组元素，要求 cellsBusy 为 0，并尝试将其置 1 U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) { // 获得 cellsBusy 锁 boolean created = false; try { // Recheck under lock CounterCell[] rs; int m, j; // 判断有没有被其它线程初始化 if ((rs = counterCells) != null && (m = rs.length) > 0 && rs[j = (m - 1) & h] == null) { rs[j] = r; created = true; } } finally { cellsBusy = 0; // 释放 cellsBusy 锁 } if (created) // 初始化元素成功，直接退出循环 break; continue; // Slot is now non-empty } } collide = false; } else if (!wasUncontended) // CAS already known to fail wasUncontended = true; // Continue after rehash（指的是更改当前线程的探针哈希值） // wasUncontended 为 true 执行到这 // 尝试将 x 累加进数组元素 else if (U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x)) break; // CAS 失败 // 判断 counterCells 是否正在扩容，或数组长度是否大于等于处理器数 else if (counterCells != as || n >= NCPU) collide = false; // At max size or stale // 如果数组没有在扩容，且数组长度小于处理器数 // 此时，如果 collide 为 false，则把它变成 true // 在下一轮循环中，如果 CAS 数组元素继续失败，就会触发 counterCells 扩容 else if (!collide) collide = true; // 如果 collide 为 true，则尝试给 counterCells 数组扩容 else if (cellsBusy == 0 && U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) { try { if (counterCells == as) {// Expand table unless stale CounterCell[] rs = new CounterCell[n fullAddCount的作用： 线程探针哈希值的初始化。 counterCells 数组的初始化和扩容。 counterCells 元素的初始化。 将 size 的变化，写入 counterCells 中的某一个元素。(如果 counterCells 初始化时，获取锁失败，则还会尝试将 size 的变化，写入 baseCount。) size的计算思想： 尽量降低线程冲突，以最快的速度写入 size 的变化。 如何降低CounterCell数组的冲突？ 如果没有冲突发生，只将 size 的变化写入 baseCount。一旦发生冲突，就用一个数组（counterCells）来存储后续所有 size 的变化。 线程只要对任意一个数组元素写入 size 变化成功即可，数组长度越长，线程发生冲突的可能性就越小。 关于 counterCells 扩容： 如果 CAS 数组元素连续失败两次，就会进行 counterCells 数组的扩容，直到达到机器的处理器数为止。 比如双核四线程，真正并行的线程数是4，counterCells 初始化后，最多扩容一次。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"1.JAVA基础/JVM/1.深入理解JVM.html":{"url":"1.JAVA基础/JVM/1.深入理解JVM.html","title":"1.深入理解JVM","keywords":"","body":"1.1. JVM模型1.1.1. 程序计数器1.1.2. Java虚拟机栈1.1.3. 本地方法栈1.1.4. java堆1.1.5. 方法区1.1.6. 运行时常量池1.1.7. 直接内存1.2. 对象的创建1.2.1. 分配对象内存的两种方式1.2.2. 对象的分配内存如何保证线程安全？1.2.3. 对象的内存布局1.3. 如何判断对象是否需要回收？1.3.1. 引用计数法1.3.2. 可达性分析（JVM采用）1.3.3. 四大引用类型1.1. JVM模型 1.1.1. 程序计数器 程序计数器占用内存很小，线程私有，用于记录当前线程所执行的字节码行号。 如果线程正在执行一个java方法，那么程序计数器记录的是正在执行的虚拟机字节码指令的地址 如果执行的是native方法，则计数器值为null 程序计数器内存区域不会出现OOM 1.1.2. Java虚拟机栈 线程私有的，生命周期和线程相同，每个方法执行的时候，都会同步创建一个栈帧，用于存储局部变量表、操作数栈、动态连接、方法出口等信息 局部变量表存放了基本数据类型（boolean、byte、char、short、int、 float、long、double）、对象引用（reference类型，它并不等同于对象本身，可能是一个指向对象起始 地址的引用指针，也可能是指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress 类型（指向了一条字节码指令的地址）。 这些数据类型在局部变量表中的存储空间以局部变量槽（Slot）来表示，其中64位长度的long和 double类型的数据会占用两个变量槽，其余的数据类型只占用一个。 对这个内存区域规定了两类异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果Java虚拟机栈容量可以动态扩展，当栈扩 展时无法申请到足够的内存会抛出OutOfMemoryError异常。 HotSpot虚拟机的栈容量是不可以动态扩展的，以前的Classic虚拟机倒是可以。所以在HotSpot虚拟机上是不会由于虚拟机栈无法扩展而导致OutOfMemoryError异常——只要线程申请栈空间成功了就不会有OOM，但是如果申请时就失败，仍然是会出现OOM异常的，后面的实战中笔者也演示了这种情况。 1.1.3. 本地方法栈 线程私有，底层C++方法 本地方法栈则是为虚拟机使用到的本地（Native） 方法服务 与虚拟机栈一样，本地方法栈也会在栈深度溢出或者栈扩展失败时分别抛出StackOverflowError和OutOfMemoryError异常。 1.1.4. java堆 线程共有，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，所有的对象实例以及数组都应当在堆上分配 经典分代：新生代、老年代、永久代、Eden、Survivor 以G1收集器的出现为分界，HotSpot里面也出现了不采用分代设计的新垃圾收集器，不采用经典分代进行区分 Java堆既可以被实现成固定大小的，也可以是可扩展的，不过当前主流的Java虚拟机都是按照可扩展来实现的（通过参数-Xmx和-Xms设定）。如果在Java堆中没有内存完成实例分配，并且堆也无法再扩展时，Java虚拟机将会抛出OutOfMemoryError异常 1.1.5. 方法区 线程共有，它用于存储已被虚拟机加载 的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据 jdk6采用永久代来实现方法区，方法区描述为堆的一个逻辑部分，但是它却有一个别名叫作“非堆”（Non-Heap），目的是与Java堆区分开来。 jdk7将原本放在永久代的字符串常量池、静态变量等移出，逐步改为采用本地内存（Native Memory）来实现方法区 jdk8废除永久代，使用元空间（Meta-space）进行替代 如果方法区无法满足新的内存分配需求时，将抛出 OutOfMemoryError异常 1.1.6. 运行时常量池 运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件中除了有类的版本、字 段、方法、接口等描述信息外，还有一项信息是常量池表（Constant Pool Table），用于存放编译期生 成的各种字面量与符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。 运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出OutOfMemoryError异常。 1.1.7. 直接内存 直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是《Java虚拟机规范》中定义的内存区域。但是这部分内存也被频繁地使用，而且也可能导致OutOfMemoryError异常出现，所 以我们放到这里一起讲解。 一般服务 器管理员配置虚拟机参数时，会根据实际内存去设置-Xmx等参数信息，但经常忽略掉直接内存，使得各个内存区域总和大于物理内存限制（包括物理的和操作系统级的限制），从而导致动态扩展时出现 OutOfMemoryError异常 在JDK 1.4中新加入了NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的 DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了 在Java堆和Native堆中来回复制数据。 1.2. 对象的创建 1.2.1. 分配对象内存的两种方式 指针碰撞 假设Java堆中内存是绝对规整的，所有被使用过的内存都被放在一 边，空闲的内存被放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那 个指针向空闲空间方向挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞”（Bump The Pointer） 空闲列表 但如果Java堆中的内存并不是规整的，已被使用的内存和空闲的内存相互交错在一起，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分 配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称 为“空闲列表”（Free List） 选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用 的垃圾收集器是否带有空间压缩整理（Compact）的能力决定。因此，当使用Serial、ParNew等带压缩 整理过程的收集器时，系统采用的分配算法是指针碰撞，既简单又高效；而当使用CMS这种基于清除（Sweep）算法的收集器时，理论上就只能采用较为复杂的空闲列表来分配内存 1.2.2. 对象的分配内存如何保证线程安全？ 采用CAS加失败重试机制保证原子性，自旋锁 TLAB另外一种是把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲（Thread Local Allocation Buffer，TLAB），哪个线程要分配内存，就在哪个线程的本地缓冲区中分配，只有本地缓冲区用完了，分配新的缓存区时才需要同步锁定。虚拟机是否使用TLAB，可以通过-XX：+/-UseTLAB参数来设定。 1.2.3. 对象的内存布局 在HotSpot虚拟机里，对象在堆内存中的存储布局可以划分为三个部分：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。 1.3. 如何判断对象是否需要回收？ 1.3.1. 引用计数法 在对象中添加一个引用计数器，每当有一个地方 引用它时，计数器值就加一；当引用失效时，计数器值就减一；任何时刻计数器为零的对象就是不可 能再被使用的。 缺点：互相引用无法回收 1.3.2. 可达性分析（JVM采用） 通过一系列称为“GC Roots”的根对象作为起始节点集，从这些节点开始，根据引用关系向下搜索，搜索过程所走过的路径称为“引用链”（Reference Chain），如果某个对象到GC Roots间没有任何引用链相连， 或者用图论的话来说就是从GC Roots到这个对象不可达时，则证明此对象是不可能再被使用的。 GC ROOT对象 在虚拟机栈（栈帧中的本地变量表）中引用的对象，譬如各个线程被调用的方法堆栈中使用到的 参数、局部变量、临时变量等。 在方法区中类静态属性引用的对象，譬如Java类的引用类型静态变量。 在方法区中常量引用的对象，譬如字符串常量池（String Table）里的引用。 在本地方法栈中JNI（即通常所说的Native方法）引用的对象。 Java虚拟机内部的引用，如基本数据类型对应的Class对象，一些常驻的异常对象（比如 NullPointExcepiton、OutOfMemoryError）等，还有系统类加载器。 所有被同步锁（synchronized关键字）持有的对象。 反映Java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等。 1.3.3. 四大引用类型 强引用 Reference 当内存不足，JVM开始垃圾回收，对于强引用对象，就算出现了OOM也不会堆该对象进行回收。 强引用是我们最常见的普通对象引用，只要还有强引用指向一个对象，就能表面对象还“或者”，垃圾收集器不会碰这种对象。在Java中最常见的就是强引用，把一个对象赋给一个引用变量，这个引用变量就是一个强引用。当一个对象被强引用变量引用时，它处于可达状态，他是不可能被垃圾回收机制回收的，既是该对象以后永远都不会被用到 JVM也不会回收。因此强引用时造成java内存泄漏的主要原因之一。 对于一个普通对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式的将应用（强）引用复制为null，一般认为就是可以被垃圾收集的了 软引用 SoftReference 软引用是一种相对强引用弱化了一些作用，需要用java.lang.ref.SOftReference类来实现，可以让对象豁免一些垃圾收集。 当系统内存充足时他不会被回收，当内存不足时会被回收。 软引用通常在对内存敏感的程序中，比如高速缓存就有用到软引用，内存足够的时候就保留，不够就回收。 弱引用 WeakReference 弱引用需要用java.lang.ref.WeakReference类来实现，比软引用的生存期更短 只要垃圾回收机制一运行，不管JVM的内存空间是否足够，都会回收。 谈谈WeakHashMap key是弱引用 虚引用PhantomReference 顾名思义，就是形同虚设，与其他集中不同，虚引用并不会决定对象的生命周期 如果一个对象持有虚引用，那么他就和没有任何引用一样，在任何时候都可能被垃圾回收器回收，他不能单独使用也不能通过它访问对象，虚引用和引用队列（ReferenceQueeu)联合使用。 需应用的主要作用是跟踪对象被垃圾回收的状态。仅仅是提供了一种确保ui想被finalize以后，做某些事情的机制。 PhantomReference的get方法总是返回null，因此无法访问对应的引用对象。其意义在于说明一个对象已经进入finalization阶段，可以被gc回收，用来实现比finalization机制更灵活的回收操作 换句话说，设置虚引用关联的唯一目的，就是这个对象被收集器回收的时候收到一个系统通知或者后续添加进一步的处理。 java允许使用finalize()方法在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"1.JAVA基础/JVM/2.JVM常见问题.html":{"url":"1.JAVA基础/JVM/2.JVM常见问题.html","title":"2.JVM常见问题","keywords":"","body":"1.1. 一、Part 11.1.1. JVM垃圾回收的时候如何确定垃圾？是否知道什么是GC Roots1.1.2. 如何盘点查看JVM系统默认值1.1.3. 你平时工作用过的JVM常用基本配置参数有哪些1.1.4. 强引用、软引用、弱引用、虚引用作用分别是什么1.1.5. 请你谈谈对OOM的认识1.1.6. GC垃圾回收算法和垃圾收集器的关系？分别是什么1.1.7. 怎么查看服务器默认的垃圾收集器是哪个？生产上如何配置垃圾收集器？对垃圾收集器的理解？1.1.8. 垃圾收集器1.1.9. G1垃圾收集器1.1.10. 生产环境服务器变慢，诊断思路和性能评估谈谈？1.1.11. 加入生产环境CPU占用过高，谈谈分析思路和定位？1.1. 一、Part 1 1.1.1. JVM垃圾回收的时候如何确定垃圾？是否知道什么是GC Roots 什么是垃圾？ 内存中已经不再使用到的空间就是垃圾 要进行垃圾回收，如何判断一个对象是否可以被回收 引用计数法：java中，引用和对象是由关联的。如果要操作对象则必须用引用进行。 因此很显然一个简单的办法是通过引用计数来判断一个对象是否可以回收，简单说，给对象中添加一个引用计数器，每当有一个地方引用它，计数器加1，每当有一个引用失效时，计数器减1，任何时刻计数器数值为零的对象就是不可能再被使用的，那么这个对象就是可回收对象。 但是它很难解决对象之间相互循环引用的问题 JVM一般不采用这种实现方式。 ==枚举根节点做可达性分析（跟搜索路径）==： 为了解决引用计数法的循环引用问题，java使用了可达性分析的方法。 所谓GC ROOT或者说Tracing GC的“根集合”就是一组比较活跃的引用。 基本思路就是通过一系列“GC Roots”的对象作为起始点，从这个被称为GC Roots 的对象开始向下搜索，如果一个对象到GC Roots没有任何引用链相连时，则说明此对象不可用。也即给定一个集合的引用作为根出发，通过引用关系遍历对象图，能被便利到的对象就被判定为存活；没有被便利到的就被判定为死亡 （1）哪些对象可以作为GC Roots对象 虚拟机栈（栈帧中的局部变量区，也叫局部变量表）中应用的对象。 方法区中的类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI（native方法）引用的对象 1.1.2. 如何盘点查看JVM系统默认值 如何查看运行中程序的JVM信息 jps查看进程信息 jinfo -flag 配置项 进程号 jinfo -flags 进程号 ==== 查看所有配置 （1）JVM参数类型 标配参 -version -help 各个版本之间稳定，很少有很大的变化 x参数 -Xint -Xcomp -Xmixed -Xint :解释执行 -Xcomp：第一次使用就编译成本地代码 -Xmixed：混合模式 ==xx参数== Boolean类型 公式：-XX+或者-某个属性值 +表示开启，-表示关闭 是否打印GC收集细节 -XX:+PrintGCDetails 开启 -XX:-PrintGCDetails 关闭 是否使用串行垃圾回收器：-XX:-UseSerialGC KV设值类型 公式：-XX:属性key=属性值value case： -XX:MetaspaceSize=128m -XX:MaxTenuringThreshold=15 -Xms----> -XX:InitialHeapSize -Xmx----> -XX:MaxHeapSize （2）查看参数 -XX:+PrintFlagsInitial 查看初始默认 ==java -XX:+PrintFlagsInitial -version== -XX:+PrintFlagsFinal 查看修改后的 :=说明是修改过的 -XX:+PrintCommandLineFlags 查看使用的垃圾回收器 1.1.3. 你平时工作用过的JVM常用基本配置参数有哪些 -Xms -Xmx -Xmn -Xms128m -Xmx4096m -Xss1024K -XX:MetaspaceSize=512m -XX:+PrintCommandLineFlags -XX:+PrintGCDetails -XX:+UseSerialGC -Xms 初始大小内存，默认为物理内存1/64，等价于-XX:InitialHeapSize -Xmx 最大分配内存，默认物理内存1/4，等价于-XX:MaxHeapSize -Xss 设置单个线程栈的大小，默认542K~1024K ，等价于-XX:ThreadStackSize -Xmn 设置年轻代的大小 -XX:MetaspaceSize 设置元空间大小 元空间的本质和永久代类似，都是对JVM规范中方法区的实现，不过元空间与永久代最大的区别在于：==元空间并不在虚拟机中，而是在本地内存中。==因此，默认元空间的大小仅受本地内存限制 -XX:+PrintGCDetails 输出详细GC收集日志信息 [名称：GC前内存占用->GC后内存占用(该区内存总大小)] -XX:SurvivorRatio 设置新生代中Eden和S0/S1空间的比例 默认-XX:SurvivorRatio=8,Eden:S0:S1=8:1:1 -XX:NewRatio 设置年轻代与老年代在堆结构的占比 默认-XX:NewRatio=2 新生代在1，老年代2，年轻代占整个堆的1/3 NewRatio值几句诗设置老年代的占比，剩下的1给新生代 -XX:MaxTenuringThreshold 设置垃圾的最大年龄 默认-XX:MaxTenuringThreshold=15 如果设置为0，年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大的值，则年轻代对象回在Survivor区进行多次复制，这样可以增加对对象在年轻代的存活时间，增加在年轻代即被回收的概率。 -XX:+UseSerialGC 串行垃圾回收器 -XX:+UseParallelGC 并行垃圾回收器 1.1.4. 强引用、软引用、弱引用、虚引用作用分别是什么 4.1 强引用 Reference 当内存不足，JVM开始垃圾回收，对于强引用对象，就算出现了OOM也不会堆该对象进行回收。 强引用是我们最常见的普通对象引用，只要还有强引用指向一个对象，就能表面对象还“或者”，垃圾收集器不会碰这种对象。在Java中最常见的就是强引用，把一个对象赋给一个引用变量，这个引用变量就是一个强引用。当一个对象被强引用变量引用时，它处于可达状态，他是不可能被垃圾回收机制回收的，既是该对象以后永远都不会被用到 JVM也不会回收。因此强引用时造成java内存泄漏的主要原因之一。 对于一个普通对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式的将应用（强）引用复制为null，一般认为就是可以被垃圾收集的了 4.2 软引用 SoftReference 软引用是一种相对强引用弱化了一些作用，需要用java.lang.ref.SOftReference类来实现，可以让对象豁免一些垃圾收集。 当系统内存充足时他不会被回收，当内存不足时会被回收。 软引用通常在对内存敏感的程序中，比如高速缓存就有用到软引用，内存足够的时候就保留，不够就回收。 4.3 弱引用 WeakReference 弱引用需要用java.lang.ref.WeakReference类来实现，比软引用的生存期更短 只要垃圾回收机制一运行，不管JVM的内存空间是否足够，都会回收。 谈谈WeakHashMap key是弱引用 4.4 虚引用PhantomReference 顾名思义，就是形同虚设，与其他集中不同，虚引用并不会决定对象的生命周期 如果一个对象持有虚引用，那么他就和没有任何引用一样，在任何时候都可能被垃圾回收器回收，他不能单独使用也不能通过它访问对象，虚引用和引用队列（ReferenceQueeu)联合使用。 需应用的主要作用是跟踪对象被垃圾回收的状态。仅仅是提供了一种确保ui想被finalize以后，做某些事情的机制。 PhantomReference的get方法总是返回null，因此无法访问对应的引用对象。其意义在于说明一个对象已经进入finalization阶段，可以被gc回收，用来实现比finalization机制更灵活的回收操作 换句话说，设置虚引用关联的唯一目的，就是这个对象被收集器回收的时候收到一个系统通知或者后续添加进一步的处理。 java允许使用finalize()方法在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。 4.4.1 引用队列Reference 创建引用的时候可以指定关联的队列，当gc释放对象内存的时候，会把引用加入到引用队列，如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动，相当于通知机制 当关联的引用队列中有数据的时候，意味着引用指向的对内存中的对象被回收。通过这种方式，jvm允许我们在对象被小回收，做一些我们自己想做的事情。 4.5 适用场景 加入一个应用需要读取大量的本地图片，如果每次读取图片都从硬盘读取会严重影响性能，如果一次性全部加载到内存又可能造成内存溢出，这时可以用软引用解决这个问题 设计思路：用一个HashMap来保存图片路径和相应图片对象关联的软引用之间的映射关系，在内存不足时，JVM会自动共回收这些缓存图片对象所占的空间，避免OOM Map> imageCache = new HashMap<>(); 1.1.5. 请你谈谈对OOM的认识 java.lang.StackOverflowError 栈空间溢出 ，递归调用卡死 java.lang.OutOfMemoryError:Java heap space 堆内存溢出 ， 对象过大 java.lang.OutOfMemoryError:GC overhead limit exceeded GC回收时间过长 过长的定义是超过98%的时间用来做GC并且回收了而不倒2%的堆内存 连续多次GC，都回收了不到2%的极端情况下才会抛出 如果不抛出，那就是GC清理的一点内存很快会被再次填满，迫使GC再次执行，这样就恶性循环， cpu使用率一直是100%，二GC却没有任何成果 int i = 0; List list = new ArrayList<>(); try{ while(true){ list.add(String.valueOf(++i).intern()); } }catch(Throwable e){ System.out.println(\"********\"); e.printStackTrace(); throw e; } java.lang.OutOfMemoryError:Direct buffer memory 直接内存挂了 写NIO程序经常使用ByteBuffer来读取或写入数据，这是一种基于通道（Channel）与缓存区（Buffer)的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作，这样能在一些场景中显著提高性能，因为避免了在java堆和native堆中来回复制数据 ByteBuffer.allocate(capability) 第一种方式是分配JVM堆内存，属于GC管辖，由于需要拷贝所以速度较慢 ByteBuffer.alloctedDirect(capability)分配os本地内存，不属于GC管辖，不需要拷贝，速度较快 但如果不断分配本地内存，堆内存很少使用，那么jvm就不需要执行GC，DirectByteBuffer对象们就不会被回收，这时候堆内存充足，但本地内存可能已经使用光了，再次尝试分配本地内存救护i出现oom，程序崩溃 java.lang.OutOfMemoryError:unable to create new native thread==好案例== 应用创建了太多线程，一个应用进程创建了多个线程，超过系统承载极限 你的服务器并不允许你的应用程序创建这么多线程，linux系统默认允许单个进程可以创建的线程数是1024，超过这个数量，就会报错 解决办法 降低应用程序创建线程的数量，分析应用给是否针对需要这么多线程，如果不是，减到最低 修改linux服务器配置 java.lang.OutOfMemoryError:Metaspace 元空间主要存放了虚拟机加载的类的信息、常量池、静态变量、即时编译后的代码 static class OOMTest{} public static void main(String[] args){ int i = 0; try{ while(true){ i++; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(OOMTest.class); enhancer.setUseCache(false); enhancer.setCallback(new MethodInterceptor(){ @Override public Object intercept(Object o,Method method,Object[] objects, MethodProxy methodProxy)throws Throwable{ return methodProxy.invokeSuper(o,args); } }); enhancer.create(); } } catch(Throwable e){ System.out.println(i+\"次后发生了异常\"); e.printStackTrace(); } } 1.1.6. GC垃圾回收算法和垃圾收集器的关系？分别是什么 垃圾收集器就是算法的具体实现 6.1 GC算法 引用计数 复制 标记清理 标记整理 6.2 4种主要垃圾收集器 Serial 串行回收 为单线程换进该设计且只是用过一个线程进行垃圾回收，会暂停所有的用户线程，不适合服务器环境 Paralle 并行回收 多个垃圾收集线程并行工作，此时用户线程是暂停的，适用于科学计算/大数据处理首台处理等弱交互场景 CMS 并发标记清除 用户线程和垃圾手机线程同时执行（不一定是并行，可能交替执行），不需要停顿用户线程，互联网公司多用它，适用堆响应时间有要求的场景 G1 将堆内存分割城不同的区域然后并发的对其进行垃圾回收 ZGC 1.1.7. 怎么查看服务器默认的垃圾收集器是哪个？生产上如何配置垃圾收集器？对垃圾收集器的理解？ 查看：java -XX:+PrintCommandLinedFlags -version 配置： 有七种：UseSerialGC UseParallelGC UseConcMarkSweepGC UseParNewGC UseParallelOldGC UseG1GC 1.1.8. 垃圾收集器 8.1 部分参数说明 DefNew：Default New Generation Tenured：Old ParNew：Parallel New Generation PSYoungGen：Parallel Scavenge ParOldGen：Parallel Old Generation 8.2 Server/Client模式分别是什么意思 适用范围：只需要掌握Server模式即可，Client模式基本不会用 操作系统 32位Window操作系统，不论硬件如何都默认使用Client的JVM模式 32位其他操作系统，2G内存同时有2个cpu以上用Server模式，低于该配置还是Client模式 64位only server模式 8.3 新生代 串行GC (Serial)/(Serial Copying) 串行收集器：Serial收集器 1:1 一个单线程的收集器，在进行垃圾收集的时候，必须暂停其他所有的工作线程知道它收集结束。 串行收集器是最古老，最稳定以及效率最高的收集器，只使用一个线程去回收但其在进行垃圾收集过程中可能会产生较长的停顿（Stop-The-World 状态）。虽然在收集垃圾过程中需要暂停所有其他的工作线程，但是它简单高效，==对于限定单个CPU环境来说，没有线程交互的开销可以获得最高的单线程垃圾收集效率，因此Serial垃圾收集器依然是java虚拟机运行在Client模式下默认的新生代垃圾收集器。== 对应的JVM参数是：==-XX:+UseSerialGC== ==开启后会使用：Serial(Young区)+Serial Old(Old区)的收集器组合== 表示：==新生代、老年代都会使用串行回收收集器，新生代使用复制算法，老年代使用标记整理算法== DefNew ----- Tenured 并行GC (ParNew) 并行收集器 N:1 使用多线程进行垃圾回收，在垃圾收集时，会Stop-the-world暂停其他所有的工作线程知道它收集结束。 ==ParNew收集器其实就是Serial收集器新生代的并行多线程版本，==最常见的应用场景时配合==老年代的CMS GC工作==，其余的行为和Serial收集器完全一样，ParNew垃圾收集器在垃圾收集过程成中童谣也要暂停所有其他的工作线程，他是很多==java虚拟机运行在Server模式下新生代的默认垃圾收集器。== 常用对应JVM参数：==-XX:+UseParNewGC== 启用ParNew收集器，只影响新生代的收集，不影响老年代 ==开启后会使用：ParNew(Young区)+Serial Old(Old 区)的收集器组合==，新生代使用复制算法，老年代采用标记-整理算法 ParNew ------ Tenured 备注: ==-XX:ParallelGCThreads== 限制线程数量，默认开启和CPU数目相同的线程数 并行回收GC (Parallel)/(Parallel Scavenge) 并行收集器 N:N 类似ParNew也是一个新生代垃圾收集器，使用复制算法，也是一个并行的多线程的垃圾收集器，俗称吞吐量有限收集器。串行收集器在新生代和老年代的并行化。 他重点关注的是： 可控制的吞吐量（Thoughput=运行用户代码时间/(运行用户代码时间+垃圾收集时间)，业绩比如程序运行100分钟，垃圾收集时间1分钟，吞吐量就是99%）。高吞吐量意味着高效利用CPU时间，他多用于在后台运算而不需要太多交互的任务。 自适应调节策略也是ParallelScavenge收集器与ParNew收集器的一个重要区别。（自适应调节策略：虚拟机会根据当前系统的运行情况手机性能监控信息，动态调整这些参数以提供最合适的停顿时间==(-XX:MaxGCPauseMillis)==或最大的吞吐量 ==-XX:ParallelGCThreads=数字N== 表示启动多少个GC线程 cpu>8 n=5/8 cpu ==-XX:+UseParallelGC==、==-XX:+UseParallelOldGC== 8.4 老年代 串行GC（Serial Old）/（Serial MSC） 并行GC（Parallel Old）/（Parallel MSC） Parallel Scavenge的老年代版本，使用多线程的标记-整理算法，Parallel Old收集器在JDK1.6开始提供 1.6之前，新生代使用ParallelScavenge收集器只能搭配年老代的Serial Old收集器，只能保证新生代的吞吐量优先，无法保证整体的吞吐量。在1.6之前（ParallelScavenge+SerialOld） Parallel Old正式为了在老年代同样提供吞吐量游戏的垃圾收集器，如果系统对吞吐量要求比较高，JDK1.8后可以考虑新生代Parallel Scavenge和年老代Parallel Old收集器的搭配策略 常用参数：==-XX:+UseParallelOldGC==》》》》》新生代Paralle+老年代Paralle Old 并发标记清除GC（CMS） CMS收集器（Concurrent Mark Sweep：并发标记清除）是一种以获取最短回收停顿时间为目标的收集器。 适合在互联网站或者B/S系统的服务器上，这列应用尤其中使服务器的响应速度，希望系统停顿时间最短。 CMS非常适合堆内存大、CPU核数多的服务区端应用，也是G1出现之大型应用的首选收集器。 并发标记清除收集器：ParNew+CMS+Serial Old CMS，并发收集低停顿，并发指的是与用户线程一起执行 JVM参数：==-XX:+UseConcMarkSweepGC==，开启该参数后会自动将-XX:UseParNewGC打开 开启该参数后，使用ParNew+CMS+Serial Old的收集器组合，Serial Old将作为CMS出错的后备收集器 4步过程： 初始标记（CMS initial mark） 只是标记一下GC Roots能够直接关联的对象，速度很快，仍然需要暂停所有的工作线程。 并发标记（CMS concurrent mark）和用户线程一起 进行GC Roots跟踪过程，和用户线程一起工作，不需要暂停工作线程。主要标记过程，标记全部对象 重新标记（CMS remark） 为了修正并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，仍然需要暂停所有的工作线程，由于并发标记时，用户线程依然运行，因此在正式清理前，再做修正 并发清除（CMS concurrent sweep）和用户线程一起 清除GC Roots不可达对象，和用户线程一起工作，不需要暂停工作线程。基于标记结果，直接清理对象 由于耗时最长的并发标记和并发清除过程中，垃圾收集线程可以和用户现在一起并发工作，所以总体上看来CMS收集器的内存回收和用户线程是一起并发的执行。 优缺点： 并发收集停顿低 并发执行，cpu资源压力大 由于并发进行，CMS在收集与应用线程会同时增加对堆内存的占用，也就是说，==CMS必须要在老年代堆内存用尽之前完成垃圾回收==，否则CMS回收失败时，将出发担保机制，串行老年代收集器将会以STW的方式进行一次GC，从而造成较大停顿时间。 采用的标记清除算法会导致大量的碎片 标记清除算法无法整理空间碎片，老年代空间会随着应用时长被逐步耗尽，最后将不得不通过担保机制堆堆内存进行压缩。CMS也提供了参数==-XX:CMSFullGCsBeForeCompaction==(默认0，即每次都进行内存整理)来制定多少次CMS收集之后，进行一次压缩的FullGC。 8.5 如何选择垃圾选择器 单CPU或小内存，单机内存 -XX:+UseSerialGC 多CPU，需要最大吞吐量，如后台计算型应用 -XX:+UseParallelGC -XX:+UseParallelOldGC 多CPU，最求低停顿时间，需快速相应，如互联网应用 -XX:+ParNewGC -XX:+UseConcMarkSweepGC 参数 新生代垃圾收集器 新生代算法 老年代垃圾收集器 老年代算法 UseSerialGC SerialGC 复制 SerialOldGC 标整 UseParNewGC ParNew 复制 SerialOldGC 标整 UseParallelGCUseParallelOldGC Parallel[Scavenge] 复制 Parallel Old 标整 UseConcMarkSweepGC ParNew 复制 CMS+Serial Old的收集器组合(Serial Old 作为CMS出错的后备收集器) 标清 UseG1GC G1整体上采用标整 局部是通过复制算法 1.1.9. G1垃圾收集器 将堆内存分割城不同的区域然后并发的对其进行垃圾回收 9.1 其他收集器特点 年轻代和老年代是各自独立且了连续的内存块 年轻代收集使用单eden+S0+S1进行复制算法 老年代收集必须扫描真个老年代区域 都是以尽可能少而快速地执行GC为设计原则 9.2 G1是什么 G1（Garbage-First）收集器，是一款面向服务端应用的收集器 应用在多处理器和大容量内存环境中，在实现高吞吐量的同时，尽可能的满足垃圾收集暂停时间的要求 和CMS收集器一样，能与应用程序线程并发执行 整理空闲空间更快 需要更多的时间来预测GC停顿时间 不希望牺牲大量的吞吐性能 不需要更大的Java Heap G1收集器的设计目标是取代CMS收集器，和CMS相比，在以下放木表现更出色： G1是一个由整理内存过程的垃圾收集器，不会产生很多内存碎片 G1的Stop The World（STW）更可控，G1在停顿时间上添加了预测机制，用户可以指定期望停顿时间。 CMS垃圾收集器虽然减少了暂停应用程序的运行时间，但是他还是存在着内存碎片问题。于是为了取出内存碎片问题，同时又保留CMS垃圾收集器低暂停时间的优点，JAVA7发布了G1垃圾收集器。 主要改变的是Eden，Survivor和Tenured等内存区域不再是连续的了，而是变成了一个个大小一样的region（区域化），每个region从1M到32M不等。一个region有可能属于Eden，Survivor或Tenured内存区域。 9.2.1 特点 G1能充分利用多CPU、多核环境优势，尽量缩短STW。 G1整体上采用标记-整理算法，局部是通过复制算法，不会产生内存碎片。 宏观上G1之中不再区分年轻代和老年代。把内存划分成多个独立的子区域（Region），可以近似理解为一个棋盘 G1收集器里面讲整个的内存去都混合在一起了，但其本身依然在小范围内要进行年轻代和老年代的区分，保留了新生代和老年代，但它们不再是物理隔离，而是一部分Region的集合且不需要Region是连续的，也就是说依然会采用不同GC方式来处理不同的区域。 G1虽然也是分代收集器，但整个内存分区不存在物理上的年轻代与老年代的区别，也不需要完全独立的survivor（to space）堆做复制准备。G1只有逻辑上的分代概念，或者说每个分区都可能随G1的运行在不同代之间前后切换 9.3 底层原理 Region区域化垃圾收集器 最大好处是化整为零，避免全内存扫描，只需要按照区域来进行扫描即可 区域化内存划片Region，整体编为了 一系列不连续的内存区域，避免了全内存区的GC操作。 核心思想是讲整个堆内存区域分成大小相同的子区域，在JVM启动时会自动共设置这些子区域的大小 在堆的使用上，G1并不要求对象的存储一定是物理上连续的，只要逻辑上连续即可，每个分区也不会固定地为某个代服务，可以按需在年轻代和老年代之间切换。启动时可以通过参数==-XX:G1HeapRegionSize==可指定分区大小（1~32M,且必须是2的幂），默认将整堆划分为2048个分区。 大小范围在1-32M，最多能设置2048个区域，也即能够支持的最大内存为64G G1算法将堆划分为诺干个区域，他仍然属于分代收集器 这些Region的一部分包含新生代，新生代的垃圾收集依然采用暂停所有应用线程的方式，将存活对象拷贝到老年代或Survivor空间，这些Region的一部分包含老年代，G1收集器通过将对象从一个区域复制到另外一个区域，完成了清理工作。这就意味着，在正常的处理过程中，G1完成了堆的压缩，这样也就不会有CMS内存碎片问题的存在了 在G1中，还有一种特殊区域，Humongous区域，如果一个对象张勇的空间超过了分区容量50%以上，G1收集器就认为i这是一个巨型对象。这些巨型对象默认直接会被分配在年老代，但是如果他是一个短期存在的巨型对象，就会对垃圾收集器造成负面影响。为了解决这个问题，G1划分了一个Humongous区，他用来专门存放巨型对象。如果一个H区装不下，那么G1就会寻找连续的H分区来存储。为了能找到连续的H区，有时候不得不启动Full GC 回收步骤 针对Eden区进行收集，Eden区耗尽后会被触发，主要小区域收集+形成连续的内存块，避免内存碎片 Eden区的数据移动到Survivor区，假如出现Survivor区空间不够，Eden区数据就会晋升到Old区 Survivor区的数据移动到新的Survivor区，部分数据晋升到Old区 最后Eden区收拾干净了，GC结束，用户的应用程序继续执行。 4步过程 初始标记：只标记GC Roots能直接关联到的对象 并发标记：进行GC Roots Tracing的过程 最终标记：修正并发标记期间，因程序运行导致标记发生变化的那一部分对象 筛选回收：根据时间来进行价值最大化的回收 9.4 case 9.5 常用配置参数（不是重点） -XX:+UseG1Gc -XX:G1HeapRegionSize=n 设置的G1区域的大小，值是2的幂，范围是1-32MB，目标是根据最小的java堆大小划分出约2048个区域 -XX:MaxGCPauseMillis=n 最大GC停顿时间，这是个软目标，JVM将尽可能（但不保证）停顿小于这个时间 -XX:InitiatingHeapOccupancyRercent=n 堆占用了多少的时候就触发GC，默认45 -XX:ConcGcThreads=n 并发GC使用的线程数 -XX:G1ReservePercent=n 设置作为空闲空间的预留内存百分比，以降低目标空间溢出的风险，默认10% 9.6 和CMS相比优势 G1不会产生内存碎片 可以精确控制停顿。该收集器十八真个堆划分成多个固定大小的区域，每根据允许停顿的时间去收集垃圾最多的区域 1.1.10. 生产环境服务器变慢，诊断思路和性能评估谈谈？ 整机：top 系统性能 uptime 精简版 load average：系统负载均衡 1min 5min 15min 系统的平均负载值 相加/3>60%压力够 CPU：vmstat 查看CPU vmstat -n 2 3 第一个参数是采样的时间间隔数单位s，第二个参数是采样的次数 procs r：运行和等待CPU时间片的进程数，原则上1核CPu的运行队列不要超过2，真个系统的运行队列不能超过总核数的2倍，否则表示系统压力过大 b：等待资源的进程数，比如正在等待磁盘I/O，网络I/O等 cpu us：用户进程消耗cpu时间百分比，us高，用户进程消耗cpu时间多，如果长期大于50%，优化程序 sy：内核进程消耗的cpu时间百分比 us+sy：参考值为80%，如果大于80，说明可能存在cpu不足 id：处于空闲的cpu百分比 wa：系统等待IO的cpu时间百分比 st：来自于一个虚拟机偷取的cpu时间的百分比 查看额外 查看所有cpu核信息 mpstat -P ALL 2 每个进程使用cpu的用量分解信息 pidstat -u 1 -p 进程编号 内存：free 查看内存 free -m free -g pidstat -p 进程编号 -r 采样间隔秒数 硬盘：df 查看磁盘剩余空间 df -h 磁盘IO：iostat 磁盘I/O性能评估 iostat -hdk 2 3 rkB/s每秒读取数据kb； wkB/s每秒读写数据量kb svctm I/O请求的平均服务时间，单位毫秒； await I/O请求的平均等待时间，单位毫秒；值越小，性能越好； ==util== 一秒中又百分几的时间用于I/O操作，接近100%时，表示磁盘带宽跑满，需要优化程序或加磁盘 rkB/s，wkB/s根据系统该应用不同回有不同的值，担忧规律遵循：长期、超大数据读写，肯定不正常，需要优化程序读取。 svctm的值与await的值很接近，表示几乎没有I/O等待，磁盘性能好，如果await的值远高于svctm的值，则表示I/O队列等待太长，需要优化程序或更换更快磁盘 pidstat -d 采样间隔秒数 -p 进程号 网络IO：ifstat ifstat l 1.1.11. 加入生产环境CPU占用过高，谈谈分析思路和定位？ 结合Linux和JDK命令一块分析 11.1 案例步骤 先用top命令找出cpu占比最高的 ps -ef或者jps进一步定位，得知是一个怎样的后台程序惹事 jps -l ps -ef|grep java|grep -v grep 定位到具体线程或者代码 ps -mp 进程编号 -o Thread,tid,time 定位到具体线程 -m ：显示所有的线程 -p pid 进程使用cpu的时间 -o：该参数后是用户自定义格式 将需要的线程ID转换为16禁止格式（英文小写格式） printf \"%x\\n\" 线程ID jstack 进程Id|grep tid(16进制线程id小写英文) -A60 查看运行轨迹，堆栈异常信息 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"1.JAVA基础/并发编程/1.JMM内存模型和volatile.html":{"url":"1.JAVA基础/并发编程/1.JMM内存模型和volatile.html","title":"1.JMM内存模型和volatile","keywords":"","body":"1.1. volatile是java虚拟机提供的轻量级同步机制1.1.1. 前提：JMM内存模型1.2. 个人理解1.3. volatile底层1.3.1. 扩展：DCL模式（Double Check Lock）双端检锁单例模式1.1. volatile是java虚拟机提供的轻量级同步机制 保证可见性 不保证原子性 保证有序性（禁止指令重排） 1.1.1. 前提：JMM内存模型 JMM（java Memory Model）：java内存模型,抽象的概念，是一种规范。 可见性: JMM关于同步的规定 线程解锁前，必须将共享变量的值刷新到主内存（可见性） 线程加锁前，必须将主内存中的共享变量复制到工作内存（栈空间）中 加锁解锁是同一把锁（原子性） 原子性 不可分割，线程做某个业务的时候，中间不可分割，整个步骤是完整的，要么同时成功，要么同时失败 有序性（禁止指令重排） happens- before原理过于晦涩，简单理解为计算机执行程序为了提高性能，会在保证数据依赖性的情况下，会对指令进行重新排序，多线程环境线程交替执行，无法保证数据一致性。 1.2. 个人理解 可见性:可见性其实就是，多个线程不可以同时操作主内存，所以当线程操作共享变量时，必须将共享变量拷贝到自己的工作内存中进行运算，运算结束后刷新回主线程。如果没有可见性，线程就算对共享变量修改后，主内存的值仍未改变，即对别的线程不可见 volatile为什么不保证原子性？ volatile没有锁的机制，允许多个线程同时对一个共享变量进行操作，虽然保证了可见性，但是在线程拷贝共享变量的时候，拷贝的是同一个值，多个线程对自己工作内存的变量进行修改后，覆盖回主内存，会造成数据的丢失 如何解决volatile不保证原子性？（1）加sync （2）对共享变量使用Atomic（原子类，CAS），就是说将线程对共享变量进行的运算变为原子操作，从复制到工作内存到覆盖主内存的过程变为一个完整的操作。每个线程进行共享变量的运算后，别的线程才可以进行读取运算 volatile保证有序性原理以及可见性： 内存屏障（Memory Barrier） 是一个CPU指令，主要作用有两个。 （1.）保证特定操作的执行顺序 （2.）保证某些变量的内存可见性 由于编译器和处理器都能执行指令重排优化，在指令间加入Memory Barrier告诉编译器和CPU，无论什么指令都不可以与该指令重排。即通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化。 内存屏障另一个作用就是刷新各种CPU缓存数据，因此在任何线程上读取到的都是数据的最新版本 有volatile修饰的变量，赋值后（前面mov%eax，0x150(%esi)这句便 是赋值操作）多执行了一个“lock addl$0x0，(%esp)”操作，这个操作的作用相当于一个内存屏障 （Memory Barrier或Memory Fence，指重排序时不能把后面的指令重排序到内存屏障之前的位置 1.3. volatile底层 如果一个字段被声明成volatile，Java线程内存模型确保所有线程看到这个变量的值是一致的 private volatile instance = new Singleton(); 汇编: 0x01a3de1d: movb $0×0,0×1104800(%esi); 0x01a3de24: lock addl $0×0,(%esp); 有 volatile 变量修饰的共享变量进行写操作的时候会多出第二行汇编代码，通过查IA-32架构软件开发者手册可知，Lock前缀的指令在多核处理器下会引发了两件事情。 将当前处理器缓存行的数据写回到系统内存。 这个写回内存的操作会使在其他内存中缓存的数据无效 第一件事很容易理解，处理器在修改数据后通常都是先写入到缓存中，但是并不会第一时间写回到主内存中。 被 volatile 修饰后，这个变量被操作后会立即被写回到主内存中。（当然整个过程会比较复杂，但是我们只需要从结果上来看和简化理解就OK了。） 那第二件事中这个写回内存的操作是如何使其他CPU里缓存了该内存地址的数据无效的呢？ 为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存（L1，L2或其他）后再进行操作，但操作完不知道何时会写到内存。 如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。 所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。 处理器无论是想要加载数据或者写回数据，都需要通过总线来传播， 那么我们也就可以将 “处理器通过嗅探在总线上传播的数据” 这样的操作形象的理解为处理器监听 总线 上的所有修改操作 1.3.1. 扩展：DCL模式（Double Check Lock）双端检锁单例模式 /** * DCL模式（Double Check Lock）双端检锁模式 */ public class SingletonDemo { private static volatile SingletonDemo instance = null; private SingletonDemo() { } public static SingletonDemo getInstance() { if (instance == null) { synchronized (SingletonDemo.class) { if (instance == null) { instance = new SingletonDemo(); } } } return instance; } } 理论上无需添加volatile关键字就可以保证多线程的单例，但是为什么需要添加volatile？ 指令重排 某一个线程执行到第一个检测时，读取到instance不为null,但是instance可能并没有完成初始化 对象初始化分为: 分配对象内存空间 初始化对象 设置instance指向刚分配的地址，此时instance!=null 由于指令重排的原因，没有按照1-> 2-> 3 的顺序进行执行指令，反而按照1-> 3 ->2的顺序进行了执行，导致instance指向的内存空间没有完成初始化对象 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"1.JAVA基础/并发编程/2.CAS.html":{"url":"1.JAVA基础/并发编程/2.CAS.html","title":"2.CAS","keywords":"","body":"1.1. CAS（Compare-and-Swap）比较并交换及如何解决ABA问题1.1.1. synchronized保证一致性，并发下降1.1.2. CAS CPU并发原语1.2. CAS的缺点1.2.1. 如何解决ABA问题1.1. CAS（Compare-and-Swap）比较并交换及如何解决ABA问题 1.1.1. synchronized保证一致性，并发下降 独占锁是一种悲观锁，synchronized就是一种独占锁，会导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁。而另一个更加有效的锁就是乐观锁。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。乐观锁用到的机制就是CAS，Compare and Swap。 1.1.2. CAS CPU并发原语 CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。 如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值 。否则，处理器不做任何操作。 Atomic底层使用cas原理---unsafe类 this即当前对象，valueOffset为内存偏移量，expect期望值即快照值，update新值 底层cas的实现调用的c++的方法 CAS自旋锁： var5取的是主内存的值，如果快照值和当前值相同，则比较并交换，否则循环，重新从主内存读取共享变量的值，再次进行判断，直到更新成功跳出循环。 1.2. CAS的缺点 ABA问题: 因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A－B－A 就会变成1A-2B－3A。 循环时间长，CPU开销大 只可以保证一个共享变量的原子操作 可以采用AtomicReference来解决，将需要原子操作的共享变量放置到AtomicReference中 1.2.1. 如何解决ABA问题 使用AtomicReference原子引用类+版本号（时间戳）= AtomicStampedReference。这个类的compareAndSet方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"1.JAVA基础/并发编程/3.锁.html":{"url":"1.JAVA基础/并发编程/3.锁.html","title":"3.锁","keywords":"","body":"1.1. 公平锁非公平锁1.2. 可重入锁（递归锁）1.3. 自旋锁1.4. 独占锁（写锁）/共享锁（读锁）/互斥锁1.1. 公平锁非公平锁 公平锁：多个线程按照申请锁的顺序来获取锁，先来先得 非公平锁：非顺序获得锁，高并发情况下，有可能造成优先级反转或饥饿现象，非公平锁的优点在于吞吐量比公平锁大 Synchronized为非公平锁 /** * Creates an instance of {@code ReentrantLock} with the * given fairness policy. * * @param fair {@code true} if this lock should use a fair ordering policy */ public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); } ReentrantLock通过构造函数指定是否为公平锁，默认为非公平锁。 1.2. 可重入锁（递归锁） 一个线程外层函数获得锁之后，内存递归函数仍可获得该锁的代码，在同一个线程在外层方法获取锁的时候，进入内层方法会自动获取锁 线程可以进入任何一个它已经拥有的锁所同步着的代码块 就是说内层方法重复加锁无需再次获取锁，直接进入内层方法 ReentrantLock/Synchronized都为可重入锁,因为加锁锁的是对象头 作用: 避免死锁 1.3. 自旋锁 尝试获取锁的线程不会立即阻塞，采取循环方式去获取锁，这样可以减少线程获取上下文的消耗，缺点浪费cpu /** * 实现自旋锁 * 自旋锁好处，循环比较获取知道成功位置，没有类似wait的阻塞 * * 通过CAS操作完成自旋锁，A线程先进来调用mylock方法自己持有锁5秒钟，B随后进来发现当前有线程持有锁，不是null，所以只能通过自旋等待，知道A释放锁后B随后抢到 */ public class SpinLockDemo { //原子引用线程 AtomicReference atomicReference = new AtomicReference<>(); public void mylock() { Thread thread = Thread.currentThread(); System.out.println(Thread.currentThread().getName() + \"\\t come in\"); while (!atomicReference.compareAndSet(null, thread)) { } } public void myUnlock() { Thread thread = Thread.currentThread(); atomicReference.compareAndSet(thread, null); System.out.println(Thread.currentThread().getName()+\"\\t invoked myunlock()\"); } public static void main(String[] args) { SpinLockDemo spinLockDemo = new SpinLockDemo(); new Thread(() -> { spinLockDemo.mylock(); try { TimeUnit.SECONDS.sleep(3); }catch (Exception e){ e.printStackTrace(); } spinLockDemo.myUnlock(); }, \"Thread 1\").start(); try { TimeUnit.SECONDS.sleep(3); }catch (Exception e){ e.printStackTrace(); } new Thread(() -> { spinLockDemo.mylock(); spinLockDemo.myUnlock(); }, \"Thread 2\").start(); } } 1.4. 独占锁（写锁）/共享锁（读锁）/互斥锁 写锁=独占锁 读锁=共享锁 互斥锁：读写锁，写写锁互斥 ReentrantReadWriteLock锁验证 /** * 多个线程同时读一个资源类没有任何问题，所以为了满足并发量，读取共享资源应该可以同时进行。 * 但是 * 如果有一个线程象取写共享资源来，就不应该自由其他线程可以对资源进行读或写 * 总结 * 读读能共存 * 读写不能共存 * 写写不能共存 */ public class ReadWriteLockDemo { public static void main(String[] args) { MyCache myCache = new MyCache(); for (int i = 1; i { myCache.put(tempInt + \"\", tempInt + \"\"); }, \"Thread \" + i).start(); } for (int i = 1; i { myCache.get(tempInt + \"\"); }, \"Thread \" + i).start(); } } } class MyCache { private volatile Map map = new HashMap<>(); private ReentrantReadWriteLock rwLock = new ReentrantReadWriteLock(); /** * 写操作：原子+独占 * 整个过程必须是一个完整的统一体，中间不许被分割，不许被打断 * * @param key * @param value */ public void put(String key, Object value) { rwLock.writeLock().lock(); try { System.out.println(Thread.currentThread().getName() + \"\\t正在写入：\" + key); TimeUnit.MILLISECONDS.sleep(1300); map.put(key, value); System.out.println(Thread.currentThread().getName() + \"\\t写入完成\"); } catch (Exception e) { e.printStackTrace(); } finally { rwLock.writeLock().unlock(); } } public void get(String key) { rwLock.readLock().lock(); try { System.out.println(Thread.currentThread().getName() + \"\\t正在读取：\" + key); TimeUnit.MILLISECONDS.sleep(13000); Object result = map.get(key); System.out.println(Thread.currentThread().getName() + \"\\t读取完成: \" + result); } catch (Exception e) { e.printStackTrace(); } finally { rwLock.readLock().unlock(); } } public void clear() { map.clear(); } } 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"1.JAVA基础/并发编程/4.CountDownLatch、CyclicBarrier、Semaphore.html":{"url":"1.JAVA基础/并发编程/4.CountDownLatch、CyclicBarrier、Semaphore.html","title":"4.CountDownLatch、CyclicBarrier、Semaphore","keywords":"","body":"1.1. CountDownLatch（火箭发射倒计时）1.2. CyclicBarrier（集齐七颗龙珠召唤神龙）1.3. Semaphore信号量1.1. CountDownLatch（火箭发射倒计时） 它允许一个或多个线程一直等待，知道其他线程的操作执行完后再执行。例如，应用程序的主线程希望在负责启动框架服务的线程已经启动所有的框架服务之后再执行 CountDownLatch主要有两个方法，当一个或多个线程调用await()方法时，调用线程会被阻塞。其他线程调用countDown()方法会将计数器减1，当计数器的值变为0时，因调用await()方法被阻塞的线程才会被唤醒，继续执行 public class CountDownLatchDemo { public static void main(String[] args) throws InterruptedException { countDownLatchTest(); } public static void countDownLatchTest() throws InterruptedException { CountDownLatch countDownLatch = new CountDownLatch(6);//定义CountDownLatch，倒计时为6 for (int i = 1; i { System.out.println(Thread.currentThread().getName()+\"\\t被灭\"); countDownLatch.countDown();//每个线程执行完毕-1 }, CountryEnum.forEach_CountryEnum(i).getRetMessage()).start(); } countDownLatch.await();//等待，倒计时归0时执行主线程 System.out.println(Thread.currentThread().getName()+\"\\t=====秦统一\"); } } 1.2. CyclicBarrier（集齐七颗龙珠召唤神龙） 可循环（Cyclic）使用的屏障。让一组线程到达一个屏障（也可叫同步点）时被阻塞，知道最后一个线程到达屏 障时，屏障才会开门，所有被屏障拦截的线程才会继续干活，线程进入屏障通过CycliBarrier的await()方法 public class CyclicBarrierDemo { public static void main(String[] args) { cyclicBarrierTest(); } public static void cyclicBarrierTest() { CyclicBarrier cyclicBarrier = new CyclicBarrier(7, () -> { System.out.println(\"====召唤神龙=====\"); }); for (int i = 1; i { System.out.println(Thread.currentThread().getName() + \"\\t收集到第\" + tempInt + \"颗龙珠\"); try { cyclicBarrier.await();//等待，梭有线程到达后才往下执行 System.out.println(tempInt); } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } }, \"\" + i).start(); } } } 1.3. Semaphore信号量 可以代替Synchronize和Lock，在只有一个（车位）的情况下 信号量主要用于两个目的，一个是用于多个共享资源的互斥作用，另一个用于并发线程数的控制 public class SemaphoreDemo { public static void main(String[] args) { Semaphore semaphore = new Semaphore(3);//模拟三个停车位 for (int i = 1; i { try { semaphore.acquire();//占用 System.out.println(Thread.currentThread().getName() + \"\\t抢到车位\"); try { TimeUnit.SECONDS.sleep(3);//停车3s } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \"\\t停车3s后离开车位\"); } catch (InterruptedException e) { e.printStackTrace(); } finally { semaphore.release();//释放 } }, \"Car \" + i).start(); } } } 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"1.JAVA基础/并发编程/5.AQS原理以及AQS同步组件.html":{"url":"1.JAVA基础/并发编程/5.AQS原理以及AQS同步组件.html","title":"5.AQS原理以及AQS同步组件","keywords":"","body":"1.1.1. AQS核心思想1.2. java并发工具类三重点1.3. AbstractQueuedSynchronizer(AQS)1.3.1. 状态1.3.2. 队列1.3.3. CAS操作1.4. ReentrantLock源码分析1.4.1. 初始化1.4.2. lock()方法1.5. Semaphore(信号量)-允许多个线程同时访问1.6. CountDownLatch （倒计时器）1.6.1. CountDownLatch 的不足1.7. CyclicBarrier(循环栅栏)1.1.1. AQS核心思想 如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 CLH 队列锁实现的，即将暂时获取不到锁的线程加入到队列中。 AQS（AbstractQueuedSynchronizer）是JAVA中众多锁以及并发工具的基础，其底层采用乐观锁，大量使用了CAS操作，而且在冲突时，采用自旋方式重试，以实现轻量级和高效地获取锁 AQS中实现了锁的获取框架，锁的实际获取逻辑交由子类去实现，就锁的获取操做而言，子类必须重写 tryAcquire方法。 1.2. java并发工具类三重点 状态: 通常是一个state属性，它基本是整个工具的核心，一般整个工具都是在设置和修改状态，不少方法的操做都依赖于当前状态是什么。因为状态是全局共享的，通常会被设置成volatile类型，以保证其修改的可见性； 队列: 队列一般是一个等待的集合，大多数以链表的形式实现。队列采用的是悲观锁的思想，表示当前所等待的资源，状态或者条件短期内可能没法知足。所以，它会将当前线程包装成某种类型的数据结构，扔到一个等待队列中，当必定条件知足后，再从等待队列中取出。 CAS: 最轻量的并发处理，对于state的修改用到的都是CAS操作，保证原子性，CAS采用Unsafe工具类的compareAndSwapXXX实现。CAS采用乐观锁的思想，死循环进行不断尝试CAS操作 1.3. AbstractQueuedSynchronizer(AQS) 1.3.1. 状态 public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { ...... //记录当前锁的状态，state=0，锁没被占用，state>0锁为占用状态， //为什么不是=1是因为，可重入锁state的值会大于1 private volatile int state; //在AbstractQueuedSynchronizer中不存在，实际定义在AbstractOwnableSynchronizer中 //继承自AbstractOwnableSynchronizer private transient Thread exclusiveOwnerThread; //等待队列的头节点,head节点永远为NULL(哑节点)，就算当前等待队列无节点也不会插入到head节点 private transient volatile Node head; //等待队列的尾节点 private transient volatile Node tail; ...... } ReentrantLock为独占锁，同一个时刻只能被一个线程进行占有，在synchronized中通过监视器锁的ObjectMonitor对象_owner属性记录当前拥有锁的线程，在AQS中通过继承AbstractOwnableSynchronizer类中的exclusiveOwnerThread属性记录当前占用锁的线程 1.3.2. 队列 在AQS中，采用的队列底层采用双端双向链表，它表示全部等待锁的线程的集合,Node为定义在AQS类中的静态内部类 static final class Node { ...... // 节点所表明的线程 volatile Thread thread; // 双向链表，每一个节点须要保存本身的前驱节点和后继节点的引用 volatile Node prev; volatile Node next; // 线程所处的等待锁的状态，初始化时，该值为0 volatile int waitStatus; static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; // 该属性用于条件队列或者共享锁 Node nextWaiter; ...... } 在这个Node类中也有一个状态变量waitStatus，它表示了当前Node所表明的线程的等待锁的状态，在独占锁模式下，咱们只须要关注CANCELLED SIGNAL两种状态便可。这里还有一个nextWaiter属性，它在独占锁模式下永远为null，仅仅起到一个标记做用 sync queue AQS中的队列是一个CLH队列，它的head节点永远是一个哑结点（dummy node),它不表明任何线程（某些状况下能够看作是表明了当前持有锁的线程），所以head所指向的Node的thread属性永远是null。只有从次头节点日后的全部节点才表明了全部等待锁的线程。也就是说，在当前线程没有抢到锁被包装成Node扔到队列中时，即便队列是空的，它也会排在第二个，咱们会在它的前面新建一个dummy节点。为了便于描述，下文中咱们把除去head节点的队列称做是等待队列，在这个队列中的节点才表明了全部等待锁的线程 Node节点各个参数的含义： thread：表示当前Node所表明的线程 waitStatus：表示节点所处的等待状态，共享锁模式下只需关注三种状态：SIGNAL CANCELLED 初始态(0) prev next：节点的前驱和后继 nextWaiter：进做为标记，值永远为null，表示当前处于独占锁模式 1.3.3. CAS操作 /** * Setup to support compareAndSet. We need to natively implement * this here: For the sake of permitting future enhancements, we * cannot explicitly subclass AtomicInteger, which would be * efficient and useful otherwise. So, as the lesser of evils, we * natively implement using hotspot intrinsics API. And while we * are at it, we do the same for other CASable fields (which could * otherwise be done with atomic field updaters). */ private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long stateOffset; private static final long headOffset; private static final long tailOffset; private static final long waitStatusOffset; private static final long nextOffset; static { try { stateOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField(\"state\")); headOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField(\"head\")); tailOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField(\"tail\")); waitStatusOffset = unsafe.objectFieldOffset (Node.class.getDeclaredField(\"waitStatus\")); nextOffset = unsafe.objectFieldOffset (Node.class.getDeclaredField(\"next\")); } catch (Exception ex) { throw new Error(ex); } } 从这个静态代码块中咱们也能够看出，CAS操做主要针对5个属性，包括AQS的3个属性state,head和tail,以及Node对象的两个属性waitStatus,next。说明这5个属性基本是会被多个线程同时访问的。CAS操作调用的仍是Unsafe的compareAndSwapXXX方法。 1.4. ReentrantLock源码分析 首先继承关系图 1.4.1. 初始化 /** * Creates an instance of {@code ReentrantLock}. * This is equivalent to using {@code ReentrantLock(false)}. */ public ReentrantLock() { //无参默认初始化非公平锁 sync = new NonfairSync(); } /** * Creates an instance of {@code ReentrantLock} with the * given fairness policy. * * @param fair {@code true} if this lock should use a fair ordering policy */ public ReentrantLock(boolean fair) { //true公平锁，false非公平锁，FairSync与NonfairSync都继承Sync类，Sync继承AQS抽象类 sync = fair ? new FairSync() : new NonfairSync(); } ReentrantLock 默认无参构造器初始化非公平锁，也可以在初始化的时候根据boolean fair构造出公平锁 FairSync与NonfairSync都继承于Sync抽象类,在sync中定义了lock()抽象方法，FairSync与NonfairSync都进行了重写 1.4.2. lock()方法 FairSync.lock() static final class FairSync extends Sync { private static final long serialVersionUID = -3000897897090466540L; final void lock() { acquire(1); } protected final boolean tryAcquire(int acquires) { //获取当前尝试加锁的线程 final Thread current = Thread.currentThread(); int c = getState(); //判断是否有线程已经占有锁 if (c == 0) { if (!hasQueuedPredecessors() && //这个方法的本质实际上是检测自己是不是head节点的后继节点，即处在阻塞队列第一位的节点 compareAndSetState(0, acquires)) {//cas更改状态值 setExclusiveOwnerThread(current);//状态更改成功，将该线程设置为占有锁的线程 return true; } } else if (current == getExclusiveOwnerThread()) {//锁已经被占有，可重入锁的特性：判断当前占有锁的线程是不是就是尝试获取锁的线程 int nextc = c + acquires; if (nextc 调用AQS中的acquire()方法 public final void acquire(int arg) { if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } tryAcquire(arg) 该方法由继承AQS的子类实现, 为获取锁的具体逻辑。 addWaiter(Node mode) 该方法由AQS实现, 负责在获取锁失败后调用, 将当前请求锁的线程包装成Node扔到sync queue中去，并返回这个Node。 acquireQueued(final Node node, int arg) 该方法由AQS实现,这个方法比较复杂, 主要对上面刚加入队列的Node不断尝试如下两种操做之一: 在前驱节点就是head节点的时候,继续尝试获取锁 将当前线程挂起,使CPU再也不调度它 selfInterrupt 该方法由AQS实现, 用于中断当前线程。因为在整个抢锁过程当中，都是不响应中断的。那若是在抢锁的过程当中发生了中断AQS的作法简单的记录有没有有发生过中断， 若是返回的时候发现曾经发生过中断，则在退出acquire方法以前，就调用selfInterrupt自我中断一下，就好像将这个发生在抢锁过程当中的中断“推迟”到抢锁结束之后再发生同样。 1.5. Semaphore(信号量)-允许多个线程同时访问 synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。 Semaphore同样具有是否开启公平模式的构造方法默认非公平模式 Semaphore 与 CountDownLatch 一样，也是共享锁的一种实现。它默认构造 AQS 的 state 为 permits。 当执行任务的线程数量超出 permits,那么多余的线程将会被放入阻塞队列 Park,并自旋判断 state 是否大于 0。 只有当 state 大于 0 的时候，阻塞的线程才能继续执行,此时先前执行任务的线程继续执行 release 方法， release 方法使得 state 的变量会加 1，那么自旋的线程便会判断成功。 如此，每次只有最多不超过 permits 数量的线程能自旋成功，便限制了执行任务线程的数量。 1.6. CountDownLatch （倒计时器） CountDownLatch 允许 count 个线程阻塞在一个地方，直至所有线程的任务都执行完毕。 CountDownLatch 是共享锁的一种实现,它默认构造 AQS 的 state 值为 count。当线程使用 countDown() 方法时,其实使用了tryReleaseShared方法以 CAS 的操作来减少 state,直至 state 为 0 。 当调用 await() 方法的时候，如果 state 不为 0，那就证明任务还没有执行完毕，await() 方法就会一直阻塞，也就是说 await() 方法之后的语句不会被执行。 然后，CountDownLatch 会自旋 CAS 判断 state == 0，如果 state == 0 的话，就会释放所有等待的线程，await() 方法之后的语句得到执行。 1.6.1. CountDownLatch 的不足 CountDownLatch 是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当 CountDownLatch 使用完毕后，它不能再次被使用。 1.7. CyclicBarrier(循环栅栏) CountDownLatch 的实现是基于 AQS 的，而 CycliBarrier 是基于 ReentrantLock(ReentrantLock 也属于 AQS 同步器)和 Condition 的. 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"1.JAVA基础/并发编程/6.阻塞队列.html":{"url":"1.JAVA基础/并发编程/6.阻塞队列.html","title":"6.阻塞队列","keywords":"","body":"1.1. 简介1.2. 为什么用？好处？1.3. BlockingQueue核心方法1.3.1. SychronousQueue1.1. 简介 ArrayBlockingQueue 一个基于数组的有界阻塞队列，此队列按照FIFO原则对元素进行排序 LinkedBlockingQueue 一个基于链表的有界阻塞队列，此队列按照FIFO原则对元素进行排序，吞吐量通常高于ArrayBlockingQueue，（但大小默认值为Integer.MAX_VALUE) SynchronousQueue 一个不存储元素的队列，每插入一个元素必须等待另一个线程进行移除，否则再次插入会阻塞状态 PriorityBlockingQueue:支持优先级排序的无界阻塞队列。 DelayQueue:使用优先级队列实现的延迟无界阻塞队列。 LinkedTransferQueue:由链表结构组成的无界阻塞队列。 LinkedBlockingDeque:由历览表结构组成的双向阻塞队列。 1.2. 为什么用？好处？ 多线程领域，阻塞是在某种情况下挂起线程，满足条件挂起线程会进行自动唤醒 不需要关注什么时候唤醒阻塞线程 1.3. BlockingQueue核心方法 方法类型 抛出异常 特殊值 阻塞 超时 插入 add(e) offer(e) put(e) offer(e,time,unit) 移除 remove() poll() take poll(time,unit) 检查 element() peek() 不可用 不可用 方法类型 status 抛出异常 当阻塞队列满时，再往队列中add会抛IllegalStateException: Queue full当阻塞队列空时，在网队列里remove会抛NoSuchElementException 特殊值 插入方法，成功true失败false移除方法，成功返回出队列的元素，队列里没有就返回null 一直阻塞 当阻塞队列满时，生产者线程继续往队列里put元素，队列会一直阻塞线程知道put数据或响应中断退出当阻塞队列空时，消费者线程试图从队列take元素，队列会一直阻塞消费者线程知道队列可用。 超时退出 当阻塞队列满时，队列会阻塞生产者线程一定时间，超过限时后生产者线程会退出 1.3.1. SychronousQueue 理论：SynchronousQueue没有容量，与其他BlockingQueue不同，SychronousQueue是一个不存储元素的BlockingQueue，每一个put操作必须要等待一个take操作，否则不能继续添加元素，反之亦然。 代码示例 package com.jian8.juc.queue; import java.util.concurrent.BlockingQueue; import java.util.concurrent.SynchronousQueue; import java.util.concurrent.TimeUnit; /** * ArrayBlockingQueue是一个基于数组结构的有界阻塞队列，此队列按FIFO原则对元素进行排序 * LinkedBlockingQueue是一个基于链表结构的阻塞队列，此队列按FIFO排序元素，吞吐量通常要高于ArrayBlockingQueue * SynchronousQueue是一个不存储元素的阻塞队列，灭个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于 * 1.队列 * 2.阻塞队列 * 2.1 阻塞队列有没有好的一面 * 2.2 不得不阻塞，你如何管理 */ public class SynchronousQueueDemo { public static void main(String[] args) throws InterruptedException { BlockingQueue blockingQueue = new SynchronousQueue<>(); new Thread(() -> { try { System.out.println(Thread.currentThread().getName() + \"\\t put 1\"); blockingQueue.put(\"1\"); System.out.println(Thread.currentThread().getName() + \"\\t put 2\"); blockingQueue.put(\"2\"); System.out.println(Thread.currentThread().getName() + \"\\t put 3\"); blockingQueue.put(\"3\"); } catch (InterruptedException e) { e.printStackTrace(); } }, \"AAA\").start(); new Thread(() -> { try { TimeUnit.SECONDS.sleep(5); System.out.println(Thread.currentThread().getName() + \"\\ttake \" + blockingQueue.take()); TimeUnit.SECONDS.sleep(5); System.out.println(Thread.currentThread().getName() + \"\\ttake \" + blockingQueue.take()); TimeUnit.SECONDS.sleep(5); System.out.println(Thread.currentThread().getName() + \"\\ttake \" + blockingQueue.take()); } catch (InterruptedException e) { e.printStackTrace(); } }, \"BBB\").start(); } } 使用场景 生产者消费者模式 传统版本 package com.jian8.juc.queue; import java.util.concurrent.locks.Condition; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; /** * 一个初始值为零的变量，两个线程对其交替操作，一个加1一个减1，来5轮 * 1. 线程 操作 资源类 * 2. 判断 干活 通知 * 3. 防止虚假唤起机制 */ public class ProdConsumer_TraditionDemo { public static void main(String[] args) { ShareData shareData = new ShareData(); for (int i = 1; i { try { shareData.increment(); } catch (Exception e) { e.printStackTrace(); } }, \"ProductorA \" + i).start(); } for (int i = 1; i { try { shareData.decrement(); } catch (Exception e) { e.printStackTrace(); } }, \"ConsumerA \" + i).start(); } for (int i = 1; i { try { shareData.increment(); } catch (Exception e) { e.printStackTrace(); } }, \"ProductorB \" + i).start(); } for (int i = 1; i { try { shareData.decrement(); } catch (Exception e) { e.printStackTrace(); } }, \"ConsumerB \" + i).start(); } } } class ShareData {//资源类 private int number = 0; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public void increment() throws Exception { lock.lock(); try { //1.判断 while (number != 0) { //等待不能生产 condition.await(); } //2.干活 number++; System.out.println(Thread.currentThread().getName() + \"\\t\" + number); //3.通知 condition.signalAll(); } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } } public void decrement() throws Exception { lock.lock(); try { //1.判断 while (number == 0) { //等待不能消费 condition.await(); } //2.消费 number--; System.out.println(Thread.currentThread().getName() + \"\\t\" + number); //3.通知 condition.signalAll(); } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } } } 使用阻塞队列 package com.jian8.juc.queue; import java.util.concurrent.ArrayBlockingQueue; import java.util.concurrent.BlockingQueue; import java.util.concurrent.TimeUnit; import java.util.concurrent.atomic.AtomicInteger; public class ProdConsumer_BlockQueueDemo { public static void main(String[] args) { MyResource myResource = new MyResource(new ArrayBlockingQueue<>(10)); new Thread(() -> { System.out.println(Thread.currentThread().getName() + \"\\t生产线程启动\"); try { myResource.myProd(); } catch (Exception e) { e.printStackTrace(); } }, \"Prod\").start(); new Thread(() -> { System.out.println(Thread.currentThread().getName() + \"\\t消费线程启动\"); try { myResource.myConsumer(); } catch (Exception e) { e.printStackTrace(); } }, \"Consumer\").start(); try { TimeUnit.SECONDS.sleep(5); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"5s后main叫停，线程结束\"); try { myResource.stop(); } catch (Exception e) { e.printStackTrace(); } } } class MyResource { private volatile boolean flag = true;//默认开启，进行生产+消费 private AtomicInteger atomicInteger = new AtomicInteger(); BlockingQueue blockingQueue = null; public MyResource(BlockingQueue blockingQueue) { this.blockingQueue = blockingQueue; System.out.println(blockingQueue.getClass().getName()); } public void myProd() throws Exception { String data = null; boolean retValue; while (flag) { data = atomicInteger.incrementAndGet() + \"\"; retValue = blockingQueue.offer(data, 2, TimeUnit.SECONDS); if (retValue) { System.out.println(Thread.currentThread().getName() + \"\\t插入队列\" + data + \"成功\"); } else { System.out.println(Thread.currentThread().getName() + \"\\t插入队列\" + data + \"失败\"); } TimeUnit.SECONDS.sleep(1); } System.out.println(Thread.currentThread().getName() + \"\\t大老板叫停了，flag=false，生产结束\"); } public void myConsumer() throws Exception { String result = null; while (flag) { result = blockingQueue.poll(2, TimeUnit.SECONDS); if (null == result || result.equalsIgnoreCase(\"\")) { flag = false; System.out.println(Thread.currentThread().getName() + \"\\t超过2s没有取到蛋糕，消费退出\"); System.out.println(); return; } System.out.println(Thread.currentThread().getName() + \"\\t消费队列\" + result + \"成功\"); } } public void stop() throws Exception { flag = false; } } 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"1.JAVA基础/并发编程/7.Synchronized与锁升级.html":{"url":"1.JAVA基础/并发编程/7.Synchronized与锁升级.html","title":"7.Synchronized与锁升级","keywords":"","body":"1.1. 应用方式1.1.1. 普通同步方法1.1.2. 静态同步方法1.1.3. 代码块1.2. synchronized底层原理1.2.1. 代码块同步是使用monitorenter 和 monitorexit 指令实现1.2.2. 对象头结构1.2.3. 同步方法由方法调用指令读取运行时常量池中方法的 ACC_SYNCHRONIZED 标志来隐式实现的1.3. synchronized的优化(锁升级)1.3.1. 偏向锁1.3.2. 轻量级锁1.3.3. 重量级锁1.3.4. 优缺点对比1.4. 锁粗化1.5. 锁消除1.1. 应用方式 普通同步方法，锁是当前的实例对象 静态同步方法，锁是是当前类的class对象 对于同步方法块，锁是synchronized括号中的对象 1.1.1. 普通同步方法 public class AccountingSync implements Runnable{ //共享资源(临界资源) static int i=0; /** * synchronized 修饰实例方法 */ public synchronized void increase(){ i++; } @Override public void run() { for(int j=0;j 普通同步方法锁的为当前实例对象 当一个线程正在访问一个对象的 synchronized 实例方法，那么其他线程不能访问该对象的其他 synchronized 方法，对象只有一把锁，当一个线程获取了该对象的锁之后，其他线程无法获取该对象的锁，所以无法访问该对象的其他synchronized实例方法 但是其他线程还是可以访问该实例对象的其他非synchronized方法，当然如果是一个线程 A 需要访问实例对象 obj1 的 synchronized 方法 f1(当前对象锁是obj1)，另一个线程 B 需要访问实例对象 obj2 的 synchronized 方法 f2(当前对象锁是obj2)，这样是允许的，因为两个实例对象锁并不同相同 此时如果两个线程操作数据并非共享的，线程安全是有保障的，如果两个线程操作的是共享数据，那么线程并发不安全 1.1.2. 静态同步方法 当synchronized作用于静态方法时，其锁就是当前类的class对象锁。 由于静态成员不专属于任何一个实例对象，是类成员，因此通过class对象锁可以控制静态成员的并发操作。 需要注意的是如果一个线程A调用一个实例对象的非static synchronized方法，而线程B需要调用这个实例对象所属类的静态 synchronized方法，是允许的，不会发生互斥现象， 因为访问静态 synchronized 方法占用的锁是当前类的class对象，而访问非静态 synchronized 方法占用的锁是当前实例对象锁 1.1.3. 代码块 synchronized(this) 当括号内为对象实例时，锁的是对象实例 synchronized(AccountingSync.class) 如果为class，则锁的class对象 1.2. synchronized底层原理 JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用monitorenter 和monitorexit指令实现的，而方法同步是使用ACC_SYNCHRONIZED进行实现 1.2.1. 代码块同步是使用monitorenter 和 monitorexit 指令实现 monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处 JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter 指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁 public class SyncCodeBlock { public int i; public void syncTask(){ //同步代码库 synchronized (this){ i++; } } } 进行反编译上述代码: Classfile /Users/zejian/Downloads/Java8_Action/src/main/java/com/zejian/concurrencys/SyncCodeBlock.class Last modified 2017-6-2; size 426 bytes MD5 checksum c80bc322c87b312de760942820b4fed5 Compiled from \"SyncCodeBlock.java\" public class com.zejian.concurrencys.SyncCodeBlock minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPER Constant pool: //........省略常量池中数据 //构造函数 public com.zejian.concurrencys.SyncCodeBlock(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"\":()V 4: return LineNumberTable: line 7: 0 //===========主要看看syncTask方法实现================ public void syncTask(); descriptor: ()V flags: ACC_PUBLIC Code: stack=3, locals=3, args_size=1 0: aload_0 1: dup 2: astore_1 3: monitorenter //注意此处，进入同步方法 4: aload_0 5: dup 6: getfield #2 // Field i:I 9: iconst_1 10: iadd 11: putfield #2 // Field i:I 14: aload_1 15: monitorexit //注意此处，退出同步方法 16: goto 24 19: astore_2 20: aload_1 21: monitorexit //注意此处，退出同步方法 22: aload_2 23: athrow 24: return Exception table: //省略其他字节码....... } SourceFile: \"SyncCodeBlock.java\" 从字节码中可知同步语句块的实现使用的是 monitorenter 和 monitorexit 指令 其中monitorenter指令指向同步代码块的开始位置，monitorexit指令则指明同步代码块的结束位置，当执行monitorenter指令时，当前线程将试图获取 objectref(即对象锁) 所对应的 monitor 的持有权 当 objectref 的 monitor 的进入计数器为 0，那线程可以成功取得 monitor，并将计数器值设置为 1，取锁成功。 如果当前线程已经拥有 objectref 的 monitor 的持有权，那它可以重入这个 monitor (关于重入性稍后会分析)，重入时计数器的值也会加 1。 倘若其他线程已经拥有 objectref 的 monitor 的所有权，那当前线程将被阻塞，直到正在执行线程执行完毕，即monitorexit指令被执行，执行线程将释放 monitor(锁)并设置计数器值为0 ，其他线程将有机会持有 monitor 值得注意的是编译器将会确保无论方法通过何种方式完成，方法中调用过的每条 monitorenter 指令都有执行其对应 monitorexit 指令，而无论这个方法是正常结束还是异常结束。为了保证在方法异常完成时 monitorenter 和 monitorexit 指令依然可以正确配对执行，编译器会自动产生一个异常处理器，这个异常处理器声明可处理所有的异常，它的目的就是用来执行 monitorexit 指令。从字节码中也可以看出多了一个monitorexit指令，它就是异常结束时被执行的释放monitor的指令。 1.2.2. 对象头结构 1.2.3. 同步方法由方法调用指令读取运行时常量池中方法的 ACC_SYNCHRONIZED 标志来隐式实现的 方法级的同步是隐式，即无需通过字节码指令来控制的，它实现在方法调用和返回操作之中。JVM可以从方法常量池中的方法表结构(method_info Structure) 中的 ACC_SYNCHRONIZED 访问标志区分一个方法是否同步方法。 当方法调用时，调用指令将会 检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置 如果设置了，执行线程将先持有monitor（虚拟机规范中用的是管程一词）， 然后再执行方法，最后再方法完成(无论是正常完成还是非正常完成)时释放monitor。 在方法执行期间，执行线程持有了monitor，其他任何线程都无法再获得同一个monitor。 如果一个同步方法执行期间抛出了异常，并且在方法内部无法处理此异常，那这个同步方法所持有的monitor将在异常抛到同步方法之外时自动释放。 public class SyncMethod { public int i; public synchronized void syncTask(){ i++; } } Classfile /Users/zejian/Downloads/Java8_Action/src/main/java/com/zejian/concurrencys/SyncMethod.class Last modified 2017-6-2; size 308 bytes MD5 checksum f34075a8c059ea65e4cc2fa610e0cd94 Compiled from \"SyncMethod.java\" public class com.zejian.concurrencys.SyncMethod minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPER Constant pool; //省略没必要的字节码 //==================syncTask方法====================== public synchronized void syncTask(); descriptor: ()V //方法标识ACC_PUBLIC代表public修饰，ACC_SYNCHRONIZED指明该方法为同步方法 flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=3, locals=1, args_size=1 0: aload_0 1: dup 2: getfield #2 // Field i:I 5: iconst_1 6: iadd 7: putfield #2 // Field i:I 10: return LineNumberTable: line 12: 0 line 13: 10 } SourceFile: \"SyncMethod.java\" synchronized修饰的方法并没有monitorenter指令和monitorexit指令， 取得代之的确实是ACC_SYNCHRONIZED标识，该标识指明了该方法是一个同步方法，JVM通过该ACC_SYNCHRONIZED访问标志来辨别一个方法是否声明为同步方法， 从而执行相应的同步调用。这便是synchronized锁在同步代码块和同步方法上实现的基本原理 1.3. synchronized的优化(锁升级) 锁的状态总共有四种，无锁状态、偏向锁、轻量级锁和重量级锁。随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级为重量级锁，但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级 1.3.1. 偏向锁 大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，因此为了减少同一线程获取锁(会涉及到一些CAS操作,耗时)的代价而引入偏向锁 偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提供程序的性能。 倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)，此时Mark Word 的结构变为轻量级锁的结构。 1.3.2. 轻量级锁 线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。 然后线程尝试使用 CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。 自旋锁长时间拿不到锁升级为重量级锁 轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。 1.3.3. 重量级锁 线程阻塞就完事 1.3.4. 优缺点对比 1.4. 锁粗化 通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽可能短，但是大某些情况下，一个程序对同一个锁不间断、高频地请求、同步与释放，会消耗掉一定的系统资源， 因为锁的讲求、同步与释放本身会带来性能损耗，这样高频的锁请求就反而不利于系统性能的优化了，虽然单次同步操作的时间可能很短。锁粗化就是告诉我们任何事情都有个度，有些情况下我们反而希望把很多次锁的请求合并成一个请求， 以降低短时间内大量锁请求、同步、释放带来的性能损耗 public void doSomethingMethod(){ synchronized(lock){ //do some thing } //这是还有一些代码，做其它不需要同步的工作，但能很快执行完毕 synchronized(lock){ //do other thing } } 上面的代码是有两块需要同步操作的，但在这两块需要同步操作的代码之间，需要做一些其它的工作，而这些工作只会花费很少的时间， 那么我们就可以把这些工作代码放入锁内，将两个同步代码块合并成一个，以降低多次锁请求、同步、释放带来的系统性能消耗，合并后的代码如下: public void doSomethingMethod(){ //进行锁粗化：整合成一次锁请求、同步、释放 synchronized(lock){ //do some thing //做其它不需要同步但能很快执行完的工作 //do other thing } } 1.5. 锁消除 锁消除是发生在编译器级别的一种锁优化方式。 有时候我们写的代码完全不需要加锁，却执行了加锁操作。 比如，StringBuffer类的append操作： @Overridepublic synchronized StringBuffer append(String str) { toStringCache = null; super.append(str); return this; } 从源码中可以看出，append方法用了synchronized关键词，它是线程安全的。但我们可能仅在线程内部把StringBuffer当作局部变量使用： package com.leeib.thread; public class Demo { public static void main(String[] args) { long start = System.currentTimeMillis(); int size = 10000; for (int i = 0; i 代码中createStringBuffer方法中的局部对象sBuf，就只在该方法内的作用域有效，不同线程同时调用createStringBuffer()方法时，都会创建不同的sBuf对象，因此此时的append操作若是使用同步操作，就是白白浪费的系统资源。 这时我们可以通过编译器将其优化，将锁消除，前提是java必须运行在server模式（server模式会比client模式作更多的优化），同时必须开启逃逸分析: -server -XX:+DoEscapeAnalysis -XX:+EliminateLocks 其中+DoEscapeAnalysis表示开启逃逸分析，+EliminateLocks表示锁消除。 逃逸分析：比如上面的代码，它要看sBuf是否可能逃出它的作用域？如果将sBuf作为方法的返回值进行返回，那么它在方法外部可能被当作一个全局对象使用， 就有可能发生线程安全问题，这时就可以说sBuf这个对象发生逃逸了，因而不应将append操作的锁消除，但我们上面的代码没有发生锁逃逸，锁消除就可以带来一定的性能提升。 锁消除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行削除。锁削除的主要判定依据来源于逃逸分析的数据支持， 如果判断到一段代码中，在堆上的所有数据都不会逃逸出去被其他线程访问到，那就可以把它们当作栈上数据对待，认为它们是线程私有的，同步加锁自然就无须进行 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"1.JAVA基础/并发编程/8.Synchronized与ReentrantLock.html":{"url":"1.JAVA基础/并发编程/8.Synchronized与ReentrantLock.html","title":"8.Synchronized与ReentrantLock","keywords":"","body":"1.1. Synchronized与ReentrantLock区别1.1. Synchronized与ReentrantLock区别 原始构成 synchronized时关键字属于jvm monitorenter，monitorexit 底层是通过monitor对象来完成，其实wait/notify等方法也依赖于monitor对象,只有在同步或方法中才能使用wait/notify等方法 Lock是具体类，是api层面的锁（java.util.） 使用方法 sychronized不需要用户取手动释放锁，当synchronized代码执行完后系统会自动让线程释放对锁的占用 ReentrantLock则需要用户去手动释放锁若没有主动释放锁，就有可能导致出现死锁现象，需要lock()和unlock()方法配合try/finally语句块来完成 等待是否可中断 synchronized不可中断，除非抛出异常或者正常运行完成 ReentrantLock可中断，设置超时方法tryLock(long timeout, TimeUnit unit)，或者lockInterruptibly()放代码块中，调用interrupt()方法可中断。 加锁是否公平 synchronized非公平锁 ReentrantLock两者都可以，默认公平锁，构造方法可以传入boolean值，true为公平锁，false为非公平锁 锁绑定多个条件Condition synchronized没有 ReentrantLock用来实现分组唤醒需要要唤醒的线程们，可以精确唤醒，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程。 package com.jian8.juc.lock; import java.util.concurrent.locks.Condition; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; /** * synchronized和lock区别 * B>C三个线程启动，要求如下： * AA打印5次，BB打印10次，CC打印15次 * 紧接着 * AA打印5次，BB打印10次，CC打印15次 * 。。。。 * 来十轮 */ public class SyncAndReentrantLockDemo { public static void main(String[] args) { ShareData shareData = new ShareData(); new Thread(() -> { for (int i = 1; i { for (int i = 1; i { for (int i = 1; i 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"1.JAVA基础/并发编程/9.ThreadPoolExecutor.html":{"url":"1.JAVA基础/并发编程/9.ThreadPoolExecutor.html","title":"9.ThreadPoolExecutor","keywords":"","body":"1.1. 创建线程的四种方式1.2. Callable接口1.3. 线程池的特点和作用1.4. 如何使用1.4.1. 不推荐的创建方式：1.4.2. 推荐，自定义线程池：1.4.3. 如何配置合理的线程池参数1.1. 创建线程的四种方式 Runnabel接口 继承Thread Callable接口 ThreadPoolExecutor 1.2. Callable接口 好处，有返回值 package com.jian8.juc.thread; import java.util.concurrent.Callable; import java.util.concurrent.ExecutionException; import java.util.concurrent.FutureTask; import java.util.concurrent.TimeUnit; /** * 多线程中，第三种获得多线程的方式 */ public class CallableDemo { public static void main(String[] args) throws ExecutionException, InterruptedException { //FutureTask(Callable callable) FutureTask futureTask = new FutureTask(new MyThread2()); new Thread(futureTask, \"AAA\").start(); // new Thread(futureTask, \"BBB\").start();//复用，直接取值，不要重启两个线程 int a = 100; int b = 0; //b = futureTask.get();//要求获得Callable线程的计算结果，如果没有计算完成就要去强求，会导致堵塞，直到计算完成 while (!futureTask.isDone()) {//当futureTask完成后取值 b = futureTask.get(); } System.out.println(\"*******Result\" + (a + b)); } } class MyThread implements Runnable { @Override public void run() { } } class MyThread2 implements Callable { @Override public Integer call() throws Exception { System.out.println(\"Callable come in\"); try { TimeUnit.SECONDS.sleep(5); } catch (InterruptedException e) { e.printStackTrace(); } return 1024; } } 1.3. 线程池的特点和作用 线程池做的工作主要是控制运行的线程的数量，处理过程中将任务放入队列，然后在线程创建后启动给这些任务，如果线程数量超过了最大数量，超出数量的线程排队等候，等其他线程执行完毕，再从队列中取出任务来执行 主要特点 线程复用、控制最大并发数、管理线程 降低资源消耗，通过重复利用已创建的线程降低线程创建和销毁造成的消耗 提过响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行 提高线程的客观理想。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控 1.4. 如何使用 1.4.1. 不推荐的创建方式： 实现有五种，Executors.newScheduledThreadPool()是带时间调度的，java8新推出Executors.newWorkStealingPool(int),使用目前机器上可用的处理器作为他的并行级别 重点有三种 Executors.newFixedThreadPool(int) 执行长期的任务，性能好很多 创建一个定长线程池，可控制线程最大并发数，炒出的线程回在队列中等待。 newFixedThreadPool创建的线程池corePoolSize和maximumPoolSize值是想到等的，他使用的是LinkedBlockingQueue Executors.newSingleThreadExecutor() 一个任务一个任务执行的场景 创建一个单线程话的线程池，他只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序执行 newSingleThreadExecutor将corePoolSize和maximumPoolSize都设置为1，使用LinkedBlockingQueue Executors.newCachedThreadPool() 执行很多短期异步的小程序或负载较轻的服务器 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲县城，若无可回收，则新建线程。 newCachedThreadPool将corePoolSize设置为0，将maximumPoolSize设置为Integer.MAX_VALUE,使用的SynchronousQueue,也就是说来了任务就创建线程运行，当县城空闲超过60s，就销毁线程 1.4.2. 推荐，自定义线程池： ThreadPollExecutor的七个参数 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) ==corePoolSize==：线程池中常驻核心线程数 在创建了线程池后，当有请求任务来之后，就会安排池中的线程去执行请求任务 当线程池的线程数达到corePoolSize后，就会把到达的任务放到缓存队列当中 ==maximumPoolSize==：线程池能够容纳同时执行的最大线程数，必须大于等于1 ==keepAliveTime==：多余的空闲线程的存活时间 当前线程池数量超过corePoolSize时，档口空闲时间达到keepAliveTime值时，多余空闲线程会被销毁到只剩下corePoolSize个线程为止 ==unit==：keepAliveTime的单位 ==workQueue==：任务队列，被提交但尚未被执行的任务 ==threadFactory==：表示生成线程池中工作线程的线程工厂，用于创建线程一般用默认的即可 ==handler==：拒绝策略，表示当队列满了并且工作线程大于等于线程池的最大线程数（maximumPoolSize）时如何来拒绝请求执行的runable的策略 线程池的工作流程 在创建了线程池之后，等待提交过来的任务请求。 当调用execute()方法添加一个请求任务时，线程池会做出如下判断 2.1 如果正在运行的线程数量小于corePoolSize，那么马上运行线程运行这个任务； 2.2 如果正在运行的线程数量大于或等于corePoolSize，那么将这个任务放入队列； 2.3如果此时队列满了且运行的线程数小于maximumPoolSize，那么还是要创建非核心线程立刻运行此任务 2.4如果队列满了且正在运行的线程数量大于或等于maxmumPoolSize，那么启动饱和拒绝策略来执行 当一个线程完成任务时，他会从队列中却下一个任务来执行 当一个线程无事可做超过一定的时间（keepAliveTime）时，线程池会判断： 如果当前运行的线程数大于corePoolSize，那么这个线程会被停掉；所以线程池的所有任务完成后他最大会收缩到corePoolSize的大小 1.4.3. 如何配置合理的线程池参数 1、线程池的拒绝策略 什么是线程策略 等待队列也已经排满了，再也塞不下新任务了，同时线程池中的max线程也达到了，无法继续为新任务服务。这时我们就需要拒绝策略机制合理的处理这个问题。 JDK内置的拒绝策略 AbortPolicy(默认) 直接抛出RejectedExecutionException异常阻止系统正常运行 CallerRunsPolicy ”调用者运行“一种调节机制，该策略既不会抛弃任务，也不会抛出异常，而是将某些任务回退到调用者，从而降低新任务的流量 DiscardOldestPolicy 抛弃队列中等待最久的任务，然后把当前任务加入队列中尝试再次提交当前任务 DiscardPolicy 直接丢弃任务，不予任何处理也不抛异常。如果允许任务丢失，这是最好的一种方案 均实现了RejectedExecutionHandler接口 2、你在工作中单一的/固定数的/可变的三种创建线程池的方法，用哪个多 ==一个都不用，我们生产上只能使用自定义的！！！！== 为什么？ 线程池不允许使用Executors创建，试试通过ThreadPoolExecutor的方式，规避资源耗尽风险 FixedThreadPool和SingleThreadPool允许请求队列长度为Integer.MAX_VALUE，可能会堆积大量请求；；CachedThreadPool和ScheduledThreadPool允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量线程，导致OOM 3、你在工作中时如何使用线程池的，是否自定义过线程池使用 package com.jian8.juc.thread; import java.util.concurrent.*; /** * 第四种获得java多线程的方式--线程池 */ public class MyThreadPoolDemo { public static void main(String[] args) { ExecutorService threadPool = new ThreadPoolExecutor(3, 5, 1L, TimeUnit.SECONDS, new LinkedBlockingDeque<>(3), Executors.defaultThreadFactory(), new ThreadPoolExecutor.DiscardPolicy()); //new ThreadPoolExecutor.AbortPolicy(); //new ThreadPoolExecutor.CallerRunsPolicy(); //new ThreadPoolExecutor.DiscardOldestPolicy(); //new ThreadPoolExecutor.DiscardPolicy(); try { for (int i = 1; i { System.out.println(Thread.currentThread().getName() + \"\\t办理业务\"); }); } } catch (Exception e) { e.printStackTrace(); } finally { threadPool.shutdown(); } } } 4、合理配置线程池你是如何考虑的？ 当前程序可以使用当前机器的所有资源 CPU密集型 CPU密集的意思是该任务需要大量的运算，而没有阻塞，CPU一直全速运行 CPU密集任务只有在真正多核CPU上才可能得到加速（通过多线程） 而在单核CPU上，无论你开几个模拟的多线程该任务都不可能得到加速，因为CPU总的运算能力就那些 CPU密集型任务配置尽可能少的线程数量： ==一般公式：CPU核数+1个线程的线程池== IO密集型 由于IO密集型任务线程并不是一直在执行任务，则应配置经可能多的线程，如CPU核数 * 2 IO密集型，即该任务需要大量的IO，即大量的阻塞。 在单线程上运行IO密集型的任务会导致浪费大量的 CPU运算能力浪费在等待。 所以在IO密集型任务中使用多线程可以大大的加速程序运行，即使在单核CPU上，这种加速主要就是利用了被浪费掉的阻塞时间。 IO密集型时，大部分线程都阻塞，故需要多配置线程数： 参考公式：==CPU核数/（1-阻塞系数） 阻塞系数在0.8~0.9之间== 八核CPU：8/（1-0.9）=80 当前程序不可以使用所有机器资源 核心思想：压测 例： 假如一个服务有n个接口，而其中有a、b两个核心接口需要使用线程池，qps总占比60% a接口占比40%，则分配2/5的资源 b接口占比20%，则分配1/5的资源 如何确定最大线程数？ 最大线程数需要贴合实际，需要考虑其他接口的最大qps和本机的live线程数 如何确定核心线程数？ 初次压测设置和核心线程数一样大，测试最大并发的情况 压测撑的住，那么直接调小核心线程数就行 撑不住，调整queue，不使用无界队列，会无限积压请求，导致oom。同样不推荐Integer.max_value 具体：一小时的访问数量 减去 一小时接口能处理的请求数量）* 150% 案例情况：如果按照上述调整后没有达到预期？ 调大阻塞队列，好处：不影响其他接口 坏处：当前线程只是等待，而不是不可用 如果不同意阻塞，服务拆分接口异步化，缓存优化，db访问优化 添加节点，空间换时间 总结： 先按照接口请求比例设置占用最大线程数 按照压测情况，适当设置核心线程数 按照最大情况，留出一定的等待队列阈值 饱和策略： a. 按照具体情况具体分析 ⅰ. 不重要丢弃 ⅱ. 日志记录，持久化机制策略都可以。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"1.JAVA基础/并发编程/x.DeadLock.html":{"url":"1.JAVA基础/并发编程/x.DeadLock.html","title":"x.DeadLock","keywords":"","body":"1.1. 死锁编码及定位分析1.1.1. 是什么1.1.2. 产生死锁的主要原因1.1.3. 死锁示例1.1.4. 解决1.1. 死锁编码及定位分析 1.1.1. 是什么 死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力干涉那他们都将无法推进下去，如果系统资源充足，进程的资源请求都能够得到满足，死锁出现的可能性就很低，否则就会因争夺有限的资源而陷入死锁。 graph TD threadA(线程A) threadB(线程B) lockA((锁A)) lockB((锁B)) threadA--持有-->lockA threadB--试图获取-->lockA threadB--持有-->lockB threadA--试图获取-->lockB 1.1.2. 产生死锁的主要原因 系统资源不足 进程运行推进的顺序不合适 资源分配不当 1.1.3. 死锁示例 package com.jian8.juc.thread; import java.util.concurrent.TimeUnit; /** * 死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力干涉那他们都将无法推进下去， */ public class DeadLockDemo { public static void main(String[] args) { String lockA = \"lockA\"; String lockB = \"lockB\"; new Thread(new HoldThread(lockA,lockB),\"Thread-AAA\").start(); new Thread(new HoldThread(lockB,lockA),\"Thread-BBB\").start(); } } class HoldThread implements Runnable { private String lockA; private String lockB; public HoldThread(String lockA, String lockB) { this.lockA = lockA; this.lockB = lockB; } @Override public void run() { synchronized (lockA) { System.out.println(Thread.currentThread().getName() + \"\\t自己持有：\" + lockA + \"\\t尝试获得：\" + lockB); try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (lockB) { System.out.println(Thread.currentThread().getName() + \"\\t自己持有：\" + lockB + \"\\t尝试获得：\" + lockA); } } } } 1.1.4. 解决 使用jps -l定位进程号 jstack 进程号找到死锁查看 如何避免死锁 避免多次加锁,尽量避免同一个线程对多个lock进行锁定,例如:主线程对a,b两个对象加锁,副线程同样对a,b两个线程加锁,就容易产生死锁 尽量保持相同的加锁顺序,如果多个线程需要对多个 Lock 进行锁定，则应该保证它们以相同的顺序请求加锁。比如上面的死锁程序，主线程先对 A 对象的 Lock 加锁，再对 B 对象的 Lock 加锁；而副线程则先对 B 对象的 Lock 加锁，再对 A 对象的 Lock 加锁。这种加锁顺序很容易形成嵌套锁定，进而导致死锁。如果让主线程、副线程按照相同的顺序加锁，就可以避免这个问题。 使用定时锁。程序在调用 acquire() 方法加锁时可指定 timeout 参数，该参数指定超过 timeout 秒后会自动释放对 Lock 的锁定，这样就可以解开死锁了。 死锁检测。死锁检测是一种依靠算法机制来实现的死锁预防机制，它主要是针对那些不可能实现按序加锁，也不能使用定时锁的场景的。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"1.JAVA基础/并发编程/x1.ThreadLocal.html":{"url":"1.JAVA基础/并发编程/x1.ThreadLocal.html","title":"x1.ThreadLocal","keywords":"","body":"1.1. ThreadLocal原理1.1.1. 源码分析1.2. 内存泄露问题1.2.1. 如何放置Entry实例导致内存泄露1.2.2. ThreadLocal正确的使用方法1.2.3. 总结1.2.4. 使用场景1.1. ThreadLocal原理 1.1.1. 源码分析 //ThreadLocal.java public T get() { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) { ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) { @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; } } return setInitialValue(); } ThreadLocalMap getMap(Thread t) { return t.threadLocals; } //Thread.java ThreadLocal.ThreadLocalMap threadLocals = null; 首先看get()方法得知，ThreadLocal并不存储数据，数据来源于ThreadLocalMap 每一个线程都会存储一个ThreadLocalMap,key 为ThreadLocal对象 好处：由于ThreadLocalMap由Thread维护，所以每个 Thread 只访问自己的 Map，那就不存在多线程写的问题，也就不需要锁 1.2. 内存泄露问题 Map 由 ThreadLocal 类的静态内部类 ThreadLocalMap 提供。该类的实例维护某个 ThreadLocal 与具体实例的映射。 与 HashMap 不同的是ThreadLocalMap 的每个 Entry 都是一个对key的弱引用，这一点从super(k)可看出。另外，每个 Entry 都包含了一个对value的强引用。 static class Entry extends WeakReference> { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal k, Object v) { super(k); value = v; } } 根据之前提到的jvm的四种引用类型得知：弱引用只要发生垃圾回收jvm都会对其进行回收，当没有强引用指向 ThreadLocal 变量时，它可被回收，从而避免上文所述 ThreadLocal 不能被回收而造成的内存泄漏的问题。 但是ThreadLocalMap 维护 ThreadLocal 变量与具体实例的映射，当 ThreadLocal 变量被回收后，该映射的键变为 null，该 Entry 无法被移除。从而使得实例被该 Entry 引用而无法被回收造成内存泄漏。 Entry虽然是弱引用，但它是 ThreadLocal 类型的弱引用（也即上文所述它是对 键 的弱引用），而非具体实例的的弱引用，所以无法避免具体实例相关的内存泄漏。 1.2.1. 如何放置Entry实例导致内存泄露 针对该问题，ThreadLocalMap 的 set 方法中，通过 replaceStaleEntry 方法将所有键为 null 的 Entry 的值设置为 null，从而使得该值可被回收。 另外，会在 rehash 方法中通过 expungeStaleEntry 方法将键和值为 null 的 Entry 设置为 null 从而使得该 Entry 可被回收。通过这种方式，ThreadLocal 可防止内存泄漏。 if (k == null) { replaceStaleEntry(key, value, i); return; } 1.2.2. ThreadLocal正确的使用方法 每次使用完ThreadLocal都调用它的remove()方法清除数据 将ThreadLocal变量定义成private static，这样就一直存在ThreadLocal的强引用，也就能保证任何时候都能通过ThreadLocal的弱引用访问到Entry的value值，进而清除掉 。 1.2.3. 总结 ThreadLocal 并不解决线程间共享数据的问题 ThreadLocal 通过隐式的在不同线程内创建独立实例副本避免了实例线程安全的问题 每个线程持有一个 Map 并维护了 ThreadLocal 对象与具体实例的映射，该 Map 由于只被持有它的线程访问，故不存在线程安全以及锁的问题 ThreadLocalMap 的 Entry 对 ThreadLocal 的引用为弱引用，避免了 ThreadLocal 对象无法被回收的问题 ThreadLocalMap 的 set 方法通过调用 replaceStaleEntry 方法回收键为 null 的 Entry 对象的值（即为具体实例）以及 Entry 对象本身从而防止内存泄漏 ThreadLocal 适用于变量在线程间隔离且在方法间共享的场景 1.2.4. 使用场景 每个线程需要有自己单独的实例 实例需要在多个方法中共享，但不希望被多线程共享 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"2.分布式/1.分布式事务.html":{"url":"2.分布式/1.分布式事务.html","title":"1.分布式事务","keywords":"","body":"一、两段式提交（2PC） 两阶段提交（Two-phase Commit，2PC），通过引入协调者（Coordinator）来协调参与者的行为，并最终决定这些参与者是否要真正执行事务。 两类节点：一个是中心化协调者节点（coordinator）和N个参与者节点（partcipant）。 两个阶段：第一阶段：投票阶段 和第二阶段：提交/执行阶段。 举例 订单服务A，需要调用 支付服务B 去支付，支付成功则处理购物订单为待发货状态，否则就需要将购物订单处理为失败状态。 1. 第一阶段：投票阶段 第一阶段主要分为3步 1）事务询问 协调者 向所有的 参与者 发送事务预处理请求，称之为Prepare，并开始等待各 参与者 的响应。 2）执行本地事务 各个 参与者 节点执行本地事务操作,但在执行完成后并不会真正提交数据库本地事务，而是先向 协调者 报告说：“我这边可以处理了/我这边不能处理”。. 3）各参与者向协调者反馈事务询问的响应 如果 参与者 成功执行了事务操作,那么就反馈给协调者 Yes 响应,表示事务可以执行,如果没有 参与者 成功执行事务,那么就反馈给协调者 No 响应,表示事务不可以执行。 第一阶段执行完后，会有两种可能。1、所有都返回Yes. 2、有一个或者多个返回No。 2. 第二阶段：提交/执行阶段（成功流程） 成功条件：所有参与者都返回Yes。 第二阶段主要分为两步 1)所有的参与者反馈给协调者的信息都是Yes,那么就会执行事务提交 协调者 向 所有参与者 节点发出Commit请求. 2)事务提交 参与者 收到Commit请求之后,就会正式执行本地事务Commit操作,并在完成提交之后释放整个事务执行期间占用的事务资源。 3. 第二阶段：提交/执行阶段（异常流程） 异常条件：任何一个 参与者 向 协调者 反馈了 No 响应,或者等待超时之后,协调者尚未收到所有参与者的反馈响应。 异常流程第二阶段也分为两步 1)发送回滚请求 协调者 向所有参与者节点发出 RoollBack 请求. 2)事务回滚 参与者 接收到RoollBack请求后,会回滚本地事务。 2PC的缺点 1）性能问题 无论是在第一阶段的过程中,还是在第二阶段,所有的参与者资源和协调者资源都是被锁住的,只有当所有节点准备完毕，事务 协调者 才会通知进行全局提交， 参与者 进行本地事务提交后才会释放资源。这样的过程会比较漫长，对性能影响比较大。 2）单节点故障 由于协调者的重要性，一旦 协调者 发生故障。参与者 会一直阻塞下去。尤其在第二阶段，协调者 发生故障，那么所有的 参与者 还都处于 锁定事务资源的状态中，而无法继续完成事务操作。（虽然协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题） 2PC出现单点问题的三种情况 (1)协调者正常,参与者宕机 由于 协调者 无法收集到所有 参与者 的反馈，会陷入阻塞情况。 解决方案:引入超时机制,如果协调者在超过指定的时间还没有收到参与者的反馈,事务就失败,向所有节点发送终止事务请求。 (2)协调者宕机,参与者正常 无论处于哪个阶段，由于协调者宕机，无法发送提交请求，所有处于执行了操作但是未提交状态的参与者都会陷入阻塞情况. 解决方案:引入协调者备份,同时协调者需记录操作日志.当检测到协调者宕机一段时间后，协调者备份取代协调者，并读取操作日志，向所有参与者询问状态。 (3)协调者和参与者都宕机 发生在第一阶段： 因为第一阶段，所有参与者都没有真正执行commit，所以只需重新在剩余的参与者中重新选出一个协调者，新的协调者在重新执行第一阶段和第二阶段就可以了。 2)发生在第二阶段 并且 挂了的参与者在挂掉之前没有收到协调者的指令。也就是上面的第4步挂了，这是可能协调者还没有发送第4步就挂了。这种情形下，新的协调者重新执行第一阶段和第二阶段操作。 3)发生在第二阶段 并且 有部分参与者已经执行完commit操作。就好比这里订单服务A和支付服务B都收到协调者 发送的commit信息，开始真正执行本地事务commit,但突发情况，Acommit成功，B确挂了。这个时候目前来讲数据是不一致的。虽然这个时候可以再通过手段让他和协调者通信，再想办法把数据搞成一致的，但是，这段时间内他的数据状态已经是不一致的了！ 2PC 无法解决这个问题。 二、TCC补偿事务 TCC 其实就是采用的补偿机制，其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。它分为三个阶段： Try 阶段主要是对业务系统做检测及资源预留 Confirm 阶段主要是对业务系统做确认提交，Try阶段执行成功并开始执行 Confirm阶段时，默认 Confirm阶段是不会出错的。即：只要Try成功，Confirm一定成功。 Cancel 阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放。 举个例子，假入 Bob 要向 Smith 转账，思路大概是： 我们有一个本地方法，里面依次调用 首先在 Try 阶段，要先调用远程接口把 Smith 和 Bob 的钱给冻结起来。 在 Confirm 阶段，执行远程调用的转账的操作，转账成功进行解冻。 如果第2步执行成功，那么转账成功，如果第二步执行失败，则调用远程冻结接口对应的解冻方法 (Cancel)。 优点： 跟2PC比起来，实现以及流程相对简单了一些，但数据的一致性比2PC也要差一些 缺点： 缺点还是比较明显的，在2,3步中都有可能失败。TCC属于应用层的一种补偿方式，所以需要程序员在实现的时候多写很多补偿的代码，在一些场景中，一些业务流程可能用TCC不太好定义及处理。 三、事务性消息 具体参考mq->事务性消息 事务性消息 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"3.Mysql原理/1.索引失效和索引优化.html":{"url":"3.Mysql原理/1.索引失效和索引优化.html","title":"1.索引失效和索引优化","keywords":"","body":"1.1. 总结1.1.1. 索引失效1.2. 示例：1.1. 总结 1.1.1. 索引失效 LOL +-*/ L : Like导致的失效%like会导致失效like%不会失效，因为前模糊没办法确定具体要查询的数据，后模糊可以先定位第一条数据，后续加载页往后查找即可 O : or连接符导致失效，ab为一个联合索引，那么a or b会不会失效？ 不会失效。如果a，b有一个不是索引，那么会失效 L : 联合查询，a>3 and b >5不失效 b>5失效 ，联合查询必须从联合索引的第一个开始才不会导致在索引失效 +-*/ ： 算术运算会失效 not null not : age!=10索引失效，mysql非结果集都会导致索引失效 null : null不会构建进b+树索引导致索引失效，索引mysql字段值尽量not null，如果有可能为null的字段则设置为默认值 no method 使用mysql内置函数会导致s索引失效,比如concat等 no convert 假如一个字段为字符串，比如id使用varchar存储，where id = 12 ，这样索引会失效，mysql会自己调用convert函数去处理数字转换为字符串 mysql版本问题 mysql5.6 和 5.6 之前对一些sql处理有差异 select * from table where a > 3这种会产生回表，是否使用索引？ 5.6之前不会使用索引，直接扫表 5.6后使用索引，然后进行回表查询 1.2. 示例： create table t_user( id int primary key auto_increment, name varchar(24) not null default '' comment '姓名', age int not null default 0 comment '年龄', position varchar(50) not null default '' comment '职位', create_time timestamp not null default current_timestamp comment '入职时间' )charset utf8mb4 comment '员工记录表'; alter table t_user add index idx_name_age_pos(name,age,position); insert into t_user(name,age,position,create_time)VALUES ('z3',22,'manager',now()); insert into t_user(name,age,position,create_time)VALUES ('tom',23,'dev',now()); insert into t_user(name,age,position,create_time)VALUES ('2000',24,'dev',now()); 1. 查询的字段按照顺序在联合索引中都可以匹配到 explain select * from t_user where name = 'tom'; explain select * from t_user where name = 'tom' and age = 23; explain select * from t_user where name = 'tom' and age = 23 and position = 'dev'; #result [ { \"id\": 1, \"select_type\": \"SIMPLE\", \"table\": \"t_user\", \"partitions\": null, \"type\": \"ref\", \"possible_keys\": \"idx_name_age_pos\", \"key\": \"idx_name_age_pos\", \"key_len\": \"98\", \"ref\": \"const\", \"rows\": 1, \"filtered\": 100, \"Extra\": null } ] [ { \"id\": 1, \"select_type\": \"SIMPLE\", \"table\": \"t_user\", \"partitions\": null, \"type\": \"ref\", \"possible_keys\": \"idx_name_age_pos\", \"key\": \"idx_name_age_pos\", \"key_len\": \"102\", \"ref\": \"const,const\", \"rows\": 1, \"filtered\": 100, \"Extra\": null } ] [ { \"id\": 1, \"select_type\": \"SIMPLE\", \"table\": \"t_user\", \"partitions\": null, \"type\": \"ref\", \"possible_keys\": \"idx_name_age_pos\", \"key\": \"idx_name_age_pos\", \"key_len\": \"102\", \"ref\": \"const,const\", \"rows\": 1, \"filtered\": 100, \"Extra\": null } ] 2. 最左前缀法则 如果索引了多列，要遵守最左前缀法则，查询从索引的最左前列开始，并且不跳过索引中的列 如果中间断了，那么只有部分使用了索引，只有前面的字段使用了索引 explain select * from t_user where age = 23; explain select * from t_user where age = 23 and position = 'dev'; #result [ { \"id\": 1, \"select_type\": \"SIMPLE\", \"table\": \"t_user\", \"partitions\": null, \"type\": \"ALL\", \"possible_keys\": null, \"key\": null, \"key_len\": null, \"ref\": null, \"rows\": 2, \"filtered\": 50, \"Extra\": \"Using where\" } ] [ { \"id\": 1, \"select_type\": \"SIMPLE\", \"table\": \"t_user\", \"partitions\": null, \"type\": \"ALL\", \"possible_keys\": null, \"key\": null, \"key_len\": null, \"ref\": null, \"rows\": 2, \"filtered\": 50, \"Extra\": \"Using where\" } ] # 由上面可以看到因为跳过了索引的name字段而无法使用索引 # 但是如果仅仅是where的顺序不同则不会影响索引的使用，mysql会对sql进行优化 explain select * from t_user where age = 23 and position = 'dev' and name = 'tom'; # result [ { \"id\": 1, \"select_type\": \"SIMPLE\", \"table\": \"t_user\", \"partitions\": null, \"type\": \"ref\", \"possible_keys\": \"idx_name_age_pos\", \"key\": \"idx_name_age_pos\", \"key_len\": \"304\", \"ref\": \"const,const,const\", \"rows\": 1, \"filtered\": 100, \"Extra\": null } ] 3. 不在索引上做任何操作 explain select * from t_user where left(name,3) = 'tom'; # result [ { \"id\": 1, \"select_type\": \"SIMPLE\", \"table\": \"t_user\", \"partitions\": null, \"type\": \"ALL\", \"possible_keys\": null, \"key\": null, \"key_len\": null, \"ref\": null, \"rows\": 2, \"filtered\": 100, \"Extra\": \"Using where\" } ] # 由上可见，因为对name字段进行了操作，导致无法使用索引查询 4. 索引中范围条件右侧的列会全部失效 explain select * from t_user where name = 'tom' and age > 18 and position = 'dev'; # result [ { \"id\": 1, \"select_type\": \"SIMPLE\", \"table\": \"t_user\", \"partitions\": null, \"type\": \"range\", \"possible_keys\": \"idx_name_age_pos\", \"key\": \"idx_name_age_pos\", \"key_len\": \"102\", \"ref\": null, \"rows\": 1, \"filtered\": 50, \"Extra\": \"Using index condition\" } ] # 由上述结果可看到key_len = 102 ，说明索引只作用了 name 和 age字段，position字段并没有使用到索引 # key_len 是使用索引的字符长度 比如name是varchar（24）对应的key_len就是98 5. 尽量使用索引覆盖防止回表 explain select * from t_user where name = 'tom'; # result [ { \"id\": 1, \"select_type\": \"SIMPLE\", \"table\": \"t_user\", \"partitions\": null, \"type\": \"ref\", \"possible_keys\": \"idx_name_age_pos\", \"key\": \"idx_name_age_pos\", \"key_len\": \"98\", \"ref\": \"const\", \"rows\": 1, \"filtered\": 100, \"Extra\": null } ] # 查询的内容都存在索引中就可以避免回表 explain select name,age,position from t_user where name = 'tom'; # result [ { \"id\": 1, \"select_type\": \"SIMPLE\", \"table\": \"t_user\", \"partitions\": null, \"type\": \"ref\", \"possible_keys\": \"idx_name_age_pos\", \"key\": \"idx_name_age_pos\", \"key_len\": \"98\", \"ref\": \"const\", \"rows\": 1, \"filtered\": 100, \"Extra\": \"Using index\" } ] # 由上\"Extra\": \"Using index\"可以看出没有产生回表，数据都从索引中查询出来 # using index ：使用覆盖索引的时候就会出现 # using where：在查找使用索引的情况下，需要回表去查询所需的数据 # using index condition：查找使用了索引，但是需要回表查询数据 # using index & using where：查找使用了索引，但是需要的数据都在索引列中能找到，所以不需要回表查询数据 6. mysql 在使用不等于（!= ， <>，is null , not null）的时候无法使用索引导致全表扫描 explain select * from t_user where name != 'tom'; explain select * from t_user where name <> 'tom'; explain select * from t_user where name is null; explain select * from t_user where name is not null; # 以上四种查询都无法使用索引，直接导致索引失效 7. like以通配符%开头会导致索引失效变成全表扫描 %只有写在最右边的索引才会生效 explain select * from t_user where name like '%tom'; # result [ { \"id\": 1, \"select_type\": \"SIMPLE\", \"table\": \"t_user\", \"partitions\": null, \"type\": \"ALL\", \"possible_keys\": null, \"key\": null, \"key_len\": null, \"ref\": null, \"rows\": 2, \"filtered\": 50, \"Extra\": \"Using where\" } ] explain select * from t_user where name like 'tom%'; # result [ { \"id\": 1, \"select_type\": \"SIMPLE\", \"table\": \"t_user\", \"partitions\": null, \"type\": \"range\", \"possible_keys\": \"idx_name_age_pos\", \"key\": \"idx_name_age_pos\", \"key_len\": \"98\", \"ref\": null, \"rows\": 1, \"filtered\": 100, \"Extra\": \"Using index condition\" } ] # 由上可见，当like以%开头的时候会导致索引失效 解决like '%字符串%'时索引不被使用的方法？（使用覆盖索引解决） explain select name,age from t_user where name like '%tom%'; # result [ { \"id\": 1, \"select_type\": \"SIMPLE\", \"table\": \"t_user\", \"partitions\": null, \"type\": \"index\", \"possible_keys\": null, \"key\": \"idx_name_age_pos\", \"key_len\": \"304\", \"ref\": null, \"rows\": 2, \"filtered\": 50, \"Extra\": \"Using where; Using index\" } ] # 当使用索引覆盖的时候，like %***%，不会导致索引失效 8. 使用or连接会导致索引失效 9. 字符串查询不加单引号也会导致索引失效 10. 尽量选择区分度高的列作为索引 区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"3.Mysql原理/2.B+Tree与Innodb.html":{"url":"3.Mysql原理/2.B+Tree与Innodb.html","title":"2.B+Tree与Innodb","keywords":"","body":"为什么不使用哈希索引、平衡二叉树、B树？ 哈希索引： 没有办法范围查找和排序操作 如果多个值的哈希值相同，只能一个一个比较查询效率低 平衡二叉树： 树的高度会越来越高，查找速度越慢 范围查询会有回旋查找的现象，效率低 B树： 范围查询依然会有回旋查找的问题，查询效率低 b树每层都要存储具体的数据，那么三层结构存储的数据极低，查找一个数据需要产生大量的磁盘io 主键索引和辅助索引存储结构？ 主键索引（聚簇索引）在表中以 存储 在主键索引中，id 是主键，我们能够通过 id 找到该行的全部列 辅助索引（非聚簇索引）以进行存储，所以在(select *)查询中会出现回表的现象 在辅助索引中，索引中的几个列构成了键，我们能够通过索引中的列找到 id， 如果有需要的话，可以再通过 id 找到当前数据行的全部内容 mysql一张表大概能存储多少数据? mysql一个存储页是16k，假如一张表的parmary key的类型是bigint那么主键所占字节为8byte也就是64bit 而向下的索引指针是6byte，那么就是固定14byte的长度为一条数据 b+树根节点 = 16k = 16 1024byte = 16 1024 / 14 = 1170 个parmary key 因为根节点每条数据都会延申出一个节点，所以第二层的数据量为 1170 * 1170 而第三层存放的为具体的表数据，假如一条数据为1k，那么一个节点就是16条数据，那么最终计算出 1170 1170 16 = 21902400 条数据 所以在一条数据1k，并且主键为bigint的情况下mysql单表可以存储21902400条数据 调优：为什么要详细评估表的每个字段的长度 假如每个字段都是varchar(255)导致一条数据16k，那么mysql单表存储数据下降为 1170 1170 1 = 1368900，130万条数据 这样每次查找数据需要加载大量的内存页产生大量的磁盘io，效率极低 mysql查找的io和时间复杂度 mysql加载一页为一次io，假设b+树有3层，那么查到具体数据需要进行3次io 而每次取出页数据后，通过二分查找（ologn）找到下层的指针 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"3.Mysql原理/3.Mysql如何实现事务.html":{"url":"3.Mysql原理/3.Mysql如何实现事务.html","title":"3.Mysql如何实现事务","keywords":"","body":"1. 数据库如何实现事务？1.1. redo log1.1.1. redo log 有什么作用？1.2. undo log1.3. mysql锁技术1.4. MVCC1.5. 事务的实现1. 数据库如何实现事务？ mysql实现事务主要根据 undo log 和 redo log，锁技术和MVCC 1.1. redo log redo log叫做重做日志，是用来实现事务的持久性。该日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo log）,前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都会存到该日志中 1.1.1. redo log 有什么作用？ mysql 为了提升性能不会把每次的修改都实时同步到磁盘，而是会先存到Boffer Pool(缓冲池)里头，把这个当作缓存来用。然后使用后台线程去做缓冲池和磁盘之间的同步。 如果数据在Buffer Pool中未同步到data page中时，就需要使用redo log将提交的事务数据同步到sql表中 总结： redo log是用来恢复数据的 用于保障，已提交事务的持久化特性 1.2. undo log undo log 叫做回滚日志，用于记录数据被修改前的信息。他正好跟前面所说的重做日志所记录的相反，重做日志记录数据被修改后的信息。undo log主要记录的是数据的逻辑变化，为了在发生错误时回滚之前的操作，需要将之前的操作都记录下来，然后在发生错误时才可以回滚。 undo log记录的日志信息是反向操作信息，例如insert对应delete (1) 如果在回滚日志里有新增数据记录，则生成删除该条的语句 (2) 如果在回滚日志里有删除数据记录，则生成生成该条的语句 (3) 如果在回滚日志里有修改数据记录，则生成修改到原先数据的语句 总结： undo log是用来回滚数据的用于保障 未提交事务的原子性 1.3. mysql锁技术 共享锁(shared lock),又叫做\"读锁\" 读锁是可以共享的，或者说多个读请求可以共享一把锁读数据，不会造成阻塞。 排他锁(exclusive lock),又叫做\"写锁\" 写锁会排斥其他所有获取锁的请求，一直阻塞，直到写入完成释放锁。 总结： 通过读写锁，可以做到读读可以并行，但是不能做到写读，写写并行 事务的隔离性就是根据读写锁来实现,锁具体见mysql锁 1.4. MVCC MVCC (MultiVersion Concurrency Control) 叫做多版本并发控制。 MVCC 1.5. 事务的实现 前面讲的重做日志，回滚日志以及锁技术就是实现事务的基础。 事务的原子性是通过 undo log 来实现的 事务的持久性是通过 redo log 来实现的 事务的隔离性是通过 (读写锁+MVCC)来实现的 而事务的终极大 boss 一致性是通过原子性，持久性，隔离性来实现的！！！ 原子性，持久性，隔离性折腾半天的目的也是为了保障数据的一致性！ 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"3.Mysql原理/4.MVCC.html":{"url":"3.Mysql原理/4.MVCC.html","title":"4.MVCC","keywords":"","body":"1. MVCC多版本并发控制1.1. 什么是快照读？什么是当前读？1.1.1. 当前读1.1.2. 快照读1.1.3. 快照读与mvcc的关系1.2. 数据库并发场景1.3. MVCC解决并发哪些问题？1.3.1. MVCC的实现原理1.3.2. MVCC和事务隔离级别1. MVCC多版本并发控制 全称Multi-Version Concurrency Control，即多版本并发控制，主要是为了提高数据库的并发性能 同一行数据平时发生读写请求时，会上锁阻塞住。但mvcc用更好的方式去处理读—写请求，做到在发生读—写请求冲突时不用加锁。 这个读是指的快照读，而不是当前读，当前读是一种加锁操作，是悲观锁。 1.1. 什么是快照读？什么是当前读？ 1.1.1. 当前读 它读取的数据库记录，都是当前最新的版本，会对当前读取的数据进行加锁，防止其他事务修改数据。是悲观锁的一种操作。 如下操作都是当前读： select lock in share mode (共享锁) select for update (排他锁) update (排他锁) insert (排他锁) delete (排他锁) 串行化事务隔离级别 1.1.2. 快照读 快照读的实现是基于多版本并发控制，即MVCC，既然是多版本，那么快照读读到的数据不一定是当前最新的数据，有可能是之前历史版本的数据。 如下操作是快照读： 不加锁的select操作（注：事务级别不是串行化） 1.1.3. 快照读与mvcc的关系 MVCC是“维持一个数据的多个版本，使读写操作没有冲突”的一个抽象概念。 1.2. 数据库并发场景 读-读：不存在任何问题，也不需要并发控制 读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读 写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失 1.3. MVCC解决并发哪些问题？ mvcc用来解决读—写冲突的无锁并发控制，就是为事务分配单向增长的时间戳。为每个数据修改保存一个版本，版本与事务时间戳相关联。 读操作只读取该事务开始前的数据库快照。 解决问题如下： 并发读-写时：可以做到读操作不阻塞写操作，同时写操作也不会阻塞读操作。 解决脏读、幻读、不可重复读等事务隔离问题，但不能解决上面的写-写 更新丢失问题。 因此有了下面提高并发性能的组合拳： MVCC + 悲观锁：MVCC解决读写冲突，悲观锁解决写写冲突 MVCC + 乐观锁：MVCC解决读写冲突，乐观锁解决写写冲突 1.3.1. MVCC的实现原理 它的实现原理主要是版本链，undolog ，Read View来实现的 版本链 我们数据库中的每行数据，除了我们肉眼看见的数据，还有几个隐藏字段，分别是db_trx_id、db_roll_pointer、db_row_id。 db_trx_id 6byte，最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的事务ID。 db_roll_pointer（版本链关键） 7byte，回滚指针，指向这条记录的上一个版本（存储于rollback segment里） db_row_id 6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以db_row_id产生一个聚簇索引。 实际还有一个删除flag隐藏字段, 记录被更新或删除并不代表真的删除，而是删除flag变了 如上图，db_row_id是数据库默认为该行记录生成的唯一隐式主键，db_trx_id是当前操作该记录的事务ID，而db_roll_pointer是一个回滚指针，用于配合undo日志，指向上一个旧版本。 每次对数据库记录进行改动，都会记录一条undo日志，每条undo日志也都有一个roll_pointer属性（INSERT操作对应的undo日志没有该属性，因为该记录并没有更早的版本），可以将这些undo日志都连起来，串成一个链表，所以现在的情况就像下图一样： 对该记录每次更新后，都会将旧值放到一条undo日志中，就算是该记录的一个旧版本，随着更新次数的增多，所有的版本都会被roll_pointer属性连接成一个链表，我们把这个链表称之为版本链，版本链的头节点就是当前记录最新的值。另外，每个版本中还包含生成该版本时对应的事务id，这个信息很重要，在根据ReadView判断版本可见性的时候会用到。 Undo log Undo log 主要用于记录数据被修改之前的日志，在表信息修改之前先会把数据拷贝到undo log里。 当事务进行回滚时可以通过undo log 里的日志进行数据还原。 Undo log 的用途 保证事务进行rollback时的原子性和一致性，当事务进行回滚的时候可以用undo log的数据进行恢复。 用于MVCC快照读的数据，在MVCC多版本控制中，通过读取undo log的历史版本数据可以实现不同事务版本号都拥有自己独立的快照数据版本。 undo log主要分为两种： insert undo log 代表事务在insert新记录时产生的undo log , 只在事务回滚时需要，并且在事务提交后可以被立即丢弃 update undo log（主要） 事务在进行update或delete时产生的undo log ; 不仅在事务回滚时需要，在快照读时也需要； 所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除 Read View(读视图) 事务进行快照读操作的时候生产的读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照。 记录并维护系统当前活跃事务的ID(没有commit，当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以越新的事务，ID值越大)，是系统中当前不应该被本事务看到的其他事务id列表。 Read View主要是用来做可见性判断的, 即当我们某个事务执行快照读的时候，对该记录创建一个Read View读视图，把它比作条件用来判断当前事务能够看到哪个版本的数据，既可能是当前最新的数据，也有可能是该行记录的undo log里面的某个版本的数据。 Read View几个属性 trx_ids: 当前系统活跃(未提交)事务版本号集合。 low_limit_id: 创建当前read view 时“当前系统最大事务版本号+1”。 up_limit_id: 创建当前read view 时“系统正处于活跃事务最小版本号” creator_trx_id: 创建当前read view的事务版本号； Read View可见性判断条件(判断当前应该查询哪个快照) db_trx_id up_limit_id || db_trx_id == creator_trx_id（显示） 如果数据事务ID小于read view中的最小活跃事务ID，则可以肯定该数据是在当前事务启之前就已经存在了的,所以可以显示。 或者数据的事务ID等于creator_trx_id ，那么说明这个数据就是当前事务自己生成的，自己生成的数据自己当然能看见，所以这种情况下此数据也是可以显示的。 db_trx_id >= low_limit_id（不显示） 如果数据事务ID大于read view 中的当前系统的最大事务ID，则说明该数据是在当前read view 创建之后才产生的，所以数据不显示。如果小于则进入下一个判断 db_trx_id是否在活跃事务（trx_ids）中 不存在：则说明read view产生的时候事务已经commit了，这种情况数据则可以显示。 已存在：则代表我Read View生成时刻，你这个事务还在活跃，还没有Commit，你修改的数据，我当前事务也是看不见的。 1.3.2. MVCC和事务隔离级别 上面所讲的Read View用于支持RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）隔离级别的实现。 RR、RC生成时机 RC隔离级别下，是每个快照读都会生成并获取最新的Read View； 而在RR隔离级别下，则是同一个事务中的第一个快照读才会创建Read View, 之后的快照读获取的都是同一个Read View，之后的查询就不会重复生成了，所以一个事务的查询结果每次都是一样的。 解决幻读问题 快照读：通过MVCC来进行控制的，不用加锁。按照MVCC中规定的“语法”进行增删改查等操作，以避免幻读。 当前读：通过next-key锁（行锁+gap间隙锁）来解决问题的。 RC、RR级别下的InnoDB快照读区别 在RR级别下的某个事务的对某条记录的第一次快照读会创建一个快照及Read View， 将当前系统活跃的其他事务记录起来，此后在调用快照读的时候，还是使用的是同一个Read View，所以只要当前事务在其他事务提交更新之前使用过快照读，那么之后的快照读使用的都是同一个Read View，所以对之后的修改不可见； 即RR级别下，快照读生成Read View时，Read View会记录此时所有其他活动事务的快照，这些事务的修改对于当前事务都是不可见的。而早于Read View创建的事务所做的修改均是可见 而在RC级别下的，事务中，每次快照读都会新生成一个快照和Read View, 这就是我们在RC级别下的事务中可以看到别的事务提交的更新的原因 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"3.Mysql原理/5.Mysql脏读、不可重复读、幻读和MVCC.html":{"url":"3.Mysql原理/5.Mysql脏读、不可重复读、幻读和MVCC.html","title":"5.Mysql脏读、不可重复读、幻读和MVCC","keywords":"","body":"1.1. 脏读、不可重复读、幻读1.1.1. 脏读1.1.2. 不可重复读1.1.3. 幻读1.1.4. 不可重复读和幻读的区别1.2. ACID1.3. 隔离级别1.4. MVCC（多版本并发控制）1.1. 脏读、不可重复读、幻读 1.1.1. 脏读 隔离级别：读未提交 A事务读取B事务尚未提交的数据，此时如果B事务发生错误并执行回滚操作，那么A事务读取到的数据就是脏数据 1.1.2. 不可重复读 隔离级别：读未提交、读已提交 事务A在执行读取操作，由整个事务A比较大，前后读取同一条数据需要经历很长的时间 。而在事务A第一次读取数据，比如此时读取了小明的年龄为20岁，事务B执行更改操作，将小明的年龄更改为30岁，此时事务A第二次读取到小明的年龄时，发现其年龄是30岁，和之前的数据不一样了，也就是数据不重复了，系统不可以读取到重复的数据，成为不可重复读 1.1.3. 幻读 隔离级别：读未提交、读已提交、可重复读 事务A在执行读取操作，需要两次统计数据的总量，前一次查询数据总量后，此时事务B执行了新增数据的操作并提交后，这个时候事务A读取的数据总量和之前统计的不一样，就像产生了幻觉一样，平白无故的多了几条数据，成为幻读。 1.1.4. 不可重复读和幻读的区别 不可重复读是读取了其他事务更改的数据，针对update操作 幻读是读取了其他事务新增的数据，针对insert和delete操作 1.2. ACID 原子性：事务包含的所有数据库操作要么全部成功，要不全部失败回滚 一致性：一个事务执行之前和执行之后都必须处于一致性状态。拿转账来说，假设用户A和用户B两者的钱加起来一共是5000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是5000，这就是事务的一致性。 隔离性：一个事务未提交的业务结果是否对于其它事务可见。级别一般有：read_uncommit，read_commit，read_repeatable，Serializable 串行化访问。 持久性：一个事务一旦被提交了，那么对数据库中数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。 1.3. 隔离级别 脏读 不可重复读 幻读 Read uncommitted y y y Read committed n y y Repeatable read n n y Serializable n n n 1.4. MVCC（多版本并发控制） Multi-Version Concurrency Control 乐观锁为理论基础的MVCC（多版本并发控制），MVCC的实现没有固定的规范。每个数据库都会有不同的实现方式。 MVCC 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"3.Mysql原理/6.Mysql锁.html":{"url":"3.Mysql原理/6.Mysql锁.html","title":"6.Mysql锁","keywords":"","body":"1.1. 锁机制1.1.1. 共享锁和排他锁1.1.2. 粒度锁1.1.3. MyISAM表锁1.1.4. InnoDB行级锁和表级锁1.1.5. InnoDB的间隙锁1.1.6. 死锁1.1.7. InnoDB避免死锁1.1.8. 一些优化锁性能的建议1.1. 锁机制 1.1.1. 共享锁和排他锁 共享锁（读锁）：其他事务可读，不可写 互斥锁（写锁）：其他事务不可读，不可写 1.1.2. 粒度锁 InnoDB：支持行级锁和表级锁，默认采用行级锁 MyISAM：仅支持表级锁 RDB：支持页面锁和表级锁 不同粒度的锁比较 表级锁：开销小，加锁快，不会出现死锁，锁的粒度大，发生锁的并发冲突很高，并发度最低 表级锁适用于以查询为主，并发用户少 行级锁：开销大，加锁慢，有死锁现象，锁粒度最小，锁并发冲突低，并发度高 在 InnoDB 中，除单个 SQL 组成的事务外，锁是逐步获得的，这就决定了在 InnoDB 中发生死锁是可能的（库->表->页->记录） 行级锁只在存储引擎层实现，而Mysql服务器层没有实现。 行级锁更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般 1.1.3. MyISAM表锁 MyISAM表级锁模式 表共享读锁：不会阻塞其他用户对表的读请求，阻塞其他用户对表的写操作 表共享写锁：阻塞其他用户对表的读请求，阻塞其他用户对表的写操作 MyISAM 表的读操作与写操作之间，以及写操作之间是串行的。 当一个线程获得对一个表的写锁后， 只有持有锁的线程可以对表进行更新操作。 其他线程的读、 写操作都会等待，直到锁被释放为止 默认情况下写锁的优先级比读锁高，两个线程竞争锁，会优先分配给写锁，这样就导致大量的更新操作会导致查询操作无法获取锁，从而永久阻塞，这也正是 MyISAM 表不太适合于有大量更新操作和查询操作应用的原因 MyISAM加表级锁的方式 MyISAM 在执行查询语句（SELECT）前，会自动给涉及的表加读锁， 在执行更新操作 （UPDATE、DELETE、INSERT 等）前，会自动给涉及的表加写锁， 这个过程并不需要用户干预，因此，用户一般不需要直接用 LOCK TABLE 命令给 MyISAM 表显式加锁。 在自动加锁的情况下，MyISAM 总是一次获得 SQL 语句所需要的全部锁，这也正是 MyISAM 表不会出现死锁（Deadlock Free）的原因。 1.1.4. InnoDB行级锁和表级锁 InnoDB的锁模式 InnoDB 实现了以下两种类型的行锁： 共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。 排他锁（X）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。 为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁： 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。 共享锁 排他锁 意向共享锁 意向排他锁 共享锁 兼容 冲突 兼容 冲突 排他锁 冲突 冲突 冲突 冲突 意向共享锁 兼容 冲突 兼容 兼容 意向排他锁 兼容 冲突 兼容 兼容 意向锁的作用 在mysql中有表锁 LOCK TABLE my_tabl_name READ; 用读锁锁表，会阻塞其他事务修改表数据。 LOCK TABLE my_table_name WRITe; 用写锁锁表，会阻塞其他事务读和写。 Innodb引擎又支持行锁 行锁分为共享锁，一个事务对一行的共享只读锁。 排它锁，一个事务对一行的排他读写锁。 这两中类型的锁共存的问题考虑这个例子： 事务A锁住了表中的一行，让这一行只能读，不能写。 之后，事务B申请整个表的写锁。如果事务B申请成功，那么理论上它就能修改表中的任意一行，这与A持有的行锁是冲突的。 数据库需要避免这种冲突，就是说要让B的申请被阻塞，直到A释放了行锁。 数据库要怎么判断这个冲突呢？ 判断表是否已被其他事务用表锁锁表 判断表中的每一行是否已被行锁锁住。 注意step2，这样的判断方法效率实在不高，因为需要遍历整个表。 于是就有了意向锁。在意向锁存在的情况下，事务A必须先申请表的意向共享锁，成功后再申请一行的行锁。 在意向锁存在的情况下，上面的判断可以改成 不变 发现表上有意向共享锁，说明表中有些行被共享行锁锁住了，因此，事务B申请表的写锁会被阻塞。 注意：申请意向锁的动作是数据库完成的，就是说，事务A申请一行的行锁的时候，数据库会自动先开始申请表的意向锁，不需要我们程序员使用代码来申请。 InnoDB加锁的方法 意向锁是 InnoDB 自动加的， 不需用户干预。 对于 UPDATE、 DELETE 和 INSERT 语句， InnoDB 会自动给涉及数据集加排他锁（X)； 对于普通 SELECT 语句，InnoDB 不会加任何锁； 事务可以通过以下语句显式给记录集加共享锁或排他锁： 共享锁（S）：`SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE` 其他 session 仍然可以查询记录，并也可以对该记录加 share mode 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。 排他锁（X)：SELECT * FROM table_name WHERE ... FOR UPDATE。 其他 session可以查询该记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁 显示加锁 select for update： 在执行这个 select 查询语句的时候，会将对应的索引访问条目进行上排他锁（X 锁），也就是说这个语句对应的锁就相当于update带来的效果。 select * for update 的使用场景：为了让自己查到的数据确保是最新数据，并且查到后的数据只允许自己来修改的时候，需要用到 for update 子句。 select lock in share mode ： select lock in share mode 子句的作用就是将查找到的数据加上一个 share 锁，这个就是表示其他的事务只能对这些数据进行简单的select 操作，并不能够进行 DML 操作。 select * lock in share mode 使用场景：为了确保自己查到的数据没有被其他的事务正在修改，也就是说确保查到的数据是最新的数据，并且不允许其他人来修改数据。但是自己不一定能够修改数据，因为有可能其他的事务也对这些数据 使用了 in share mode 的方式上了 S 锁。 性能影响： select for update 语句，相当于一个 update 语句。在业务繁忙的情况下，如果事务没有及时的commit或者rollback 可能会造成其他事务长时间的等待，从而影响数据库的并发使用效率。 select lock in share mode 语句是一个给查找的数据上一个共享锁（S 锁）的功能，它允许其他的事务也对该数据上S锁，但是不能够允许对该数据进行修改。如果不及时的commit 或者rollback 也可能会造成大量的事务等待。 InnoDB行锁的实现方式 InnoDB 行锁是通过给索引上的索引项加锁来实现的，这一点 MySQL 与 Oracle 不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB 这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB 才使用行级锁，否则，InnoDB 将使用表锁！ 不论是使用主键索引、唯一索引或普通索引，InnoDB 都会使用行锁来对数据加锁。 只有执行计划真正使用了索引，才能使用行锁：即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。因此，在分析锁冲突时， 别忘了检查 SQL 的执行计划（可以通过 explain 检查 SQL 的执行计划），以确认是否真正使用了索引。 由于 MySQL 的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然多个session是访问不同行的记录， 但是如果是使用相同的索引键， 是会出现锁冲突的（后使用这些索引的session需要等待先使用索引的session释放锁后，才能获取锁）。 应用设计的时候要注意这一点。 例如：city表city_id字段有索引,Cityname字段没有索引： SELECT * FROM city WHERE city_id=14 AND Cityname='深圳' FOR UPDATE; SELECT * FROM city WHERE city_id=14 AND Cityname='长沙' FOR UPDATE; 会话2与会话1访问的是不同的记录，但是因为使用了相同的索引值，所以需要等待锁 1.1.5. InnoDB的间隙锁 当我们用范围条件（>）而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。 很显然，在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际应用开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。 InnoDB间隙锁的作用 防止幻读，以满足相关隔离级别的要求； 满足恢复和复制的需要： MySQL 通过 BINLOG 录入执行成功的 INSERT、UPDATE、DELETE 等更新数据的 SQL 语句，并由此实现 MySQL 数据库的恢复和主从复制。MySQL 的恢复机制（复制其实就是在 Slave Mysql 不断做基于 BINLOG 的恢复）有以下特点： 一是 MySQL 的恢复是 SQL 语句级的，也就是重新执行 BINLOG 中的 SQL 语句。 二是 MySQL 的 Binlog 是按照事务提交的先后顺序记录的， 恢复也是按这个顺序进行的。 由此可见，MySQL 的恢复机制要求：在一个事务未提交前，其他并发事务不能插入满足其锁定条件的任何记录，也就是不允许出现幻读。 1.1.6. 死锁 死锁产生： 死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环。 当事务试图以不同的顺序锁定资源时，就可能产生死锁。多个事务同时锁定同一个资源时也可能会产生死锁。 锁的行为和顺序和存储引擎相关。以同样的顺序执行语句，有些存储引擎会产生死锁有些不会——死锁有双重原因：真正的数据冲突；存储引擎的实现方式。 检测死锁： 数据库系统实现了各种死锁检测和死锁超时的机制。InnoDB存储引擎能检测到死锁的循环依赖并立即返回一个错误。死锁恢复： 死锁发生以后，只有部分或完全回滚其中一个事务，才能打破死锁，InnoDB目前处理死锁的方法是，将持有最少行级排他锁的事务进行回滚。所以事务型应用程序在设计时必须考虑如何处理死锁，多数情况下只需要重新执行因死锁回滚的事务即可。外部锁的死锁检测： 发生死锁后，InnoDB 一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB 并不能完全自动检测到死锁， 这需要通过设置锁等待超时参数 innodb_lock_wait_timeout 来解决死锁影响性能： 死锁会影响性能而不是会产生严重错误，因为InnoDB会自动检测死锁状况并回滚其中一个受影响的事务。在高并发系统上，当许多线程等待同一个锁时，死锁检测可能导致速度变慢。 有时当发生死锁时，禁用死锁检测（使用innodb_deadlock_detect配置选项）可能会更有效，这时可以依赖innodb_lock_wait_timeout设置进行事务回滚。 1.1.7. InnoDB避免死锁 为了在单个InnoDB表上执行多个并发写入操作时避免死锁，可以在事务开始时通过为预期要修改的每个元祖（行）使用SELECT ... FOR UPDATE语句来获取必要的锁，即使这些行的更改语句是在之后才执行的。 在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应先申请共享锁、更新时再申请排他锁，因为这时候当用户再申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁 如果事务需要修改或锁定多个表，则应在每个事务中以相同的顺序使用加锁语句。 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会 通过SELECT ... LOCK IN SHARE MODE获取行的读锁后，如果当前事务再需要对该记录进行更新操作，则很有可能造成死锁。 改变事务隔离级别 如果出现死锁，可以用 SHOW INNODB STATUS 命令来确定最后一个死锁产生的原因。返回结果中包括死锁相关事务的详细信息，如引发死锁的 SQL 语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等。据此可以分析死锁产生的原因和改进措施。 1.1.8. 一些优化锁性能的建议 尽量使用较低的隔离级别，读已提交足够使用 精心设计索引， 并尽量使用索引访问数据， 使加锁更精确， 从而减少锁冲突的机会 选择合理的事务大小，小事务发生锁冲突的几率也更小 给记录集显示加锁时，最好一次性请求足够级别的锁。比如要修改数据的话，最好直接申请排他锁，而不是先申请共享锁，修改时再请求排他锁，这样容易产生死锁 不同的程序访问一组表时，应尽量约定以相同的顺序访问各表，对一个表而言，尽可能以固定的顺序存取表中的行。这样可以大大减少死锁的机会 尽量用相等条件访问数据，这样可以避免间隙锁对并发插入的影响 不要申请超过实际需要的锁级别 除非必须，查询时不要显示加锁。 MySQL的MVCC可以实现事务中的查询不用加锁，优化事务性能；MVCC只在COMMITTED READ（读提交）和REPEATABLE READ（可重复读）两种隔离级别下工作 对于一些特定的事务，可以使用表锁来提高处理速度或减少死锁的可能 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"3.Mysql原理/7.Explain.html":{"url":"3.Mysql原理/7.Explain.html","title":"7.Explain","keywords":"","body":"1.1. Explain执行计划1.1. Explain执行计划 id:选择标识符 sql执行的顺序标识，如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行 select_type:表示查询的类型。 (1) SIMPLE(简单SELECT，不使用UNION或子查询等) (2) PRIMARY(子查询中最外层查询，查询中若包含任何复杂的子部分，最外层的select被标记为PRIMARY) (3) UNION(UNION中的第二个或后面的SELECT语句) (4) DEPENDENT UNION(UNION中的第二个或后面的SELECT语句，取决于外面的查询) (5) UNION RESULT(UNION的结果，union语句中第二个select开始后面所有select) (6) SUBQUERY(子查询中的第一个SELECT，结果不依赖于外部查询) (7) DEPENDENT SUBQUERY(子查询中的第一个SELECT，依赖于外部查询) (8) DERIVED(派生表的SELECT, FROM子句的子查询) (9) UNCACHEABLE SUBQUERY(一个子查询的结果不能被缓存，必须重新评估外链接的第一行) table:输出结果集的表 显示这一步所访问数据库中表名称（显示这一行的数据是关于哪张表的），可能是简称 type:表示表的连接类型 对表访问方式，表示MySQL在表中找到所需行的方式，又称“访问类型”。 常用的类型有： ALL、index、range、 ref、eq_ref、const、system、NULL（从左到右，性能从差到好） ALL：Full Table Scan， MySQL将遍历全表以找到匹配的行 index: Full Index Scan，index与ALL区别为index类型只遍历索引树 range:只检索给定范围的行，使用一个索引来选择行 ref: 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值 eq_ref: 类似ref，区别就在使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配，简单来说，就是多表连接中使用primary key或者 unique key作为关联条件 const、system: 当MySQL对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于where列表中，MySQL就能将该查询转换为一个常量，system是const类型的特例，当查询的表只有一行的情况下，使用system NULL: MySQL在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。 possible_keys:表示查询时，可能使用的索引 指出MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用（该查询可以利用的索引，如果没有任何索引显示 null） 该列完全独立于EXPLAIN输出所示的表的次序。这意味着在possible_keys中的某些键实际上不能按生成的表次序使用。 如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查WHERE子句看是否它引用某些列或适合索引的列来提高你的查询性能。如果是这样，创造一个适当的索引并且再次用EXPLAIN检查查询 key:表示实际使用的索引 key列显示MySQL实际决定使用的键（索引），必然包含在possible_keys中 如果没有选择索引，键是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX。 key_len:索引字段的长度 表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度（key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的） 不损失精确性的情况下，长度越短越好 ref:列与索引的比较 列与索引的比较，表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值 rows:扫描出的行数(估算的行数) 估算出结果集行数，表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数 Extra:执行情况的描述和说明 Using where:不用读取表中所有信息，仅通过索引就可以获取所需数据，这发生在对表的全部的请求列都是同一个索引的部分的时候，表示mysql服务器将在存储引擎检索行后再进行过滤 Using temporary：表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询，常见 group by ; order by Using filesort：当Query中包含 order by 操作，而且无法利用索引完成的排序操作称为“文件排序” Using join buffer：改值强调了在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。 Impossible where：这个值强调了where语句会导致没有符合条件的行（通过收集统计信息不可能存在结果）。 Select tables optimized away：这个值意味着仅通过使用索引，优化器可能仅从聚合函数结果中返回一行 No tables used：Query语句中使用from dual 或不含任何from子句 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"4.Redis原理/常见问题/1.热key击穿穿透雪崩.html":{"url":"4.Redis原理/常见问题/1.热key击穿穿透雪崩.html","title":"1.热key击穿穿透雪崩","keywords":"","body":"1.1. 热key，怎么解决？1.1.1. 热key是什么？1.1.2. 如何解决热key问题1.2. 缓存击穿1.2.1. 缓存击穿是什么？1.2.2. 如何解决？1.3. 缓存穿透1.3.1. 缓存穿透是什么？1.3.2. 如何解决？1.4. 缓存雪崩1.4.1. 缓存雪崩是什么？1.4.2. 如何解决？1.1. 热key，怎么解决？ 1.1.1. 热key是什么？ 热key问题就是，突然有几十万的请求去访问redis上的某个特定key。那么，这样会造成流量过于集中，达到物理网卡上限，从而导致这台redis的服务器宕机。 接下来这个key的请求，就会直接怼到数据库上，导致服务不可用。 1.1.2. 如何解决热key问题 二级缓存利用ehcache，或者一个HashMap都可以。在发现热key以后，把热key加载到系统的JVM中（类似soul网关的二级缓存，把接口路径从库中同步到jvm缓存中，相当于预加载） 提前把热key打散到不同的服务器，降低压力 1.2. 缓存击穿 1.2.1. 缓存击穿是什么？ 缓存击穿的概念就是单个key并发访问过高，过期时导致所有请求直接打到db上，这个和热key的问题比较类似，只是说的点在于过期导致请求全部打到DB上而已。 1.2.2. 如何解决？ 加锁更新，比如请求查询A，发现缓存中没有，对A这个key加锁，同时去数据库查询数据，写入缓存，再返回给用户，这样后面的请求就可以从缓存中拿到数据了。 使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用setnx加锁，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法 public String get(key) { String value = redis.get(key); if (value == null) { //代表缓存值过期 //设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db if (redis.setnx(key_mutex, 1, 3 * 60) == 1) { //代表设置成功 value = db.get(key); redis.set(key, value, expire_secs); redis.del(key_mutex); } else { //这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可 sleep(50); get(key); //重试 } } else { return value; } } 1.3. 缓存穿透 1.3.1. 缓存穿透是什么？ 缓存穿透是指查询不存在缓存中的数据，每次请求都会打到DB，就像缓存不存在一样。 1.3.2. 如何解决？ 布隆过滤器，通过布隆过滤器去拦截，查询布隆过滤器返回0直接返回，不会在打到db，但是布隆过滤器会有误判问题，误判率和hash算法有关 每次请求不存在的结果在redis中写入对应的key和null值设置过期时间（临时解决方案） 1.4. 缓存雪崩 1.4.1. 缓存雪崩是什么？ 当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上，这样可能导致整个系统的崩溃，称为雪崩。雪崩和击穿、热key的问题不太一样的是，他是指大规模的缓存都过期失效了。 1.4.2. 如何解决？ 针对不同key设置不同的过期时间，避免同时过期 限流，如果redis宕机，可以限流，避免同时刻大量请求打崩DB 二级缓存，同热key的方案。 加锁排队，解决不了吞吐量问题 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"4.Redis原理/常见问题/2.redis分布式锁.html":{"url":"4.Redis原理/常见问题/2.redis分布式锁.html","title":"2.redis分布式锁","keywords":"","body":"1.1. 如何使用Redis实现分布式锁？1.1.1. 怎么保证业务出现异常导致锁一直无法释放？1.1.2. 怎么保证不会存在别的线程，误删除key，导致多个线程同时拿到锁？1.1.3. 基于多个 Redis 节点实现高可靠的分布式锁--Redlock1.1.4. 扩展：redisson的WatchDog是如何看家护院的？1.1. 如何使用Redis实现分布式锁？ 核心： SET key value [EX seconds | PX milliseconds] [NX] setnx，不存在就创建返回1，存在不创建不更新返回0 单个命令保证原子性 1.1.1. 怎么保证业务出现异常导致锁一直无法释放？ 给锁变量添加过期时间，即使持有锁的客户端发生了异常，无法主动地释放锁，Redis 也会根据锁变量的过期时间，在锁变量过期后，把它删除 1.1.2. 怎么保证不会存在别的线程，误删除key，导致多个线程同时拿到锁？ key的value值写入线程的的唯一值，这里的唯一值就可以用来标识当前操作的客户端，在释放锁操作时，客户端需要判断，当前锁变量的值是否和自己的唯一标识相等，只有在相等的情况下，才能释放锁。这样一来，就不会出现误释放锁的问题了 同样为了保证判断当前持有锁的线程是否为释放锁的线程的原子性，需要采用lua脚本进行判断 //释放锁 比较unique_value是否相等，避免误释放 if redis.call(\"get\",KEYS[1]) == ARGV[1] then return redis.call(\"del\",KEYS[1]) else return 0 end 1.1.3. 基于多个 Redis 节点实现高可靠的分布式锁--Redlock 使用 SET 命令和 Lua 脚本在 Redis 单节点上实现分布式锁。但是，我们现在只用了一个 Redis 实例来保存锁变量，如果这个 Redis 实例发生故障宕机了， 那么锁变量就没有了。此时，客户端也无法进行锁操作了，这就会影响到业务的正常执行。所以，我们在实现分布式锁时，还需要保证锁的可靠性。那怎么提高呢？ 这就要提到基于多个 Redis 节点实现分布式锁的方式了。 Redlock 算法的基本思路，是让客户端和多个独立的 Redis 实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布 式锁了，否则加锁失败。这样一来，即使有单个 Redis 实例发生故障，因为锁变量在其它实例上也有保存，所以，客户端仍然可以正常地进行锁操作，锁变量并不会丢失 客户端获取当前时间 客户端按顺序依次向 N 个 Redis 实例执行加锁操作 这里的加锁操作和在单实例上执行的加锁操作一样，使用 SET 命令，带上 NX，EX/PX 选项，以及带上客户端的唯一标识。当然，如果某个 Redis 实例发生故障了，为了保证在这 种情况下，Redlock 算法能够继续运行，我们需要给加锁操作设置一个超时时间 如果客户端在和一个 Redis 实例请求加锁时，一直到超时都没有成功，那么此时，客户端会和下一个 Redis 实例继续请求加锁。加锁操作的超时时间需要远远地小于锁的有效时 间，一般也就是设置为几十毫秒 一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时 客户端只有在满足下面的这两个条件时，才能认为是加锁成功。 1.客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁 2.客户端获取锁的总耗时没有超过锁的有效时间 在满足了这两个条件后，我们需要重新计算这把锁的有效时间，计算的结果是锁的最初有效时间减去客户端为获取锁的总耗时。如果锁的有效时间已经来不及完成共享数据的操作 了，我们可以释放锁，以免出现还没完成数据操作，锁就过期了的情况 1.1.4. 扩展：redisson的WatchDog是如何看家护院的？ 如果加锁后线程执行时间过长超过超时时间，redisson如何处理？ https://blog.csdn.net/ice24for/article/details/86177152 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"4.Redis原理/常见问题/3.如何保证缓存一致性.html":{"url":"4.Redis原理/常见问题/3.如何保证缓存一致性.html","title":"3.如何保证缓存一致性","keywords":"","body":"1.1. 四种方案1.2. 疑问：更新缓存还是淘汰缓存？1.2.1. 淘汰缓存1.2.2. 更新缓存1.2.3. 顺序：先淘汰缓存还是先更新数据库？1.1. 四种方案 先更新缓存->更新数据库 先更新数据库->更新缓存 先淘汰缓存->更新数据库 先更新数据库->淘汰缓存 1.2. 疑问：更新缓存还是淘汰缓存？ 1.2.1. 淘汰缓存 优点： 操作简单，无论更新操作是否复杂，直接将缓存中的旧值淘汰 缺点： 下次查询会无法在cache中查到，存在一次cache miss，这是需要重新读取数据库 1.2.2. 更新缓存 优点： cache命中率高，不会存在cache miss 缺点： 如果更新操作复杂，涉及到其它数据，需要缓存多次与数据库操作，此时更新cache的消耗远大于直接淘汰cache 所以直接淘汰缓存更好，这样每次读取这个数据最多有一次cache miss，但是性能更加稳定 更新cache的另一个问题 直接淘汰cache比更新cache要更好，但是考虑一下更新cache的其它问题 当并发较大，同时有两个线程需要对同一个数据进行更新时，可能会出现以下问题： 方案一、先更新(update)缓存，再更新数据库   线程A更新了缓存   线程B更新了缓存   线程B更新了数据库   线程A更新了数据库 方案二、先更新数据库，再更新(update)缓存   线程A更新了数据库   线程B更新了数据库   线程B更新了缓存   线程A更新了缓存 并发情况下，如果更新的先后顺序存在明确要求，更新cache 的方案会导致数据不一致，只有进行‘串行化’（加锁更新） 由上得，更新cache消耗大，会导致数据不一致，所以选择直接淘汰cache 1.2.3. 顺序：先淘汰缓存还是先更新数据库？ 首先考虑执行失败的问题 方案一：先淘汰缓存后更新数据库 缓存淘汰后，更新数据库失败，此时再次查询缓存，最多会出现一次cache miss 方案二：先更新数据库后淘汰缓存 数据库更新成功，缓存淘汰失败会导致缓存中的数据长时间不一致 解决方案：重试机制，删除缓存失败后，由业务代码再次重试，直到缓存被删除 使用mq进行消费重试，直到删除成功 先淘汰cache，再更新数据库：   采用同步更新缓存的策略，可能会导致数据长时间不一致，如果用延迟双删来优化，还需要考虑究竟需要延时多长时间的问题——读的效率较高，但数据的一致性需要靠其它手段来保证   采用异步更新缓存的策略，不会导致数据不一致，但在数据库更新完成之前，都需要到数据库层面去读取数据，读的效率不太好——保证了数据的一致性，适用于对一致性要求高的业务 先更新数据库，再淘汰cache：   无论是同步/异步更新缓存，都不会导致数据的最终不一致，在更新数据库期间，cache中的旧数据会被读取，可能会有一段时间的数据不一致，但读的效率很好——保证了数据读取的效率，如果业务对一致性要求不是很高，这种方案最合适 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"4.Redis原理/常见问题/4.过期删除策略和内存淘汰策略.html":{"url":"4.Redis原理/常见问题/4.过期删除策略和内存淘汰策略.html","title":"4.过期删除策略和内存淘汰策略","keywords":"","body":"1.1. 过期删除策略1.2. 内存淘汰策略1.1. 过期删除策略 在Redis内部，每当我们设置一个键的过期时间时，Redis就会将该键带上过期时间存放到一个过期字典中。当我们查询一个键时，Redis便首先检查该键是否存在过期字典中，如果存在，那就获取其过期时间。然后将过期时间和当前系统时间进行比对，比系统时间大，那就没有过期；反之判定该键过期。 1. 定时删除 在设置某个key 的过期时间同时，我们创建一个定时器，让定时器在该过期时间到来时，立即执行对其进行删除的操作。 优点：定时删除对内存是最友好的，能够保存内存的key一旦过期就能立即从内存中删除。 缺点：对CPU最不友好，在过期键比较多的时候，删除过期键会占用一部分 CPU 时间，对服务器的响应时间和吞吐量造成影响。 2. 惰性删除 设置该key 过期时间后，我们不去管它，当需要该key时，我们在检查其是否过期，如果过期，我们就删掉它，反之返回该key。 优点：对 CPU友好，我们只会在使用该键时才会进行过期检查，对于很多用不到的key不用浪费时间进行过期检查。 缺点：对内存不友好，如果一个键已经过期，但是一直没有使用，那么该键就会一直存在内存中，如果数据库中有很多这种使用不到的过期键，这些键便永远不会被删除，内存永远不会释放。从而造成内存泄漏。 3. 定期删除 每隔一段时间，我们就对一些key进行检查，删除里面过期的key。 优点：可以通过限制删除操作执行的时长和频率来减少删除操作对 CPU 的影响。另外定期删除，也能有效释放过期键占用的内存。 缺点：难以确定删除操作执行的时长和频率。 如果执行的太频繁，定期删除策略变得和定时删除策略一样，对CPU不友好。 如果执行的太少，那又和惰性删除一样了，过期键占用的内存不会及时得到释放。 另外最重要的是，在获取某个键时，如果某个键的过期时间已经到了，但是还没执行定期删除，那么就会返回这个键的值，这是业务不能忍受的错误。 Redis过期删除策略是采用惰性删除和定期删除这两种方式组合进行的，惰性删除能够保证过期的数据我们在获取时一定获取不到，而定期删除设置合适的频率，则可以保证无效的数据及时得到释放，而不会一直占用内存数据。 1.2. 内存淘汰策略 当现有内存大于 maxmemory 时，便会触发redis主动淘汰内存方式，通过设置 maxmemory-policy ，有如下几种淘汰方式： volatile-lru 利用LRU算法移除设置过过期时间的key (LRU:最近使用 Least Recently Used ) 。 allkeys-lru 利用LRU算法移除任何key （和上一个相比，删除的key包括设置过期时间和不设置过期时间的）。通常使用该方式。 volatile-random 移除设置过过期时间的随机key 。 allkeys-random 无差别的随机移除。 volatile-ttl 移除即将过期的key(minor TTL) noeviction 不移除任何key，只是返回一个写错误 ，默认选项，一般不会选用。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"4.Redis原理/数据结构/1.简单动态字符串.html":{"url":"4.Redis原理/数据结构/1.简单动态字符串.html","title":"1.简单动态字符串","keywords":"","body":"1.1. SDS1.1.1. SDS的结构1.1.2. 为什么采用SDS存储字符串？1.1. SDS Redis 没有直接使用 C 语言传统的字符串表示（以空字符结尾的字符数组，以下简称 C 字符串）， 而是自己构建了一种名为简单动态字符串（simple dynamic string，SDS）的抽象类型， 并将 SDS 用作 Redis 的默认字符串表示。 例如： redis> SET msg \"hello world\" OK 那么 Redis 将在数据库中创建了一个新的键值对， 其中： 键值对的键是一个字符串对象， 对象的底层实现是一个保存着字符串 \"msg\" 的 SDS 。 键值对的值也是一个字符串对象， 对象的底层实现是一个保存着字符串 \"hello world\" 的 SDS 。 除了用来保存数据库中的字符串值之外， SDS 还被用作缓冲区（buffer）： AOF 模块中的 AOF 缓冲区， 以及客户端状态中的输入缓冲区， 都是由 SDS 实现的。（后续更新） 1.1.1. SDS的结构 struct sdshdr { // 记录 buf 数组中已使用字节的数量 // 等于 SDS 所保存字符串的长度 int len; // 记录 buf 数组中未使用字节的数量 int free; // 字节数组，用于保存字符串 char buf[]; }; free 属性的值为 0 ， 表示这个 SDS 没有分配任何未使用空间。 len 属性的值为 5 ， 表示这个 SDS 保存了一个五字节长的字符串。 buf 属性是一个 char 类型的数组， 数组的前五个字节分别保存了 'R' 、 'e' 、 'd' 、 'i' 、 's' 五个字符， 而最后一个字节则保存了空字符 '\\0' 。 1.1.2. 为什么采用SDS存储字符串？ C语言字符串是字符数组，并不记录自身的长度信息， 所以为了获取一个 C 字符串的长度， 程序必须遍历整个字符串， 对遇到的每个字符进行计数， 直到遇到代表字符串结尾的空字符为止， 这个操作的复杂度为 O(N) SDS 在 len 属性中记录了 SDS 本身的长度， 所以获取一个 SDS 长度的复杂度仅为 O(1) ，这样 STRLEN 命令的复杂度仅为 O(1) 减少修改字符串时带来的内存重分配次数，杜绝了发生缓冲区溢出的可能性 当 SDS API 需要对 SDS 进行修改时， API 会先检查 SDS 的空间是否满足修改所需的要求， 如果不满足的话， API 会自动将 SDS 的空间扩展至执行修改所需的大小， 然后才执行实际的修改操作， 所以使用 SDS 既不需要手动修改 SDS 的空间大小， 也不会出现前面所说的缓冲区溢出问题。 当 SDS 的 API 对一个 SDS 进行修改， 并且需要对 SDS 进行空间扩展的时候， 程序不仅会为 SDS 分配修改所必须要的空间， 还会为 SDS 分配额外的未使用空间。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"4.Redis原理/数据结构/2.链表.html":{"url":"4.Redis原理/数据结构/2.链表.html","title":"2.链表","keywords":"","body":"1.1. 链表和链表节点的实现1.1.1. 重点1.1. 链表和链表节点的实现 listNode 双向链表节点: typedef struct listNode { // 前置节点 struct listNode *prev; // 后置节点 struct listNode *next; // 节点的值 void *value; } listNode; list: 双端双向链表 typedef struct list { // 表头节点 listNode *head; // 表尾节点 listNode *tail; // 链表所包含的节点数量 unsigned long len; // 节点值复制函数 void *(*dup)(void *ptr); // 节点值释放函数 void (*free)(void *ptr); // 节点值对比函数 int (*match)(void *ptr, void *key); } list; list 结构为链表提供了表头指针 head 、表尾指针 tail ， 以及链表长度计数器 len ， 而 dup 、 free 和 match 成员则是用于实现多态链表所需的类型特定函数： dup 函数用于复制链表节点所保存的值； free 函数用于释放链表节点所保存的值； match 函数则用于对比链表节点所保存的值和另一个输入值是否相等。 1.1.1. 重点 链表被广泛用于实现 Redis 的各种功能， 比如列表键， 发布与订阅， 慢查询， 监视器， 等等。 每个链表节点由一个 listNode 结构来表示， 每个节点都有一个指向前置节点和后置节点的指针， 所以 Redis 的链表实现是双端链表。 每个链表使用一个 list 结构来表示， 这个结构带有表头节点指针、表尾节点指针、以及链表长度等信息。 因为链表表头节点的前置节点和表尾节点的后置节点都指向 NULL ， 所以 Redis 的链表实现是无环链表。 通过为链表设置不同的类型特定函数， Redis 的链表可以用于保存各种不同类型的值。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"4.Redis原理/数据结构/3.字典.html":{"url":"4.Redis原理/数据结构/3.字典.html","title":"3.字典","keywords":"","body":"1.1. 字典1.1.1. 底层结构1.2. 哈希算法1.3. rehash1.3.1. 渐进式rehash1.4. 总结1.1. 字典 字典（map）， 是一种用于保存键值对（key-value pair）的抽象数据结构。 1.1.1. 底层结构 redis的字典使用哈希表作为底层实现， 一个哈希表里面可以有多个哈希表节点， 而每个哈希表节点就保存了字典中的一个键值对。 hash表数据结构: typedef struct dictht { // 哈希表数组 dictEntry **table; // 哈希表大小 unsigned long size; // 哈希表大小掩码，用于计算索引值 // 总是等于 size - 1 unsigned long sizemask; // 该哈希表已有节点的数量 unsigned long used; } dictht; sizemask 属性的值总是等于 size - 1 ， 这个属性和哈希值一起决定一个键应该被放到 table 数组的哪个索引上面。 hash表单个节点数据结构: typedef struct dictEntry { // 键 void *key; // 值 union { void *val; uint64_t u64; int64_t s64; } v; // 指向下个哈希表节点，形成链表 struct dictEntry *next; } dictEntry; *next形成链表，使用链地址法解决hash冲突 字典数据结构: typedef struct dict { // 类型特定函数 dictType *type; // 私有数据 void *privdata; // 哈希表 dictht ht[2]; // rehash 索引 // 当 rehash 不在进行时，值为 -1 int rehashidx; /* rehashing not in progress if rehashidx == -1 */ } dict; type 属性和 privdata 属性是针对不同类型的键值对， 为创建多态字典而设置的： type 属性是一个指向 dictType 结构的指针， 每个 dictType 结构保存了一簇用于操作特定类型键值对的函数， Redis 会为用途不同的字典设置不同的类型特定函数。 而 privdata 属性则保存了需要传给那些类型特定函数的可选参数。 ht 属性是一个包含两个项的数组， 数组中的每个项都是一个 dictht 哈希表， 一般情况下， 字典只使用 ht[0] 哈希表， ht[1] 哈希表只会在对 ht[0] 哈希表进行 rehash 时使用。 除了 ht[1] 之外， 另一个和 rehash 有关的属性就是 rehashidx ： 它记录了 rehash 目前的进度， 如果目前没有在进行 rehash ， 那么它的值为 -1 。 1.2. 哈希算法 当要将一个新的键值对添加到字典里面时， 程序需要先根据键值对的键计算出哈希值和索引值， 然后再根据索引值， 将包含新键值对的哈希表节点放到哈希表数组的指定索引上面。 # 使用字典设置的哈希函数，计算键 key 的哈希值 hash = dict->type->hashFunction(key); # 使用哈希表的 sizemask 属性和哈希值，计算出索引值 # 根据情况不同， ht[x] 可以是 ht[0] 或者 ht[1] index = hash & dict->ht[x].sizemask; hash算法其实和hashmap相同，都是(n-1)&hash,n为数组长度 链地址法解决hash冲突 1.3. rehash 由上面的dict的数据结构可知，一个字典存储的有两个ht[] (hash表)。dict的扩容和收缩都是通过rehash来完成 步骤如下： 为字典的 ht[1] 哈希表分配空间， 这个哈希表的空间大小取决于要执行的操作， 以及 ht[0] 当前包含的键值对数量 （也即是ht[0].used 属性的值）： 如果执行的是扩展操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used * 2 的 2^n （2 的 n 次方幂）； 如果执行的是收缩操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used 的 2^n 。 将保存在 ht[0] 中的所有键值对 rehash 到 ht[1] 上面： rehash 指的是重新计算键的哈希值和索引值， 然后将键值对放置到 ht[1] 哈希表的指定位置上。 当 ht[0] 包含的所有键值对都迁移到了 ht[1] 之后 （ht[0] 变为空表）， 释放 ht[0] ， 将 ht[1] 设置为 ht[0] ， 并在 ht[1] 新创建一个空白哈希表， 为下一次 rehash 做准备。 1.3.1. 渐进式rehash 扩展或收缩哈希表需要将 ht[0] 里面的所有键值对 rehash 到 ht[1] 里面， 但是， 这个 rehash 动作并不是一次性、集中式地完成的， 而是分多次、渐进式地完成的。 为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。 在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。 在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。 随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。 因为在进行渐进式 rehash 的过程中， 字典会同时使用 ht[0] 和 ht[1] 两个哈希表， 所以在渐进式 rehash 进行期间， 字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行： 比如说， 要在字典里面查找一个键的话， 程序会先在 ht[0] 里面进行查找， 如果没找到的话， 就会继续到 ht[1] 里面进行查找。 另外， 在渐进式 rehash 执行期间， 新添加到字典的键值对一律会被保存到 ht[1] 里面， 而 ht[0] 则不再进行任何添加操作： 这一措施保证了 ht[0] 包含的键值对数量会只减不增， 并随着 rehash 操作的执行而最终变成空表。 1.4. 总结 字典被广泛用于实现 Redis 的各种功能， 其中包括数据库和哈希键。 Redis 中的字典使用哈希表作为底层实现， 每个字典带有两个哈希表， 一个用于平时使用， 另一个仅在进行 rehash 时使用。 当字典被用作数据库的底层实现， 或者哈希键的底层实现时， Redis 使用 MurmurHash2 算法来计算键的哈希值。 哈希表使用链地址法来解决键冲突， 被分配到同一个索引上的多个键值对会连接成一个单向链表。 在对哈希表进行扩展或者收缩操作时， 程序需要将现有哈希表包含的所有键值对 rehash 到新哈希表里面， 并且这个 rehash 过程并不是一次性地完成的， 而是渐进式地完成的。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"4.Redis原理/数据结构/4.跳跃表.html":{"url":"4.Redis原理/数据结构/4.跳跃表.html","title":"4.跳跃表","keywords":"","body":"1.1. 跳表基础概念1.2. 实现1.3. 重点1.1. 跳表基础概念 跳跃表（skiplist）是一种有序数据结构， 它通过在每个节点中维持多个指向其他节点的指针， 从而达到快速访问节点的目的。 跳跃表支持平均 O(log N) 最坏 O(N) 复杂度的节点查找， 还可以通过顺序性操作来批量处理节点。 1.2. 实现 Redis 的跳跃表由 zskiplistNode 和 zskiplist 两个结构定义， 其中 zskiplistNode 结构用于表示跳跃表节点 zskiplist结构则用于保存跳跃表节点的相关信息， 比如节点的数量， 以及指向表头节点和表尾节点的指针， 等等。 图片最左端是zskiplist具有四个属性： typedef struct zskiplist { // 表头节点和表尾节点 struct zskiplistNode *header, *tail; // 表中节点的数量 unsigned long length; // 表中层数最大的节点的层数 int level; } zskiplist; header ：指向跳跃表的表头节点。 tail ：指向跳跃表的表尾节点。 level ：记录目前跳跃表内，层数最大的那个节点的层数（表头节点的层数不计算在内）。 length ：记录跳跃表的长度，也即是，跳跃表目前包含节点的数量（表头节点不计算在内）。 位于 zskiplist 结构右方的是四个 zskiplistNode 结构， 该结构包含以下属性： typedef struct zskiplistNode { // 后退指针 struct zskiplistNode *backward; // 分值 double score; // 成员对象 robj *obj; // 层 struct zskiplistLevel { // 前进指针 struct zskiplistNode *forward; // 跨度 unsigned int span; } level[]; } zskiplistNode; 层（level）：节点中用 L1 、 L2 、 L3 等字样标记节点的各个层， L1 代表第一层， L2 代表第二层，以此类推。每个层都带有两个属性： 前进指针和跨度。前进指针用于访问位于表尾方向的其他节点，而跨度则记录了前进指针所指向节点和当前节点的距离。 在上面的图片中，连线上带有数字的箭头就代表前进指针，而那个数字就是跨度。当程序从表头向表尾进行遍历时，访问会沿着层的前进指针进行。 后退（backward）指针：节点中用 BW 字样标记节点的后退指针，它指向位于当前节点的前一个节点。后退指针在程序从表尾向表头遍历时使用。 分值（score）：各个节点中的 1.0 、 2.0 和 3.0 是节点所保存的分值。在跳跃表中，节点按各自所保存的分值从小到大排列。 成员对象（obj）：各个节点中的 o1 、 o2 和 o3 是节点所保存的成员对象。 每次创建一个新跳跃表节点的时候， 程序都根据幂次定律 （power law，越大的数出现的概率越小） 随机生成一个介于 1 和 32 之间的值作为 level 数组的大小， 这个大小就是层的“高度”。 节点的分值（score 属性）是一个 double 类型的浮点数， 跳跃表中的所有节点都按分值从小到大来排序。节点的成员对象（obj 属性）是一个指针， 它指向一个字符串对象， 而字符串对象则保存着一个 SDS 值。 注意表头节点和其他节点的构造是一样的： 表头节点也有后退指针、分值和成员对象， 不过表头节点的这些属性都不会被用到， 所以图中省略了这些部分， 只显示了表头节点的各个层。 1.3. 重点 跳跃表是有序集合的底层实现之一， 除此之外它在 Redis 中没有其他应用。 Redis 的跳跃表实现由 zskiplist 和 zskiplistNode 两个结构组成， 其中 zskiplist 用于保存跳跃表信息（比如表头节点、表尾节点、长度）， 而 zskiplistNode 则用于表示跳跃表节点。 每个跳跃表节点的层高都是 1 至 32 之间的随机数。 在同一个跳跃表中， 多个节点可以包含相同的分值， 但每个节点的成员对象必须是唯一的。 跳跃表中的节点按照分值大小进行排序， 当分值相同时， 节点按照成员对象的大小进行排序。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"4.Redis原理/数据结构/5.整数集合.html":{"url":"4.Redis原理/数据结构/5.整数集合.html","title":"5.整数集合","keywords":"","body":"1.1. 整数集合1.1.1. 实现1.1.2. 升级机制1.1.3. 重点1.1. 整数集合 整数集合（intset）是set的底层实现之一： 当一个set只包含整数值元素， 并且这个set的元素数量不多时， Redis 就会使用整数集合作为set的底层实现。 1.1.1. 实现 整数集合（intset）是 Redis 用于保存整数值的集合抽象数据结构， 它可以保存类型为 int16_t 、 int32_t 或者 int64_t 的整数值， 并且保证集合中不会出现重复元素。 typedef struct intset { // 编码方式 uint32_t encoding; // 集合包含的元素数量 uint32_t length; // 保存元素的数组 int8_t contents[]; } intset; contents 数组是整数集合的底层实现： 整数集合的每个元素都是 contents 数组的一个数组项（item）， 各个项在数组中按值的大小从小到大有序地排列， 并且数组中不包含 任何重复项。 length记录整数集合包含的元素数量，等于contents数组的长度 虽然 intset 结构将 contents 属性声明为 int8_t 类型的数组， 但实际上 contents 数组并不保存任何 int8_t 类型的值 —— contents 数组的真正类型取决于 encoding 属性的值： - 如果 encoding 属性的值为 INTSET_ENC_INT16 ， 那么 contents 就是一个 int16_t 类型的数组， 数组里的每个项都是一个 int16_t 类型的整数值 （最小值为 -32,768 ，最大值为 32,767 ）。 - 如果 encoding 属性的值为 INTSET_ENC_INT32 ， 那么 contents 就是一个 int32_t 类型的数组， 数组里的每个项都是一个 int32_t 类型的整数值 （最小值为 -2,147,483,648 ，最大值为 2,147,483,647 ）。 - 如果 encoding 属性的值为 INTSET_ENC_INT64 ， 那么 contents 就是一个 int64_t 类型的数组， 数组里的每个项都是一个 int64_t 类型的整数值 （最小值为 -9,223,372,036,854,775,808 ，最大值为 9,223,372,036,854,775,807 ）。 1.1.2. 升级机制 每当我们要将一个新元素添加到整数集合里面， 并且新元素的类型比整数集合现有所有元素的类型都要长时， 整数集合需要先进行升级（upgrade）， 然后才能将新元素添加到整数集合里面。(节约内存) 升级整数集合并添加新元素共分为三步进行： 根据新元素的类型， 扩展整数集合底层数组的空间大小， 并为新元素分配空间。 将底层数组现有的所有元素都转换成与新元素相同的类型， 并将类型转换后的元素放置到正确的位上， 而且在放置元素的过程中， 需要继续维持底层数组的有序性质不变。 将新元素添加到底层数组里面。 只会升级不会降级 1.1.3. 重点 整数集合是集合键的底层实现之一。 整数集合的底层实现为数组， 这个数组以有序、无重复的方式保存集合元素， 在有需要时， 程序会根据新添加元素的类型， 改变这个数组的类型。 升级操作为整数集合带来了操作上的灵活性， 并且尽可能地节约了内存。 整数集合只支持升级操作， 不支持降级操作。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"4.Redis原理/数据结构/6.压缩列表.html":{"url":"4.Redis原理/数据结构/6.压缩列表.html","title":"6.压缩列表","keywords":"","body":"1.1. 压缩列表1.2. 实现1.3. 重点1.1. 压缩列表 压缩列表（ziplist）是list和hash的底层实现之一。 当一个list只包含少量列表项， 并且每个节点要么就是小整数值， 要么就是长度比较短的字符串， 那么 Redis 就会使用压缩列表来做list的底层实现。 1.2. 实现 压缩列表是 Redis 为了节约内存而开发的， 由一系列特殊编码的连续内存块组成的顺序型（sequential）数据结构。 一个压缩列表可以包含任意多个节点（entry）， 每个节点可以保存一个字节数组或者一个整数值。 zlbytes 记录整个压缩列表占用的内存字节数：在对压缩列表进行内存重分配， 或者计算 zlend 的位置时使用。 zltail 记录压缩列表表尾节点距离压缩列表的起始地址有多少字节： 通过这个偏移量，程序无须遍历整个压缩列表就可以确定表尾节点的地址。 zllen 记录了压缩列表包含的节点数量： 当这个属性的值小于 UINT16_MAX （65535）时， 这个属性的值就是压缩列表包含节点的数量； 当这个值等于 UINT16_MAX 时， 节点的真实数量需要遍历整个压缩列表才能计算得出。 entryX 压缩列表包含的各个节点，节点的长度由节点保存的内容决定。 zlend 特殊值 0xFF （十进制 255 ），用于标记压缩列表的末端。 每个压缩列表节点可以保存一个字节数组或者一个整数值， 其中， 字节数组可以是以下三种长度的其中一种： 长度小于等于 63 （2^{6}-1）字节的字节数组； 长度小于等于 16383 （2^{14}-1） 字节的字节数组； 长度小于等于 4294967295 （2^{32}-1）字节的字节数组； 而整数值则可以是以下六种长度的其中一种： 4 位长，介于 0 至 12 之间的无符号整数； 1 字节长的有符号整数； 3 字节长的有符号整数； int16_t 类型整数； int32_t 类型整数； int64_t 类型整数。 1.3. 重点 压缩列表是一种为节约内存而开发的顺序型数据结构。 压缩列表被用作列表键和哈希键的底层实现之一。 压缩列表可以包含多个节点，每个节点可以保存一个字节数组或者整数值。 添加新节点到压缩列表， 或者从压缩列表中删除节点， 可能会引发连锁更新操作， 但这种操作出现的几率并不高。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"4.Redis原理/数据结构/7.对象.html":{"url":"4.Redis原理/数据结构/7.对象.html","title":"7.对象","keywords":"","body":"1.1. 对象1.2. 实现1.2.1. 字符串对象1.2.2. list1.2.3. Hash对象1.2.4. Set1.2.5. ZSet1.3. 重点1.1. 对象 Redis 并没有直接使用链表、跳表等数据结构来实现键值对数据库， 而是基于这些数据结构创建了一个对象系统， 这个系统包含String、list、hash、set和zset对象这五种类型的对象， 每种对象都用到了至少一种我们前面所介绍的数据结构。 通过这五种不同类型的对象， Redis 可以在执行命令之前， 根据对象的类型来判断一个对象是否可以执行给定的命令。 使用对象的另一个好处是， 我们可以针对不同的使用场景， 为对象设置多种不同的数据结构实现， 从而优化对象在不同场景下的使用效率。 除此之外， Redis 的对象系统还实现了基于引用计数技术的内存回收机制： 当程序不再使用某个对象的时候， 这个对象所占用的内存就会被自动释放； 另外， Redis 还通过引用计数技术实现了对象共享机制， 这一机制可以在适当的条件下， 通过让多个数据库键共享同一个对象来节约内存。 最后， Redis 的对象带有访问时间记录信息， 该信息可以用于计算数据库键的空转时长， 在服务器启用了 maxmemory 功能的情况下， 空转时长较大的那些键可能会优先被服务器删除。 1.2. 实现 Redis 中的每个对象都由一个 redisObject 结构表示， 该结构中和保存数据有关的三个属性分别是 type 属性、 encoding 属性和 ptr 属性： typedef struct redisObject { // 类型 unsigned type:4; // 编码 unsigned encoding:4; // 指向底层实现数据结构的指针 void *ptr; // ... } robj; type记录的为对象的类型： 类型常量 对象的名称 REDIS_STRING 字符串对象 REDIS_LIST 列表对象 REDIS_HASH 哈希对象 REDIS_SET 集合对象 REDIS_ZSET 有序集合对象 对象底层锁采用的数据结构： 对象所使用的底层数据结构 命令输出 整数 \"int\" embstr \"embstr\" 简单动态字符串 \"raw\" 字典 \"hashtable\" 双端链表 \"linkedlist\" 压缩列表 \"ziplist\" 整数集合 \"intset\" 跳跃表和字典 \"skiplist\" Redis 缓存保存的键值对来说， 键总是一个字符串对象， 而值则可以是字符串对象、list对象、哈希对象、set对象、zset对象的其中一种 1.2.1. 字符串对象 字符串对象的编码可以是 int 、 raw 或者 embstr 如果一个字符串对象保存的是整数值， 并且这个整数值可以用 long 类型来表示， 那么字符串对象会将整数值保存在字符串对象结构的 ptr属性里面（将 void* 转换成 long ）， 并将字符串对象的编码设置为 int 。 如果字符串对象保存的是一个字符串值， 并且这个字符串值的长度大于 39 字节， 那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串值， 并将对象的编码设置为 raw 。 如果字符串对象保存的是一个字符串值， 并且这个字符串值的长度小于等于 39 字节， 那么字符串对象将使用 embstr 编码的方式来保存这个字符串值。 embstr 编码是专门用于保存短字符串的一种优化编码方式， 这种编码和 raw 编码一样， 都使用 redisObject 结构和 sdshdr 结构来表示字符串对象， 但 raw 编码会调用两次内存分配函数来分别创建 redisObject 结构和 sdshdr 结构， 而 embstr 编码则通过调用一次内存分配函数来分配一块连续的空间， 空间中依次包含 redisObject 和 sdshdr 两个结构 值 编码 可以用 long 类型保存的整数。 int 可以用 long double 类型保存的浮点数。 embstr 或者 raw 字符串值，或者因为长度太大而没办法用 long 类型表示的整数， 又或者因为长度太大而没办法用long double 类型表示的浮点数。 embstr 或者 raw 1.2.2. list 列表对象的编码可以是 ziplist 或者 linkedlist 当列表对象可以同时满足以下两个条件时， 列表对象使用 ziplist 编码： 列表对象保存的所有字符串元素的长度都小于 64 字节； 列表对象保存的元素数量小于 512 个； 1.2.3. Hash对象 哈希对象的编码可以是 ziplist 或者 hashtable ziplist 编码的哈希对象使用压缩列表作为底层实现， 每当有新的键值对要加入到哈希对象时， 程序会先将保存了键的压缩列表节点推入到压缩列表表尾， 然后再将保存了值的压缩列表节点推入到压缩列表表尾， 因此： 保存了同一键值对的两个节点总是紧挨在一起， 保存键的节点在前， 保存值的节点在后； 先添加到哈希对象中的键值对会被放在压缩列表的表头方向， 而后来添加到哈希对象中的键值对会被放在压缩列表的表尾方向。 hashtable 编码的哈希对象使用字典作为底层实现， 哈希对象中的每个键值对都使用一个字典键值对来保存： 字典的每个键都是一个字符串对象， 对象中保存了键值对的键； 字典的每个值都是一个字符串对象， 对象中保存了键值对的值。 1.2.4. Set Set对象的编码可以是 intset 或者 hashtable 1.2.5. ZSet 有序集合的编码可以是 ziplist 或者 skiplist 1.3. 重点 Redis 数据库中的每个键值对的键和值都是一个对象。 Redis 共有字符串、列表、哈希、集合、有序集合五种类型的对象， 每种类型的对象至少都有两种或以上的编码方式， 不同的编码可以在不同的使用场景上优化对象的使用效率。 服务器在执行某些命令之前， 会先检查给定键的类型能否执行指定的命令， 而检查一个键的类型就是检查键的值对象的类型。 Redis 的对象系统带有引用计数实现的内存回收机制， 当一个对象不再被使用时， 该对象所占用的内存就会被自动释放。 Redis 会共享值为 0 到 9999 的字符串对象。 对象会记录自己的最后一次被访问的时间（lru）， 这个时间可以用于计算对象的空转时间 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"4.Redis原理/核心设计/1.redis核心设计概述.html":{"url":"4.Redis原理/核心设计/1.redis核心设计概述.html","title":"1.redis核心设计概述","keywords":"","body":"1.1. redis 知识全景图1.1. redis 知识全景图 “两大维度”就是指系统维度和应用维度，“三大主线”也就是指高性能、高可靠和高可扩展（可以简称为“三高”）。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"4.Redis原理/核心设计/2.redis为什么这么快.html":{"url":"4.Redis原理/核心设计/2.redis为什么这么快.html","title":"2.redis为什么这么快","keywords":"","body":"1.1. redis是不是单线程？1.2. redis为什么采用单线程？1.2.1. 多线程的开销1.3. 单线程的redis为什么这么快?1.3.1. 基本IO模型与阻塞点1.3.2. 非阻塞模式思想1.3.3. 基于多路复用的高性能IO模型1.1. redis是不是单线程？ 我们通常说，Redis 是单线程，主要是指 Redis 的网络 IO和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。 但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的 1.2. redis为什么采用单线程？ 要更好地理解 Redis 为什么用单线程，我们就要先了解多线程的开销。 1.2.1. 多线程的开销 一般来说： 使用多线程可以增加系统的吞吐率，或者可以增加系统的扩展性。 的确，对于一个多线程的系统来说，在有合理的资源分配的情况下，可以增加系统中处理请求操作的资源实体，进而提升系统能够同时处理的请求数，即吞吐率。 但是，在采用多线程编程的过程中，如果没有良好的系统设计，刚开始增加线程数系统吞吐量会增加，但是进一步增加线程系统的吞吐量会增长迟缓甚至下降 多线程存在的瓶颈 系统中通常会存在被多线程同时访问的共享资源，比如一个共享的数据结构。当有多个线程要修改这个共享资源时，为了保证共享资源的正确性，就需要有额外的机制进行保证，而这个额外的机制，就会带来额外的开销。 拿 Redis 来说，Redis 有 List 的数据类型，并提供出队（LPOP）和入队（LPUSH）操作。假设 Redis 采用多线程设计，现在有两个线程 A 和B，线程 A 对一个 List 做 LPUSH 操作，并对队列长度加 1。 同时，线程 B 对该 List 执行LPOP 操作，并对队列长度减 1。为了保证队列长度的正确性，Redis 需要让线程 A 和 B的 LPUSH 和 LPOP 串行执行，这样一来，Redis 可以无误地记录它们对 List 长度的修改。 否则，我们可能就会得到错误的长度结果。这就是多线程编程模式面临的共享资源的并发访问控制问题。 1.3. 单线程的redis为什么这么快? 大部分操作都是在内存上完成 高效的数据结构，哈希表，跳表 redis采用非阻塞io模型，多路io复用 像理解多路io复用，必须弄明白网络操作的基本io模型和潜在的阻塞点 1.3.1. 基本IO模型与阻塞点 以get请求为例，处理一个 Get 请求，需要监听客户端请求（bind/listen），和客户端建立连接（accept），从 socket 中读取请求（recv），解析 客户端发送请求（parse），根据请求类型读取键值数据（get），最后给客户端返回结果，即向 socket 中写回数据（send）。 观察基本io模型的处理逻辑可以发现存在两个潜在的阻塞点，分别为accept()和recv() 当redis监听到一个客户端有连接请求但是一直未建立连接时，会阻塞在accept()导致其它客户端无法建立连接 当 Redis 通过 recv() 从一个客户端读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 recv() 这就导致整个线程阻塞，无法处理其它客户端的请求，效率很低 1.3.2. 非阻塞模式思想 非阻塞模式说白了就是在，等待建立连接和等待接收数据的时候可以处理其它操作 当 Redis 调用 accept() 但一直未有连接请求到达时，Redis 线程可以返回处理其他操作，而不用一直等待。但是，你要注意的是，调用 accept() 时，已经存在监听套接字了 Redis 调用 recv() 后，如果已连接套接字上一直没有数据到达，Redis 线程同样可以返回处理其他操作。我们也需要有机制继续监听该已连接套接字，并在有数据达到时通知 Redis 这样才能保证 Redis 线程，既不会像基本 IO 模型中一直在阻塞点等待，也不会导致 Redis无法处理实际到达的连接请求或数据。 到此，Linux 中的 IO 多路复用机制就要登场了。 1.3.3. 基于多路复用的高性能IO模型 Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的select/epoll 机制简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同 时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个IO 流的效果。 为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数 其实，select/epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件 这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。这样一来，Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。同时， Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升Redis 的响应性能 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"4.Redis原理/核心设计/3.AOF日志.html":{"url":"4.Redis原理/核心设计/3.AOF日志.html","title":"3.AOF日志","keywords":"","body":"1.1. AOF日志是如何实现的？1.1.1. AOF 为什么要先执行命令再记日志？1.1.2. AOF的两个潜在风险1.1.3. 日志文件过大如何解决的？AOF重写机制1.1. AOF日志是如何实现的？ 说到日志，我们比较熟悉的是数据库的写前日志（Write Ahead Log, WAL），也就是说，在实际写数据前，先把修改的数据记到日志文件中，以便故障时进行恢复。不过， AOF 日志正好相反，它是写后日志，“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志 Redis -> 执行命令写内存 -> 向磁盘中写入aof日志 1.1.1. AOF 为什么要先执行命令再记日志？ 为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错 AOF 还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作 1.1.2. AOF的两个潜在风险 如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险 AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因为，AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。 仔细分析这两个风险都是和 AOF 写回磁盘的时机相关的。这也就意味着，如果能够控制一个写命令执行完后 AOF 日志写回磁盘的时机，这两个风险就解除了 三种写回策略 对于这个问题，AOF 机制给我们提供了三个选择，也就是 AOF 配置项 appendfsync 的三个可选值。 Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘； Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘； No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。 针对避免主线程阻塞和减少数据丢失问题，这三种写回策略都无法做到两全其美 Always，同步写回，是它在每一个写命令后都有一个慢速的落盘操作，不可避免地会影响主线程性能 No，操作系统控制的写回，在写完缓冲区后，就可以继续执行后续的命令，但是落盘的时机已经不在 Redis 手中了，只要 AOF 记录没有写回磁盘，一旦宕机对应的数据就丢失了 Everysec，每秒写回，采用一秒写回一次的频率，避免了“同步写回”的性能开销，虽然减少了对系统性能的影响，但是如果发生宕机，上一秒内未落盘的命令操作仍然会丢失。所以，这只能算是，在避免影响主线程性能和避免数据丢失两者间取了个折中 1.1.3. 日志文件过大如何解决的？AOF重写机制 AOF 是以文件的形式在记录接收到的所有写命令。随着接收的写命令越来越多，AOF 文件会越来越大。这也就意味着，一定要小心 AOF 文件过大带来的性能问题 文件系统本身对文件大小有限制，无法保存过大的文件； 如果文件太大，之后再往里面追加命令记录的话，效率也会变低； 如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到 Redis 的正常使用。 重写机制：Redis服务器可以创建一个新的AOF文件来替代现有的AOF文件，新旧两个文件所保存的数据库状态是相同的，但是新的AOF文件不会包含任何浪费空间的冗余命令，通常体积会较旧AOF文件小很多 AOF日志重写是否会阻塞主线程？ 和 AOF 日志由主线程写回不同，重写过程是由后台线程 bgrewriteaof 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降 主线程 fork 出后台的 bgrewriteaof 子进程。此时，fork 会把主线程的内存拷贝一份给 bgrewriteaof 子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志 使用子进程进行AOF重写的问题 问题： 子进程在进行AOF重写期间，服务器进程还要继续处理命令请求，而新的命令可能对现有的数据进行修改，这会让当前数据库的数据和重写后的AOF文件中的数据不一致 为了解决这种数据不一致的问题，Redis增加了一个AOF重写缓存，这个缓存在fork出子进程之后开始启用， Redis服务器主进程在执行完写命令之后，会同时将这个写命令追加到AOF缓冲区和AOF重写缓冲区 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"4.Redis原理/核心设计/4.RDB日志.html":{"url":"4.Redis原理/核心设计/4.RDB日志.html","title":"4.RDB日志","keywords":"","body":"1.1. RDB内存快照1.1.1. RDB是否会阻塞主线程1.1.2. 混合使用 AOF 日志和内存快照1.1. RDB内存快照 所谓内存快照，就是把某一时刻的状态以文件的形式写到磁盘上，也就是快照。这样一来，即使宕机，快照文件也不会丢失，数据的可靠性也就 得到了保证。这个快照文件就称为 RDB 文件，其中，RDB 就是 Redis DataBase 的缩写 和 AOF 相比，RDB 记录的是某一时刻的数据，并不是操作，所以，在做数据恢复时，我们可以直接把 RDB 文件读入内存，很快地完成恢复 1.1.1. RDB是否会阻塞主线程 Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave save：在主线程中执行，会导致阻塞； bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是Redis RDB 文件生成的默认配置。 Redis 会借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。 简单来说，bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件 1.1.2. 混合使用 AOF 日志和内存快照 Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。 这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"4.Redis原理/核心设计/5.主从库如何保证一致.html":{"url":"4.Redis原理/核心设计/5.主从库如何保证一致.html","title":"5.主从库如何保证一致","keywords":"","body":"1.1. Redis高可用1.2. 主从库的数据拷贝1.2.1. 主从库间如何进行第一次同步？1.2.2. 主从级联模式分担全量复制时的主库压力1.2.3. 主从库间的网络断了怎么办？1.2.4. 为什么主从库间的复制不使用 AOF 呢？1.2.5. 小结1.1. Redis高可用 一般来说Redis具备高可用性包括两点：1. 数据尽量少丢失 2. 服务尽量少中断 AOF和RDB日志保证了前者，对于服务尽量少中断，redis采用增加副本冗余量，将一份数据同时保存在多个实例上。即使有一个实例出现了故障，需要过一段时间才能恢复，其他实例也可以对外提供服务，不会影响业务使用 多实例保存同一份数据需要考虑一个问题： 这么多副本，它们之间的数据如何保持一致 1.2. 主从库的数据拷贝 Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式 读操作：主库、从库都可以接收； 写操作：首先到主库执行，然后，主库将写操作同步给从库。 1.2.1. 主从库间如何进行第一次同步？ 当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。 replicaof 172.16.19.3 6379 第一阶段是主从库间建立连接、协商同步的过程，主要是为全量复制做准备。在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了 具体来说，从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync 命令包含了主库的 runID 和复制进度 offset 两个参数。 runID，是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设为“？”。 offset，此时设为 -1，表示第一次复制。 主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的 RDB 文件 具体来说，主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。 这是因为从库在通过 replicaof命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。 主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则，Redis 的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。 为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录RDB 文件生成后收到的所有写操作 主库会把第二阶段执行过程中新收到的写命令，再发送给从库。 具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了 1.2.2. 主从级联模式分担全量复制时的主库压力 通过分析主从库间第一次数据同步的过程，一次全量复制中，对于主库来说，需要完成两个耗时的操作：生成 RDB 文件和传输 RDB 文件 如果从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 这个操作会阻塞主线程处理正常请求，从而导致 主库响应应用程序的请求速度变慢。此外，传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力 主库同步数据压力过大怎么办？ -- “主 - 从 - 从”模式 主从库模式中，所有的从库都是和主库连接，所有的全量复制也都是和主库进行的。现在，可以通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上。 1.2.3. 主从库间的网络断了怎么办？ 在 Redis 2.8 之前，如果主从库在命令传播时出现了网络闪断，那么，从库就会和主库重新进行一次全量复制，开销非常大 从 Redis 2.8 开始，网络断了之后，主从库会采用增量复制的方式继续同步 当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。 repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置 主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset之间的差距 此时，主库只用把 master_repl_offset 和 slave_repl_offset之间的命令操作同步给从库就行 因为 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入， 此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致 一般而言，我们可以调整 repl_backlog_size 这个参数,repl_backlog_size = 缓冲空间大小 2 (缓冲空间大小 = 主库写入命令速度 操作大小 - 主从库间网络传输命令速度 * 操作大小) 1.2.4. 为什么主从库间的复制不使用 AOF 呢？ 对于从库来说，RDB文件可以更迅速的数据同步 AOF文件过大，网络传输比较耗时 1.2.5. 小结 全量复制虽然耗时，但是对于从库来说，如果是第一次同步，全量复制是无法避免的，所以，我给你一个小建议：一个 Redis 实例的数据库不要太大，一个实例大小在几 GB 级别比较合适，这样可以减少 RDB 文件生成、传输和重新加载的开销 为了避免多个从库同时和主库进行全量复制，给主库过大的同步压力，我们也可以采用“主 - 从 - 从”这一级联模式，来缓解主库的压力。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"4.Redis原理/核心设计/6.哨兵机制.html":{"url":"4.Redis原理/核心设计/6.哨兵机制.html","title":"6.哨兵机制","keywords":"","body":"1.1. 哨兵模式1.1.1. 哨兵机制的基本流程1.1.2. 在监控任务中，哨兵怎么判断主库是否处于下线状态？1.1.3. 在选主任务中，哨兵如何决定选择哪个从库实例作为主库？1.1. 哨兵模式 在主从架构下，如果从库发生故障，客户端可以继续像主库或者从库发送请求，进行相关操作。 如果主库发生故障，会直接影响到从库的同步，并且客户端进行的写操作都会出现异常 无论写服务终端还是从库无法进行数据同步，都无法接受，所以如果主库挂了，我们需要一个新的主库，或者把从库切换为主库，这就涉及三个问题： 主库是否真的挂掉？ 该选择哪个库作为主库？ 怎么把新的主库信息通知给从库以及客户端？ 这就要提到哨兵机制了。在 Redis 主从集群中，哨兵机制是实现主从库自动切换的关键机制，它有效地解决了主从复制模式下故障转移的这三个问题 1.1.1. 哨兵机制的基本流程 哨兵其实就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务： 监控 选主（选择主库） 通知 监控 监控是指哨兵运行过程中，周期性给所有主从库发送PING命令，检测他们是否依然在线运行， 如果从库在规定时间内没有响应哨兵的PING命令，哨兵会将该库标记为下线状态，如果主库没有响应，哨兵会判定为主库下线，然后开始自动切换主库的流程 选主 主库挂了后，哨兵在从库中根据一定的规则选出一个从库实例，把它作为新的主库 通知 选定完主库后，哨兵会把新的主库的连接信息发送给其它从库，让他们执行replicaof命令，和新的主库建立连接并进行数据的复制，同时将新主库信息通知给客户端 1.1.2. 在监控任务中，哨兵怎么判断主库是否处于下线状态？ 哨兵对于主库的下线判断有主管下线和客观下线两种 主观下线：哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。如果哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记为“主观下线” 如果检测的是从库，那么，哨兵简单地把它标记为“主观下线”就行了，因为从库的下线影响一般不太大，集群的对外服务不会间断 如果检测的是主库，那么，哨兵还不能简单地把它标记为“主观下线”，开启主从切换。因为很有可能存在这么一个情况：那就是哨兵误判了，其实主库并没有故障。可是，一旦启动了主从切换，后续的选主和通知操作都会带来额外的计算和通信开销 什么叫误判？什么情况下会出现误判？ 误判就是主库实际并没有下线，但是哨兵误以为它下线了。误判一般会发生在集群网络压力较大、网络拥塞，或者是主库本身压力较大的情况下 如何减少误判？ 通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群。引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好， 而误判主库下线的情况。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低 客观下线：判断主库是否下线时，不能由一个哨兵说了算，只有大多数的哨兵实例，都判断主库已经“主观下线”了，主库才会被标记为“客观下线”，这个叫法也是表明主库下线成为一 个客观事实了。这个判断原则就是：少数服从多数。同时，这会进一步触发哨兵开始主从切换流程 1.1.3. 在选主任务中，哨兵如何决定选择哪个从库实例作为主库？ 一般来说，哨兵选择新主库的过程称为“筛选 + 打分”。简单来说，在多个从库中，先按照一定的筛选条件，把不符合条件的从库去掉。然后，我们再按照一定的规则，给剩下的从库逐个打分，将得分最高的从库选为新主库 什么是筛选条件？除了要检查从库的当前在线状态，还要判断它之前的网络连接状态 如果从库总是和主库断连，而且断连次数超出了一定的阈值，我们就有理由相信，这个从库的网络状况并不是太好，就可以把这个从库筛掉了 具体怎么判断呢？你使用配置项 down-after-milliseconds * 10。其中，down-after\u0002milliseconds 是我们认定主从库断连的最大连接超时时间。 如果在 down-after\u0002milliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好，不适合作为新主库 根据什么进行打分？ 从库优先级、从库复制进度以及从库 ID 号 按照三个规则依次进行三轮打分，这三个规则分别是从库优先级、从库复制进度以及从库 ID 号。 只要在某一轮中，有从库得分最高，那么它就是主库了，选主过程到此结束。如果没有出现得分最高的从库，那么就继续进行下一轮 第一轮，优先级最高的从库得分高 用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级。比如，有两个从库，它们的内存大小不一样，你可以手动给内存大的实例设置一个高优先级。在选主时， 哨兵会给优先级高的从库打高分，如果有一个从库优先级最高，那么它就是新主库了。如果从库的优先级都一样，那么哨兵开始第二轮打分。 第二轮，和旧主库同步程度最接近的从库得分高 如果选择和旧主库同步最接近的那个从库作为主库，那么，这个新主库上就有最新的数据 主从库同步时有个命令传播的过程。在这个过程中，主库会用master_repl_offset 记录当前的最新写操作在 repl_backlog_buffer 中的位置，而从库会 用 slave_repl_offset 这个值记录当前的复制进度此时，我们想要找的从库，它的 slave_repl_offset 需要最接近 master_repl_offset。如果 在所有从库中，有从库的 slave_repl_offset 最接近 master_repl_offset，那么它的得分就最高，可以作为新主库 第三轮，ID 号小的从库得分高 每个实例都会有一个 ID，这个 ID 就类似于这里的从库的编号，在优先级和复制进度都相同的情况下，ID 号最小的从库得分最高，会被选为新主库 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"4.Redis原理/核心设计/7.哨兵集群.html":{"url":"4.Redis原理/核心设计/7.哨兵集群.html","title":"7.哨兵集群","keywords":"","body":"1.1. 哨兵集群1.1.1. 基于 pub/sub 机制的哨兵集群组成1.1.2. 基于 pub/sub 机制的客户端事件通知1.1.3. 由哪个哨兵执行主从切换？1.1. 哨兵集群 如果有哨兵实例在运行时发生了故障，主从库还能正常切换吗？ 一旦多个实例组成了哨兵集群，即使有哨兵实例出现故障挂掉了，其他哨兵还能继续协作完成主从库切换的工作，包括判定主库是不是处于下线状态，选择新主库，以及通知从库和客户端 在配置哨兵的信息时，我们只需要用到下面的这个配置项，设置主库的 IP 和端口，并没有配置其他哨兵的连接信息 sentinel monitor 这些哨兵实例既然都不知道彼此的地址，又是怎么组成集群的呢? 1.1.1. 基于 pub/sub 机制的哨兵集群组成 哨兵实例之间可以相互发现，要归功于 Redis 提供的 pub/sub 机制，也就是发布 / 订阅机制 哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP 和端口）。同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当 多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口 除了哨兵实例，我们自己编写的应用程序也可以通过 Redis 进行消息的发布和订阅。所以，为了区分不同应用的消息，Redis 会以频道的形式，对这些消息进行分门别类的管理。 所谓的频道，实际上就是消息的类别。当消息类别相同时，它们就属于同一个频道。反之，就属于不同的频道。只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换 在主从集群中，主库上有一个名为__sentinel__:hello的频道，不同哨兵就是通过它来相互发现，实现互相通信的。 哨兵除了彼此之间建立起连接形成集群外，还需要和从库建立连接。这是因为，在哨兵的监控任务中，它需要对主从库都进行心跳判断，而且在主从库切换完成后，它还需要通知从库，让它们和新主库进行同步 哨兵如何知道从库的ip地址和端口？ 这是由哨兵向主库发送 INFO 命令来完成的。就像下图所示，哨兵 2 给主库发送 INFO 命令，主库接受到这个命令后，就会把从库列表返回给哨兵。接着，哨兵就可以根据从库列 表中的连接信息，和每个从库建立连接，并在这个连接上持续地对从库进行监控。哨兵 1和 3 可以通过相同的方法和从库建立连接 总结： 通过 pub/sub 机制，哨兵之间可以组成集群，同时，哨兵又通过 INFO 命令，获得了从库连接信息，也能和从库建立连接，并进行监控 1.1.2. 基于 pub/sub 机制的客户端事件通知 在实际使用哨兵时，我们有时会遇到这样的问题：如何在客户端通过监控了解哨兵进行主从切换的过程呢？比如说，主从切换进行到哪一步了？这其实就是要求，客户端能够获取到哨兵集群在监控、选主、切换这个过程中发生的各种事件 哨兵就是一个运行在特定模式下的 Redis 实例，只不过它并不服务请求操作，只是完成监控、选主和通知的任务。所以，每个哨兵实例也提供 pub/sub 机制，客户 端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件 1.1.3. 由哪个哨兵执行主从切换？ 确定由哪个哨兵执行主从切换的过程，和主库“客观下线”的判断过程类似，也是一个“投票仲裁”的过程。在具体了解这个过程前，我们再来看下，判断“客观下线”的仲裁过程 哨兵集群要判定主库“客观下线”，需要有一定数量的实例都认为该主库已经“主观下线”了 任何一个实例只要自身判断主库“主观下线”后，就会给其他哨兵实例发送 is-master-down by-addr 命令。接着，其他实例会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y 相当于赞成票，N 相当于反对票 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"5.MQ/kafka/1.kafka.html":{"url":"5.MQ/kafka/1.kafka.html","title":"1.kafka","keywords":"","body":"1.1.1. kafka调优1.1.1. kafka调优 https://blog.csdn.net/qq_43284469/article/details/123265905 bin/zookeeper-server-start.sh config/zookeeper.properties &>/tmp/zo & bin/kafka-server-start.sh config/server.properties &>/tmp/kafka & bin/kafka-topics.sh --create --topic first --replication-factor 1 --partitions 1 --bootstrap-server 39.108.209.40:2181 screen https://www.cnblogs.com/gotodsp/p/6375005.html 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"5.MQ/1.mq选型.html":{"url":"5.MQ/1.mq选型.html","title":"1.mq选型","keywords":"","body":"1.1.1. 为什么使用消息队列?1.1.2. 消息队列的缺点?1.1.3. kafka、activemq、rabbitmq、rocketmq都有什么优点缺点?1.1.1. 为什么使用消息队列? 解耦,例如a系统要发送数据到bcd三个系统,接口调用发送,这个时候维护会很麻烦,假如这个时候b系统不需要该数据了, e系统又需要该数据,接口的维护就异常麻烦,并且如果bcd系统挂了怎么解决?是不是要重新调用? 如果使用mq进行解耦,只需要让bcd三个系统进行监听消息就可以了,是否重试消费只需要bcd系统自己决定 异步,同样假如一个接口需要abcd四个服务,并且每个服务都要对db进行写操作,这个时候接口的延时会很高,使用mq进行异步处理可以很好的降低接口延迟 削峰,如果每天下午1点会有10w的并发请求,而系统的最大处理能力只有1000,这个时候就可以通过mq进行削峰 1.1.2. 消息队列的缺点? 系统的可用性会降低,消息的重复消费问题?消息丢失怎么解决?消息消费的顺序性如何保证?mq挂了又怎么办? 一致性问题,a系统直接返回结果,bcd如果处理失败怎么解决?数据会不一致 1.1.3. kafka、activemq、rabbitmq、rocketmq都有什么优点缺点? 特性 activemq rabbitmq rocketmq kafka 单机吞吐量 万级,吞吐量比rocketmq和kafka低了一个数量级 万级,吞吐量比rocketmq和kafka低了一个数量级 10万级别,rocketmq是可以支撑高吞吐的mq 10w级别,高吞吐量是kafka的优点之一, 一般配合大数据系统做实时数据计算和日志采集 topic数量对吞吐量的影响 ---- ---- topic达到几百个或几千个级别,会造成吞吐量小幅下降,这是rocketmq的优点,在同等机器的情况下可以支撑大量的topic topic从几十个到上百个时,吞吐量会大幅度下降,同等机器的情况下,kafka要保证topic不可太多 时效性 ms级 微秒级,rabbitmq 的优点,延迟最低 ms级 延迟在ms以内 可用性 高,主从架构实现高可用 高,主从架构实现高可用 非常高,分布式架构 非常高,kafka是分布式的,一个数据多个副本,少量数据宕机,不会丢失数据,不会导致不可用 消息可靠性 较低概率丢失数据 ---- 通过参数优化可以做到0丢失 通过参数优化可以做到0丢失 功能支持 mq领域的功能极具完备 基于erlang开发,所以并发能力强,性能好,延时低 较为完善,扩展性好 功能简单 优劣势总结 非常成熟,偶尔会丢消息,使用较少 性能好延时低,吞吐较低,mq功能完善 接口简单易用,吞吐高,性能好,分布式扩展,可靠性可用性都ok,还支持大规模的topic数量 功能少,优点突出,高吞吐,高可用,可靠性高,分布式任意扩展,缺点是topic数量不能过高影响吞吐,并且kafka有可能重复消费数据 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"5.MQ/2.如何保证mq的高可用.html":{"url":"5.MQ/2.如何保证mq的高可用.html","title":"2.如何保证mq的高可用","keywords":"","body":"1.1. rabbitmq的高可用1.1.1. 单机模式1.1.2. 普通集群模式1.1.3. 镜像集群模式1.2. kafka的高可用1.1. rabbitmq的高可用 RabbitMQ 是比较有代表性的,因为是基于主从做高可用性的 rabbitmq 有三种模式： 单机模式， 普通集群模式， 镜像集群模式 1.1.1. 单机模式 demo用,生产没人用单机 1.1.2. 普通集群模式 多台机器多个rabbitmq实例,创建一个queue只会放到一个mq实例里,但是每个实例都会同步queue的元数据,在进行消息消费的时候,如果连接到a实例,queue的数据在b,那么a实例会从b实例拉取数据 这种模式麻烦不友好,假如存放queue的实例宕机,别的实例就没办法从该实例拉取数据,如果开启持久化,消息虽然不会丢失,但是必须等到机器恢复才可以进行消费,没法做到高可用 1.1.3. 镜像集群模式 rabbitmq 的高可用模式，跟普通集群模式不一样的是，创建的 queue，无论元数据还是queue里的消息都会存在于多个实例上， 然后每次你写消息到queue的时候， 都会自动把消息到多个实例的queue里的消息进行消息同步 好处:任何一个机器宕机都不影响消息的发送和消费,实现可高可用 坏处:开销大,所有的消息都进行同步会有很大的网络带宽压力.没有扩展性,新增机器也包含所有的数据,并没有办法扩展queue 1.2. kafka的高可用 kafka基础架构:多个broker组成,每一个broker是一个节点,创建一个topic会划分为多个partition,每个partition存在于不同的broker上,每个partition只有一部分数据 这就是天然的分布式消息队列，就是说一个topic的数据，是分散放在多个机器上的，每个机器就放一部分数据。 实际上rabbitmq并不是分布式消息队列,只不过提供了集群、HA的机制,无论怎么使用,一个queue的数据都会完整的存放到一个节点里 kafka有replica副本机制,每个partition都有多个副本,副本会分布到不同的broker上,然后所有的replica会选举出一个leader,生产消费都与leader打交道,其他的replica都是follower,写的时候 leader会负责将数据同步到所有的follower,读的时候也是直接读取leader的数据 为什么只能读取leader的数据?随意读写follower会有数据一致性问题 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"5.MQ/3.事务性消息.html":{"url":"5.MQ/3.事务性消息.html","title":"3.事务性消息","keywords":"","body":"1.1. 如何通过消息中间件实现分布式事务1.1.1. 普通消息的处理逻辑1.1.2. 事务性消息1.1.3. 独立消息服务的最终一致性1.1. 如何通过消息中间件实现分布式事务 虽然有基于两阶段提交的XA分布式事务，但是这类方案因为需要资源的全局锁定，导致性能极差； 因此后面就逐渐衍生出了消息最终一致性、TCC等柔性事务的分布式事务方案，现在主要分析一下基于消息的最终一致性方案。 1.1.1. 普通消息的处理逻辑 消息生成者发送消息 MQ收到消息，将消息进行持久化，在存储中新增一条记录 返回ACK给消费者 MQ push 消息给对应的消费者，然后等待消费者返回ACK 如果消息消费者在指定时间内成功返回ack，那么MQ认为消息消费成功，在存储中删除消息，即执行第6步；如果MQ在指定时间内没有收到ACK，则认为消息消费失败，会尝试重新push消息,重复执行4、5、6步骤 MQ删除消息 有可能产生的异常情况： a事务处理成功，服务宕机，事务未提交，消息没有发送出去（仍保持一致性） a事务处理成功，由于网络原因或者MQ宕机，消息没有发送出去，事务回滚（仍保持一致性） a事务处理成功，消息发送成功，但是MQ由于其他原因，导致消息存储失败，事务回滚（仍保持一致性） a事务处理成功，消息存储成功，但是MQ处理超时，b服务ACK确认失败，导致发送方本地事务回滚 （数据不一致） 由上可得，使用普通的方式无论如何都没办法做到消息两方的事务的一致性 1.1.2. 事务性消息 由于传统的处理方式无法解决消息生成者本地事务处理成功与消息发送成功两者的一致性问题，因此事务消息就诞生了，它实现了消息生成者本地事务与消息发送的原子性，保证了消息生成者本地事务处理成功与消息发送成功的最终一致性问题。 事务消息与普通消息的区别就在于消息生产环节，生产者首先预发送一条消息到MQ(这也被称为发送half消息) MQ接受到消息后，先进行持久化，则存储中会新增一条状态为待发送的消息 然后返回ACK给消息生产者，此时MQ不会触发消息推送事件 生产者预发送消息成功后，执行本地事务 执行本地事务，执行完成后，发送执行结果给MQ MQ会根据结果删除或者更新消息状态为可发送 如果消息状态更新为可发送，则MQ会push消息给消费者，后面消息的消费和普通消息是一样的 注意点： 由于MQ通常都会保证消息能够投递成功，因此，如果业务没有及时返回ACK结果，那么就有可能造成MQ的重复消息投递问题。因此，对于消息最终一致性的方案，消息的消费者必须要对消息的消费支持幂等，不能造成同一条消息的重复消费的情况。 有可能产生的异常情况： 消息未存储，业务操作未执行 （仍保持一致性） 存储待发送消息成功，但是ACK失败，导致业务未执行(可能是MQ处理超时、网络抖动等原因) (不保持一致) 处理异常：MQ确认业务操作结果，处理消息(删除消息) 存储待发送消息成功，ACK成功，业务执行(可能成功也可能失败)，但是MQ没有收到生产者业务处理的最终结果(不保持一致) 处理异常：MQ确认业务操作结果，处理消息(根据就业务处理结果，更新消息状态，如果业务执行成功，则投递消息，失败则删除消息) 业务处理成功，并且发送结果给MQ，但是MQ更新消息失败，导致消息状态依旧为待发送 处理异常：MQ确认业务操作结果，处理消息(根据就业务处理结果，更新消息状态，如果业务执行成功，则投递消息，失败则删除消息) 现在目前较为主流的MQ，比如ActiveMQ、RabbitMQ、Kafka、RocketMQ等，只有RocketMQ支持事务消息。 RocketMQ就是其内部实现会有一个定时任务，去轮训状态为待发送的消息，然后给producer发送check请求，而producer必须实现一个check监听器，监听器的内容通常就是去检查与之对应的本地事务是否成功(一般就是查询DB)，如果成功了，则MQ会将消息设置为可发送，否则就删除消息。 1.1.3. 独立消息服务的最终一致性 消息生产者调用消息服务系统的预发送消息接口 消息服务系统存储消息，状态为待发送 消息生产者执行业务操作 发送业务处理结果给消息服务系统（如果出现问题，则还有定时任务去轮训长时间为待发送状态的数据，再次反调用生产者的消息确认接口），消息状态改为可发送 定时轮训状态为可发送的消息发送消息给mq mq确认收到消息后ack告知消息服务系统收到消息 mq存储消息 mq发送消息给消息消费者，保证幂等 消费者进行业务处理 返回ack（如果消息消费者失败，则扔回队列继续消费） 独立消息服务的最终一致性最核心做法就是在执行业务操作前，调用预发送接口，并且预发送与业务数据的记录必须在同一个事务内完成，这是该方案的前提核心保障。 预发送成功后，通过一个定时任务到DB中去轮训状态为待发送的消息，然后将消息投递给MQ。这个过程中可能存在消息投递失败的可能，此时就依靠重试机制来保证，直到成功收到MQ的ACK确认之后，再将消息状态更新或者消息清除； 而后面消息的消费失败的话，则依赖MQ本身的重试来完成，其最后做到两边系统数据的最终一致性。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"6.Spring/1.Spring的Bean的生命周期.html":{"url":"6.Spring/1.Spring的Bean的生命周期.html","title":"1.Spring的Bean的生命周期","keywords":"","body":"1.1. Bean的生命周期1.1.1. 加载配置1.1.2. bean流程1.1.3. 初始化1.1. Bean的生命周期 Spring 的生命周期大概可分为四个阶段： 实例化 Instantiation 属性赋值 Populate 初始化 Initialization 销毁 Destruction 1.1.1. 加载配置 在Spring实例化Bean之前还有如何将SpringBean的配置信息加载成为BeanDefinition，Spring采用策略模式定义了一个BeanDefinitionReader接口 1.1.2. bean流程 在BeanDefinition加载完成后进行bean的实例化 BeanFactoryPostProcessor BeanFactoryPostProcessor是spring初始化bean的扩展点 BeanFactoryPostProcessor可以对bean的定义（配置元数据）进行处理。也就是说，Spring IoC容器允许BeanFactoryPostProcessor在容器实际实例化任何其它的bean之前读取配置元数据，并有可能修改它 可以配置多个BeanFactoryPostProcessor。能通过设置'order'属性来控制BeanFactoryPostProcessor的执行次序 BeanFactoryPostProcessor可以修改BeanDefinition，但是绝对不可以触发bean的实例化，会破坏容器造成预估不到的副作用 实例化 完成BeanFactoryPostProcessor的处理后进行bean的实例化， 实例化之前有一个重要的扩展点 —— InstantiationAwareBeanPostProcessor InstantiationAwareBeanPostProcessor接口继承BeanPostProcessor接口，它内部提供了3个方法，再加上BeanPostProcessor接口内部的2个方法， 所以实现这个接口需要实现5个方法。InstantiationAwareBeanPostProcessor接口的主要作用在于目标对象的实例化过程中需要处理的事情，包括实例化对象的前后过程以及实例的属性设置 postProcessBeforeInstantiation方法是最先执行的方法，它在目标对象实例化之前调用，该方法的返回值类型是Object，我们可以返回任何类型的值。 由于这个时候目标对象还未实例化，所以这个返回值可以用来代替原本该生成的目标对象的实例(比如代理对象)。如果该方法的返回值代替原本该生成的目标对象， 后续只有postProcessAfterInitialization方法会调用，其它方法不再调用；否则按照正常的流程走 bean实例化完成后会进行属性的装配，将依赖bean注入到属性中 1.1.3. 初始化 初始化前后会调用BeanPostProcessor的postProcessorBeforeInstantiation方法和postProcessorAfterInstantiation BeanPostProcessor接口的作用是在Spring完成实例化之后，对Spring容器实例化的Bean添加一些自定义的处理逻辑 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"6.Spring/2.Spring的Aop原理.html":{"url":"6.Spring/2.Spring的Aop原理.html","title":"2.Spring的Aop原理","keywords":"","body":"1.1. Spring AOP代理对象的生成1.1.1. cglib和jdk动态代理的区别：1.1.2. spring何时使用cglib和jdk1.1.3. JDK动态代理和cglib生成字节码的区别1.1.4. CGlib比JDK快？1.1. Spring AOP代理对象的生成 Spring提供了两种方式来生成代理对象: JDKProxy和Cglib， 具体使用哪种方式生成由AopProxyFactory根据AdvisedSupport对象的配置来决定。 默认的策略是如果目标类是接口，则使用JDK动态代理技术，否则使用Cglib来生成代理 1.1.1. cglib和jdk动态代理的区别： JDK动态代理 利用拦截器（拦截器必须实现InvocationHandler）加上反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理 CGLIB动态代理 利用ASM开源包，对代理对象类的class文件加载进行修改字节码生成子类来处理 1.1.2. spring何时使用cglib和jdk 如果目标对象实现了接口，默认情况使用jdk动态代理实现aop 如果目标对象没有使用接口，则通过cglib来进行动态代理 同样可以全部强制使用cglib 1.1.3. JDK动态代理和cglib生成字节码的区别 jdk动态代理只能对实现接口的类进行代理，而不能针对类 cglib是针对类进行代理，主要是对指定的类生成一个子类，覆盖其中的方法， 并覆盖其中方法实现增强，但是因为采用的是继承，所以该类或方法最好不要声明成final， 对于final类或方法，是无法继承的。 1.1.4. CGlib比JDK快？ 使用CGLib实现动态代理，CGLib底层采用ASM字节码生成框架，使用字节码技术生成代理类， 在jdk6之前比使用Java反射效率要高。唯一需要注意的是，CGLib不能对声明为final的方法进行代理，因为CGLib原理是动态生成被代理类的子类。 在jdk6、jdk7、jdk8逐步对JDK动态代理优化之后，在调用次数较少的情况下，JDK代理效率高于CGLIB代理效率， 只有当进行大量调用的时候，jdk6和jdk7比CGLIB代理效率低一点，但是到jdk8的时候，jdk代理效率高于CGLIB代理， 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"6.Spring/3.三级缓存解决循环依赖.html":{"url":"6.Spring/3.三级缓存解决循环依赖.html","title":"3.三级缓存解决循环依赖","keywords":"","body":"1.1. spring如何解决循环依赖1.1.1. 为什么不是二级缓存？（解决aop代理对象）1.1. spring如何解决循环依赖 spring在填充属性时，如果发现该属性还没有在spring生成，则会跑去生成属性对象实例 我们可以看到填充属性的时候，spring会提前将已经实例化的bean通过ObjectFactory半成品暴露出去，为什么称为半成品是因为这时候的bean对象实例化，但是未进行属性填充，是一个不完整的bean实例对象 spring利用singletonObjects, earlySingletonObjects, singletonFactories三级缓存去解决的，所说的缓存其实也就是三个Map 可以看到三级缓存各自保存的对象，这里重点关注二级缓存earlySingletonObjects和三级缓存singletonFactory，一级缓存可以进行忽略。前面我们讲过先实例化的bean会通过ObjectFactory半成品提前暴露在三级缓存中 singletonFactory是传入的一个匿名内部类，调用ObjectFactory.getObject()最终会调用getEarlyBeanReference方法。再来看看循环依赖中是怎么拿其它半成品的实例对象的。 我们假设现在有这样的场景AService依赖BService，BService依赖AService ​ 1. AService首先实例化，实例化通过ObjectFactory半成品暴露在三级缓存中 ​ 2. 填充属性BService，发现BService还未进行过加载，就会先去加载BService ​ 3. 再加载BService的过程中，实例化，也通过ObjectFactory半成品暴露在三级缓存 ​ 4. 填充属性AService的时候，这时候能够从三级缓存中拿到半成品的ObjectFactory 拿到ObjectFactory对象后，调用ObjectFactory.getObject()方法最终会调用getEarlyBeanReference()方法，getEarlyBeanReference这个方法主要逻辑大概描述下如果bean被AOP切面代理则返回的是beanProxy对象，如果未被代理则返回的是原bean实例，这时我们会发现能够拿到bean实例(属性未填充)，然后从三级缓存移除，放到二级缓存earlySingletonObjects中，而此时B注入的是一个半成品的实例A对象，不过随着B初始化完成后，A会继续进行后续的初始化操作，最终B会注入的是一个完整的A实例，因为在内存中它们是同一个对象。下面是重点，我们发现这个二级缓存好像显得有点多余，好像可以去掉，只需要一级和三级缓存也可以做到解决循环依赖的问题？？？ 1.1.1. 为什么不是二级缓存？（解决aop代理对象） 首先如果存在aop那么容器终注入的应该是代理对象，所以如果没有AOP的话确实可以两级缓存就可以解决循环依赖的问题，如果加上AOP，两级缓存是无法解决的，不可能每次执行singleFactory.getObject()方法都给我产生一个新的代理对象，所以还要借助另外一个缓存来保存产生的代理对象 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"7.Netty/1.传统IO.html":{"url":"7.Netty/1.传统IO.html","title":"1.传统IO","keywords":"","body":"1. Netty简介1.1. Netty 的介绍1.2. Netty 的应用场景1.2.1. 互联网行业1.2.2. 游戏行业1.2.3. 大数据领域2. Java BIO编程2.1. I/O 模型2.2. BIO、NIO、AIO 使用场景分析2.3. Java BIO 基本介绍2.4. Java BIO 工作机制2.5. Java BIO 应用实例2.6. 问题分析3. Java NIO编程3.1. Java NIO 基本介绍3.2. NIO 和 BIO 的比较3.3. NIO 三大核心原理示意图3.3.1. Selector、Channel 和 Buffer 关系图（简单版）3.4. 缓冲区（Buffer）3.4.1. 基本介绍3.4.2. Buffer 类及其子类3.4.3. ByteBuffer3.5. 通道（Channel）3.5.1. 基本介绍3.5.2. FileChannel 类3.5.3. 应用实例1 - 本地文件写数据3.5.4. 应用实例2 - 本地文件读数据3.5.5. 应用实例3 - 使用一个 Buffer 完成文件读取、写入3.5.6. 应用实例4 - 拷贝文件 transferFrom 方法3.5.7. 关于 Buffer 和 Channel 的注意事项和细节3.6. Selector（选择器）3.6.1. 基本介绍3.6.2. Selector 示意图和特点说明3.6.3. Selector 类相关方法3.6.4. 注意事项3.7. NIO 非阻塞网络编程原理分析图3.8. NIO 非阻塞网络编程快速入门3.8.1. SelectionKey3.8.2. ServerSocketChannel3.8.3. SocketChannel3.9. NIO网络编程应用实例 - 群聊系统3.10. Java AIO 基本介绍3.11. BIO、NIO、AIO 对比表1. Netty简介 1.1. Netty 的介绍 Netty 是由 JBOSS 提供的一个 Java 开源框架，现为 Github 上的独立项目。 Netty 是一个异步的、基于事件驱动的网络应用框架，用以快速开发高性能、高可靠性的网络 IO 程序。 Netty 主要针对在 TCP 协议下，面向 Client 端的高并发应用，或者 Peer-to-Peer 场景下的大量数据持续传输的应用。 Netty 本质是一个 NIO 框架，适用于服务器通讯相关的多种应用场景。 要透彻理解 Netty，需要先学习 NIO，这样我们才能阅读 Netty 的源码。 相对简单的一个体系图 1.2. Netty 的应用场景 1.2.1. 互联网行业 互联网行业：在分布式系统中，各个节点之间需要远程服务调用，高性能的 RPC 框架必不可少，Netty 作为异步高性能的通信框架，往往作为基础通信组件被这些 RPC 框架使用。 典型的应用有：阿里分布式服务框架 Dubbo 的 RPC 框 架使用 Dubbo 协议进行节点间通信，Dubbo 协议默认使用 Netty 作为基础通信组件，用于实现各进程节点之间的内部通信。 1.2.2. 游戏行业 无论是手游服务端还是大型的网络游戏，Java 语言得到了越来越广泛的应用。 Netty 作为高性能的基础通信组件，提供了 TCP/UDP 和 HTTP 协议栈，方便定制和开发私有协议栈，账号登录服务器。 地图服务器之间可以方便的通过 Netty 进行高性能的通信。 1.2.3. 大数据领域 经典的 Hadoop 的高性能通信和序列化组件 Avro 的 RPC 框架，默认采用 Netty 进行跨界点通信。 它的 NettyService 基于 Netty 框架二次封装实现。 2. Java BIO编程 2.1. I/O 模型 I/O 模型简单的理解：就是用什么样的通道进行数据的发送和接收，很大程度上决定了程序通信的性能。 Java 共支持 3 种网络编程模型 I/O 模式：BIO、NIO、AIO。 Java BIO：同步并阻塞（传统阻塞型），服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销。【简单示意图】 Java NIO：同步非阻塞，服务器实现模式为一个线程处理多个请求（连接），即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有 I/O 请求就进行处理。【简单示意图】 Java AIO(NIO.2)：异步非阻塞，AIO 引入异步通道的概念，采用了 Proactor 模式，简化了程序编写，有效的请求才启动线程，它的特点是先由操作系统完成后才通知服务端程序启动线程去处理，一般适用于连接数较多且连接时间较长的应用。 2.2. BIO、NIO、AIO 使用场景分析 BIO 方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4 以前的唯一选择，但程序简单易理解。 NIO 方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，弹幕系统，服务器间通讯等。编程比较复杂，JDK1.4 开始支持。 AIO 方式使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用 OS 参与并发操作，编程比较复杂，JDK7 开始支持。 2.3. Java BIO 基本介绍 Java BIO 就是传统的 Java I/O 编程，其相关的类和接口在 java.io。 BIO(BlockingI/O)：同步阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，可以通过线程池机制改善（实现多个客户连接服务器）。【后有应用实例】 BIO 方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4 以前的唯一选择，程序简单易理解。 2.4. Java BIO 工作机制 对 BIO 编程流程的梳理 服务器端启动一个 ServerSocket。 客户端启动 Socket 对服务器进行通信，默认情况下服务器端需要对每个客户建立一个线程与之通讯。 客户端发出请求后，先咨询服务器是否有线程响应，如果没有则会等待，或者被拒绝。 如果有响应，客户端线程会等待请求结束后，再继续执行。 2.5. Java BIO 应用实例 实例说明： 使用 BIO 模型编写一个服务器端，监听 6666 端口，当有客户端连接时，就启动一个线程与之通讯。 要求使用线程池机制改善，可以连接多个客户端。 服务器端可以接收客户端发送的数据（telnet 方式即可）。 代码演示： package com.atguigu.bio; import java.io.InputStream; import java.net.ServerSocket; import java.net.Socket; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class BIOServer { public static void main(String[] args) throws Exception { //线程池机制 //思路 //1. 创建一个线程池 //2. 如果有客户端连接，就创建一个线程，与之通讯(单独写一个方法) ExecutorService newCachedThreadPool = Executors.newCachedThreadPool(); //创建ServerSocket ServerSocket serverSocket = new ServerSocket(6666); System.out.println(\"服务器启动了\"); while (true) { System.out.println(\"线程信息id = \" + Thread.currentThread().getId() + \"名字 = \" + Thread.currentThread().getName()); //监听，等待客户端连接 System.out.println(\"等待连接....\"); //会阻塞在accept() final Socket socket = serverSocket.accept(); System.out.println(\"连接到一个客户端\"); //就创建一个线程，与之通讯(单独写一个方法) newCachedThreadPool.execute(new Runnable() { public void run() {//我们重写 //可以和客户端通讯 handler(socket); } }); } } //编写一个handler方法，和客户端通讯 public static void handler(Socket socket) { try { System.out.println(\"线程信息id = \" + Thread.currentThread().getId() + \"名字 = \" + Thread.currentThread().getName()); byte[] bytes = new byte[1024]; //通过socket获取输入流 InputStream inputStream = socket.getInputStream(); //循环的读取客户端发送的数据 while (true) { System.out.println(\"线程信息id = \" + Thread.currentThread().getId() + \"名字 = \" + Thread.currentThread().getName()); System.out.println(\"read....\"); int read = inputStream.read(bytes); if (read != -1) { System.out.println(new String(bytes, 0, read));//输出客户端发送的数据 } else { break; } } } catch (Exception e) { e.printStackTrace(); } finally { System.out.println(\"关闭和client的连接\"); try { socket.close(); } catch (Exception e) { e.printStackTrace(); } } } } 2.6. 问题分析 每个请求都需要创建独立的线程，与对应的客户端进行数据 Read，业务处理，数据 Write。 当并发数较大时，需要创建大量线程来处理连接，系统资源占用较大。 连接建立后，如果当前线程暂时没有数据可读，则线程就阻塞在 Read 操作上，造成线程资源浪费。 3. Java NIO编程 3.1. Java NIO 基本介绍 Java NIO 全称 Java non-blocking IO，是指 JDK 提供的新 API。从 JDK1.4 开始，Java 提供了一系列改进的输入/输出的新特性，被统称为 NIO（即 NewIO），是同步非阻塞的。 NIO 相关类都被放在 java.nio 包及子包下，并且对原 java.io 包中的很多类进行改写。【基本案例】 NIO 有三大核心部分：Channel（通道）、Buffer（缓冲区）、Selector（选择器） 。 NIO 是面向缓冲区，或者面向块编程的。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动，这就增加了处理过程中的灵活性，使用它可以提供非阻塞式的高伸缩性网络。 Java NIO 的非阻塞模式，使一个线程从某通道发送请求或者读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取，而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。非阻塞写也是如此，一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。【后面有案例说明】 通俗理解：NIO 是可以做到用一个线程来处理多个操作的。假设有 10000 个请求过来,根据实际情况，可以分配 50 或者 100 个线程来处理。不像之前的阻塞 IO 那样，非得分配 10000 个。 HTTP 2.0 使用了多路复用的技术，做到同一个连接并发处理多个请求，而且并发请求的数量比 HTTP 1.1 大了好几个数量级。 案例说明 NIO 的 Buffer package com.atguigu.nio; import java.nio.IntBuffer; public class BasicBuffer { public static void main(String[] args) { //举例说明 Buffer 的使用(简单说明) //创建一个 Buffer，大小为 5，即可以存放 5 个 int IntBuffer intBuffer = IntBuffer.allocate(5); //向buffer存放数据 //intBuffer.put(10); //intBuffer.put(11); //intBuffer.put(12); //intBuffer.put(13); //intBuffer.put(14); for (int i = 0; i 3.2. NIO 和 BIO 的比较 BIO 以流的方式处理数据，而 NIO 以块的方式处理数据，块 I/O 的效率比流 I/O 高很多。 BIO 是阻塞的，NIO 则是非阻塞的。 BIO 基于字节流和字符流进行操作，而 NIO 基于 Channel（通道）和 Buffer（缓冲区）进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。Selector（选择器）用于监听多个通道的事件（比如：连接请求，数据到达等），因此使用单个线程就可以监听多个客户端通道。 Buffer和Channel之间的数据流向是双向的 3.3. NIO 三大核心原理示意图 一张图描述 NIO 的 Selector、Channel 和 Buffer 的关系。 3.3.1. Selector、Channel 和 Buffer 关系图（简单版） 关系图的说明: 每个 Channel 都会对应一个 Buffer。 Selector 对应一个线程，一个线程对应多个 Channel（连接）。 该图反应了有三个 Channel 注册到该 Selector //程序 程序切换到哪个 Channel 是由事件决定的，Event 就是一个重要的概念。 Selector 会根据不同的事件，在各个通道上切换。 Buffer 就是一个内存块，底层是有一个数组。 数据的读取写入是通过 Buffer，这个和 BIO是不同的，BIO 中要么是输入流，或者是输出流，不能双向，但是 NIO 的 Buffer 是可以读也可以写，需要 flip 方法切换 Channel 是双向的，可以返回底层操作系统的情况，比如 Linux，底层的操作系统通道就是双向的。 3.4. 缓冲区（Buffer） 3.4.1. 基本介绍 缓冲区（Buffer）：缓冲区本质上是一个可以读写数据的内存块，可以理解成是一个容器对象（含数组），该对象提供了一组方法，可以更轻松地使用内存块，，缓冲区对象内置了一些机制，能够跟踪和记录缓冲区的状态变化情况。Channel 提供从文件、网络读取数据的渠道，但是读取或写入的数据都必须经由 Buffer，如图:【后面举例说明】 3.4.2. Buffer 类及其子类 在 NIO 中，Buffer 是一个顶层父类，它是一个抽象类，类的层级关系图： Buffer 类定义了所有的缓冲区都具有的四个属性来提供关于其所包含的数据元素的信息： Buffer 类相关方法一览 3.4.3. ByteBuffer 从前面可以看出对于 Java 中的基本数据类型（boolean 除外），都有一个 Buffer 类型与之相对应，最常用的自然是 ByteBuffer 类（二进制数据），该类的主要方法如下： 3.5. 通道（Channel） 3.5.1. 基本介绍 NIO 的通道类似于流，但有些区别如下： 通道可以同时进行读写，而流只能读或者只能写 通道可以实现异步读写数据 通道可以从缓冲读数据，也可以写数据到缓冲: BIO 中的 Stream 是单向的，例如 FileInputStream 对象只能进行读取数据的操作，而 NIO 中的通道（Channel）是双向的，可以读操作，也可以写操作。 Channel 在 NIO 中是一个接口 public interface Channel extends Closeable{} 常用的 Channel 类有：FileChannel、DatagramChannel、ServerSocketChannel 和 SocketChannel。【ServerSocketChanne 类似 ServerSocket、SocketChannel 类似 Socket】 FileChannel 用于文件的数据读写，DatagramChannel 用于 UDP 的数据读写，ServerSocketChannel 和 SocketChannel 用于 TCP 的数据读写。 图示 3.5.2. FileChannel 类 FileChannel 主要用来对本地文件进行 IO 操作，常见的方法有 public int read(ByteBuffer dst)，从通道读取数据并放到缓冲区中 public int write(ByteBuffer src)，把缓冲区的数据写到通道中 public long transferFrom(ReadableByteChannel src, long position, long count)，从目标通道中复制数据到当前通道 public long transferTo(long position, long count, WritableByteChannel target)，把数据从当前通道复制给目标通道 3.5.3. 应用实例1 - 本地文件写数据 实例要求： 使用前面学习后的 ByteBuffer（缓冲）和 FileChannel（通道），将 \"hello,尚硅谷\" 写入到 file01.txt 中 文件不存在就创建 代码演示 package com.atguigu.nio; import java.io.FileOutputStream; import java.nio.ByteBuffer; import java.nio.channels.FileChannel; public class NIOFileChannel01 { public static void main(String[] args) throws Exception { String str = \"hello,尚硅谷\"; //创建一个输出流 -> channel FileOutputStream fileOutputStream = new FileOutputStream(\"d:\\\\file01.txt\"); //通过 fileOutputStream 获取对应的 FileChannel //这个 fileChannel 真实类型是 FileChannelImpl FileChannel fileChannel = fileOutputStream.getChannel(); //创建一个缓冲区 ByteBuffer ByteBuffer byteBuffer = ByteBuffer.allocate(1024); //将 str 放入 byteBuffer byteBuffer.put(str.getBytes()); //对 byteBuffer 进行 flip byteBuffer.flip(); //将 byteBuffer 数据写入到 fileChannel fileChannel.write(byteBuffer); fileOutputStream.close(); } } 3.5.4. 应用实例2 - 本地文件读数据 实例要求： 使用前面学习后的 ByteBuffer（缓冲）和 FileChannel（通道），将 file01.txt 中的数据读入到程序，并显示在控制台屏幕 假定文件已经存在 代码演示 package com.atguigu.nio; import java.io.File; import java.io.FileInputStream; import java.nio.ByteBuffer; import java.nio.channels.FileChannel; public class NIOFileChannel02 { public static void main(String[] args) throws Exception { //创建文件的输入流 File file = new File(\"d:\\\\file01.txt\"); FileInputStream fileInputStream = new FileInputStream(file); //通过 fileInputStream 获取对应的 FileChannel -> 实际类型 FileChannelImpl FileChannel fileChannel = fileInputStream.getChannel(); //创建缓冲区 ByteBuffer byteBuffer = ByteBuffer.allocate((int)file.length()); //将通道的数据读入到 Buffer fileChannel.read(byteBuffer); //将 byteBuffer 的字节数据转成 String System.out.println(new String(byteBuffer.array())); fileInputStream.close(); } } 3.5.5. 应用实例3 - 使用一个 Buffer 完成文件读取、写入 实例要求： 使用 FileChannel（通道）和方法 read、write，完成文件的拷贝 拷贝一个文本文件 1.txt，放在项目下即可 代码演示 package com.atguigu.nio; import java.io.FileInputStream; import java.io.FileOutputStream; import java.nio.ByteBuffer; import java.nio.channels.FileChannel; public class NIOFileChannel03 { public static void main(String[] args) throws Exception { FileInputStream fileInputStream = new FileInputStream(\"1.txt\"); FileChannel fileChannel01 = fileInputStream.getChannel(); FileOutputStream fileOutputStream = new FileOutputStream(\"2.txt\"); FileChannel fileChannel02 = fileOutputStream.getChannel(); ByteBuffer byteBuffer = ByteBuffer.allocate(512); while (true) { //循环读取 //这里有一个重要的操作，一定不要忘了 /* public final Buffer clear() { position = 0; limit = capacity; mark = -1; return this; } */ byteBuffer.clear(); //清空 buffer int read = fileChannel01.read(byteBuffer); System.out.println(\"read = \" + read); if (read == -1) { //表示读完 break; } //将 buffer 中的数据写入到 fileChannel02--2.txt byteBuffer.flip(); fileChannel02.write(byteBuffer); } //关闭相关的流 fileInputStream.close(); fileOutputStream.close(); } } 3.5.6. 应用实例4 - 拷贝文件 transferFrom 方法 实例要求： 使用 FileChannel（通道）和方法 transferFrom，完成文件的拷贝 拷贝一张图片 代码演示 package com.atguigu.nio; import java.io.FileInputStream; import java.io.FileOutputStream; import java.nio.channels.FileChannel; public class NIOFileChannel04 { public static void main(String[] args) throws Exception { //创建相关流 FileInputStream fileInputStream = new FileInputStream(\"d:\\\\a.jpg\"); FileOutputStream fileOutputStream = new FileOutputStream(\"d:\\\\a2.jpg\"); //获取各个流对应的 FileChannel FileChannel sourceCh = fileInputStream.getChannel(); FileChannel destCh = fileOutputStream.getChannel(); //使用 transferForm 完成拷贝 destCh.transferFrom(sourceCh, 0, sourceCh.size()); //关闭相关通道和流 sourceCh.close(); destCh.close(); fileInputStream.close(); fileOutputStream.close(); } } 3.5.7. 关于 Buffer 和 Channel 的注意事项和细节 ByteBuffer 支持类型化的 put 和 get，put 放入的是什么数据类型，get 就应该使用相应的数据类型来取出，否则可能有 BufferUnderflowException 异常。【举例说明】 package com.atguigu.nio; import java.nio.ByteBuffer; public class NIOByteBufferPutGet { public static void main(String[] args) { //创建一个 Buffer ByteBuffer buffer = ByteBuffer.allocate(64); //类型化方式放入数据 buffer.putInt(100); buffer.putLong(9); buffer.putChar('尚'); buffer.putShort((short) 4); //取出 buffer.flip(); System.out.println(); System.out.println(buffer.getInt()); System.out.println(buffer.getLong()); System.out.println(buffer.getChar()); System.out.println(buffer.getShort()); } } 可以将一个普通 Buffer 转成只读 Buffer【举例说明】 package com.atguigu.nio; import java.nio.ByteBuffer; public class ReadOnlyBuffer { public static void main(String[] args) { //创建一个 buffer ByteBuffer buffer = ByteBuffer.allocate(64); for (int i = 0; i NIO 还提供了 MappedByteBuffer，可以让文件直接在内存（堆外的内存）中进行修改，而如何同步到文件由 NIO 来完成。【举例说明】 package com.atguigu.nio; import java.io.RandomAccessFile; import java.nio.MappedByteBuffer; import java.nio.channels.FileChannel; /** * 说明 1.MappedByteBuffer 可让文件直接在内存（堆外内存）修改,操作系统不需要拷贝一次 */ public class MappedByteBufferTest { public static void main(String[] args) throws Exception { RandomAccessFile randomAccessFile = new RandomAccessFile(\"1.txt\", \"rw\"); //获取对应的通道 FileChannel channel = randomAccessFile.getChannel(); /** * 参数 1:FileChannel.MapMode.READ_WRITE 使用的读写模式 * 参数 2：0：可以直接修改的起始位置 * 参数 3:5: 是映射到内存的大小（不是索引位置），即将 1.txt 的多少个字节映射到内存 * 可以直接修改的范围就是 0-5 * 实际类型 DirectByteBuffer */ MappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, 0, 5); mappedByteBuffer.put(0, (byte) 'H'); mappedByteBuffer.put(3, (byte) '9'); mappedByteBuffer.put(5, (byte) 'Y');//IndexOutOfBoundsException randomAccessFile.close(); System.out.println(\"修改成功~~\"); } } 前面我们讲的读写操作，都是通过一个 Buffer 完成的，NIO 还支持通过多个 Buffer（即 Buffer数组）完成读写操作，即 Scattering 和 Gathering【举例说明】 package com.atguigu.nio; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.ServerSocketChannel; import java.nio.channels.SocketChannel; import java.util.Arrays; /** * Scattering：将数据写入到 buffer 时，可以采用 buffer 数组，依次写入 [分散] * Gathering：从 buffer 读取数据时，可以采用 buffer 数组，依次读 */ public class ScatteringAndGatheringTest { public static void main(String[] args) throws Exception { //使用 ServerSocketChannel 和 SocketChannel 网络 ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); InetSocketAddress inetSocketAddress = new InetSocketAddress(7000); //绑定端口到 socket，并启动 serverSocketChannel.socket().bind(inetSocketAddress); //创建 buffer 数组 ByteBuffer[] byteBuffers = new ByteBuffer[2]; byteBuffers[0] = ByteBuffer.allocate(5); byteBuffers[1] = ByteBuffer.allocate(3); //等客户端连接 (telnet) SocketChannel socketChannel = serverSocketChannel.accept(); int messageLength = 8; //假定从客户端接收 8 个字节 //循环的读取 while (true) { int byteRead = 0; while (byteRead \"position = \" + buffer.position() + \", limit = \" + buffer.limit()).forEach(System.out::println); } //将所有的 buffer 进行 flip Arrays.asList(byteBuffers).forEach(buffer -> buffer.flip()); //将数据读出显示到客户端 long byteWirte = 0; while (byteWirte { buffer.clear(); }); System.out.println(\"byteRead = \" + byteRead + \", byteWrite = \" + byteWirte + \", messagelength = \" + messageLength); } } } 3.6. Selector（选择器） 3.6.1. 基本介绍 Java 的 NIO，用非阻塞的 IO 方式。可以用一个线程，处理多个的客户端连接，就会使用到 Selector（选择器）。 Selector 能够检测多个注册的通道上是否有事件发生（注意：多个 Channel 以事件的方式可以注册到同一个 Selector），如果有事件发生，便获取事件然后针对每个事件进行相应的处理。这样就可以只用一个单线程去管理多个通道，也就是管理多个连接和请求。 只有在连接/通道真正有读写事件发生时，才会进行读写，就大大地减少了系统开销，并且不必为每个连接都创建一个线程，不用去维护多个线程。 避免了多线程之间的上下文切换导致的开销。 3.6.2. Selector 示意图和特点说明 说明如下： Netty 的 IO 线程 NioEventLoop 聚合了 Selector（选择器，也叫多路复用器），可以同时并发处理成百上千个客户端连接。 当线程从某客户端 Socket 通道进行读写数据时，若没有数据可用时，该线程可以进行其他任务。 线程通常将非阻塞 IO 的空闲时间用于在其他通道上执行 IO 操作，所以单独的线程可以管理多个输入和输出通道。 由于读写操作都是非阻塞的，这就可以充分提升 IO 线程的运行效率，避免由于频繁 I/O 阻塞导致的线程挂起。 一个 I/O 线程可以并发处理 N 个客户端连接和读写操作，这从根本上解决了传统同步阻塞 I/O 一连接一线程模型，架构的性能、弹性伸缩能力和可靠性都得到了极大的提升。 3.6.3. Selector 类相关方法 3.6.4. 注意事项 NIO 中的 ServerSocketChannel 功能类似 ServerSocket、SocketChannel 功能类似 Socket。 Selector 相关方法说明 selector.select(); //阻塞 selector.select(1000); //阻塞 1000 毫秒，在 1000 毫秒后返回 selector.wakeup(); //唤醒 selector selector.selectNow(); //不阻塞，立马返还 3.7. NIO 非阻塞网络编程原理分析图 NIO 非阻塞网络编程相关的（Selector、SelectionKey、ServerScoketChannel 和 SocketChannel）关系梳理图 对上图的说明： 当客户端连接时，会通过 ServerSocketChannel 得到 SocketChannel。 Selector 进行监听 select 方法，返回有事件发生的通道的个数。 将 socketChannel 注册到 Selector 上，register(Selector sel, int ops)，一个 Selector 上可以注册多个 SocketChannel。 注册后返回一个 SelectionKey，会和该 Selector 关联（集合）。 进一步得到各个 SelectionKey（有事件发生）。 在通过 SelectionKey 反向获取 SocketChannel，方法 channel()。 可以通过得到的 channel，完成业务处理。 直接看后面代码吧 3.8. NIO 非阻塞网络编程快速入门 案例： 编写一个 NIO 入门案例，实现服务器端和客户端之间的数据简单通讯（非阻塞） 目的：理解 NIO 非阻塞网络编程机制 package com.atguigu.nio; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.*; import java.util.Iterator; import java.util.Set; public class NIOServer { public static void main(String[] args) throws Exception{ //创建ServerSocketChannel -> ServerSocket ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); //得到一个Selecor对象 Selector selector = Selector.open(); //绑定一个端口6666, 在服务器端监听 serverSocketChannel.socket().bind(new InetSocketAddress(6666)); //设置为非阻塞 serverSocketChannel.configureBlocking(false); //把 serverSocketChannel 注册到 selector 关心 事件为 OP_ACCEPT pos_1 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); System.out.println(\"注册后的selectionkey 数量=\" + selector.keys().size()); // 1 //循环等待客户端连接 while (true) { //这里我们等待1秒，如果没有事件发生, 返回 if(selector.select(1000) == 0) { //没有事件发生 System.out.println(\"服务器等待了1秒，无连接\"); continue; } //如果返回的>0, 就获取到相关的 selectionKey集合 //1.如果返回的>0， 表示已经获取到关注的事件 //2. selector.selectedKeys() 返回关注事件的集合 // 通过 selectionKeys 反向获取通道 Set selectionKeys = selector.selectedKeys(); System.out.println(\"selectionKeys 数量 = \" + selectionKeys.size()); //遍历 Set, 使用迭代器遍历 Iterator keyIterator = selectionKeys.iterator(); while (keyIterator.hasNext()) { //获取到SelectionKey SelectionKey key = keyIterator.next(); //根据key 对应的通道发生的事件做相应处理 if(key.isAcceptable()) { //如果是 OP_ACCEPT, 有新的客户端连接 //该该客户端生成一个 SocketChannel SocketChannel socketChannel = serverSocketChannel.accept(); System.out.println(\"客户端连接成功 生成了一个 socketChannel \" + socketChannel.hashCode()); //将 SocketChannel 设置为非阻塞 socketChannel.configureBlocking(false); //将socketChannel 注册到selector, 关注事件为 OP_READ， 同时给socketChannel //关联一个Buffer socketChannel.register(selector, SelectionKey.OP_READ, ByteBuffer.allocate(1024)); System.out.println(\"客户端连接后 ，注册的selectionkey 数量=\" + selector.keys().size()); //2,3,4.. } if(key.isReadable()) { //发生 OP_READ //通过key 反向获取到对应channel SocketChannel channel = (SocketChannel)key.channel(); //获取到该channel关联的buffer ByteBuffer buffer = (ByteBuffer)key.attachment(); channel.read(buffer); System.out.println(\"form 客户端 \" + new String(buffer.array())); } //手动从集合中移动当前的selectionKey, 防止重复操作 keyIterator.remove(); } } } } pos1： 1、对操作系统有一定了解的同学，就会大概知道这里监听的是一个Accept通道。这个通道的作用就是监听，实际建立连接了还会有一个通道。 2、简单说一下为什么。因为客户端发请求的时候，服务器这边是肯定要先有一个监听通道，监听某个端口是否有客户端要建立链接，如果有客户端想要建立链接，那么会再创建一个和客户端真正通信的通道。 3、如果有其它客户端还想要建立链接，这个Accept监听端口监听到了，就会再创建几个真正的通信通道。 4、也就是Server的一个端口可以建立多个TCP连接，因为IP层协议通过 目标地址+端口+源地址+源端口四个信息识别一个上下文 package com.atguigu.nio; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.SocketChannel; public class NIOClient { public static void main(String[] args) throws Exception{ //得到一个网络通道 SocketChannel socketChannel = SocketChannel.open(); //设置非阻塞 socketChannel.configureBlocking(false); //提供服务器端的ip 和 端口 InetSocketAddress inetSocketAddress = new InetSocketAddress(\"127.0.0.1\", 6666); //连接服务器 if (!socketChannel.connect(inetSocketAddress)) { while (!socketChannel.finishConnect()) { System.out.println(\"因为连接需要时间，客户端不会阻塞，可以做其它工作..\"); } } //...如果连接成功，就发送数据 String str = \"hello, 尚硅谷~\"; //Wraps a byte array into a buffer ByteBuffer buffer = ByteBuffer.wrap(str.getBytes()); //发送数据，将 buffer 数据写入 channel socketChannel.write(buffer); System.in.read(); } } 实际执行效果可以复制代码去试下 3.8.1. SelectionKey SelectionKey，表示 Selector 和网络通道的注册关系，共四种： int OP_ACCEPT：有新的网络连接可以 accept，值为 16 int OP_CONNECT：代表连接已经建立，值为 8 int OP_READ：代表读操作，值为 1 int OP_WRITE：代表写操作，值为 4 源码中： public static final int OP_READ = 1 SelectionKey 相关方法 3.8.2. ServerSocketChannel ServerSocketChannel 在服务器端监听新的客户端 Socket 连接，负责监听，不负责实际的读写操作 相关方法如下 3.8.3. SocketChannel SocketChannel，网络 IO 通道，具体负责进行读写操作。NIO 把缓冲区的数据写入通道，或者把通道里的数据读到缓冲区。 相关方法如下 3.9. NIO网络编程应用实例 - 群聊系统 实例要求： 编写一个 NIO 群聊系统，实现服务器端和客户端之间的数据简单通讯（非阻塞） 实现多人群聊 服务器端：可以监测用户上线，离线，并实现消息转发功能 客户端：通过 Channel 可以无阻塞发送消息给其它所有用户，同时可以接受其它用户发送的消息（有服务器转发得到） 目的：进一步理解 NIO 非阻塞网络编程机制 示意图分析和代码 代码： // 服务端： package com.atguigu.nio.groupchat; import java.io.IOException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.Channel; import java.nio.channels.SelectionKey; import java.nio.channels.Selector; import java.nio.channels.ServerSocketChannel; import java.nio.channels.SocketChannel; import java.util.Iterator; public class GroupChatServer { //定义属性 private Selector selector; private ServerSocketChannel listenChannel; private static final int PORT = 6667; //构造器 //初始化工作 public GroupChatServer() { try { //得到选择器 selector = Selector.open(); //ServerSocketChannel listenChannel = ServerSocketChannel.open(); //绑定端口 listenChannel.socket().bind(new InetSocketAddress(PORT)); //设置非阻塞模式 listenChannel.configureBlocking(false); //将该 listenChannel 注册到 selector listenChannel.register(selector, SelectionKey.OP_ACCEPT); } catch (IOException e) { e.printStackTrace(); } } public void listen() { try { //循环处理 while (true) { int count = selector.select(); if (count > 0) { //有事件处理 // 遍历得到 selectionKey 集合 Iterator iterator = selector.selectedKeys().iterator(); while (iterator.hasNext()) { //取出 selectionkey SelectionKey key = iterator.next(); //监听到 accept if (key.isAcceptable()) { SocketChannel sc = listenChannel.accept(); sc.configureBlocking(false); //将该 sc 注册到 seletor sc.register(selector, SelectionKey.OP_READ); //提示 System.out.println(sc.getRemoteAddress() + \" 上线 \"); } if (key.isReadable()) {//通道发送read事件，即通道是可读的状态 // 处理读(专门写方法..) readData(key); } //当前的 key 删除，防止重复处理 iterator.remove(); } } else { System.out.println(\"等待....\"); } } } catch (Exception e) { e.printStackTrace(); } finally { //发生异常处理.... } } //读取客户端消息 public void readData(SelectionKey key) { SocketChannel channel = null; try { //得到 channel channel = (SocketChannel) key.channel(); //创建 buffer ByteBuffer buffer = ByteBuffer.allocate(1024); int count = channel.read(buffer); //根据 count 的值做处理 if (count > 0) { //把缓存区的数据转成字符串 String msg = new String(buffer.array()); //输出该消息 System.out.println(\"form客户端:\" + msg); //向其它的客户端转发消息(去掉自己),专门写一个方法来处理 sendInfoToOtherClients(msg, channel); } } catch (IOException e) { try { System.out.println(channel.getRemoteAddress() + \"离线了..\"); //取消注册 key.cancel(); //关闭通道 channel.close(); } catch (IOException e2) { e2.printStackTrace(); } } } //转发消息给其它客户(通道) private void sendInfoToOtherClients(String msg, SocketChannel self) throws IOException { System.out.println(\"服务器转发消息中...\"); //遍历所有注册到 selector 上的 SocketChannel,并排除 self for (SelectionKey key : selector.keys()) { //通过 key 取出对应的 SocketChannel Channel targetChannel = key.channel(); //排除自己 if (targetChannel instanceof SocketChannel && targetChannel != self) { //转型 SocketChannel dest = (SocketChannel) targetChannel; //将 msg 存储到 buffer ByteBuffer buffer = ByteBuffer.wrap(msg.getBytes()); //将 buffer 的数据写入通道 dest.write(buffer); } } } public static void main(String[] args) { //创建服务器对象 GroupChatServer groupChatServer = new GroupChatServer(); groupChatServer.listen(); } } // 客户端： package com.atguigu.nio.groupchat; import java.io.IOException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.SelectionKey; import java.nio.channels.Selector; import java.nio.channels.SocketChannel; import java.util.Iterator; import java.util.Scanner; public class GroupChatClient { //定义相关的属性 private final String HOST = \"127.0.0.1\";//服务器的ip private final int PORT = 6667;//服务器端口 private Selector selector; private SocketChannel socketChannel; private String username; //构造器,完成初始化工作 public GroupChatClient() throws IOException { selector = Selector.open(); //连接服务器 socketChannel = SocketChannel.open(new InetSocketAddress(HOST, PORT)); //设置非阻塞 socketChannel.configureBlocking(false); //将 channel 注册到selector socketChannel.register(selector, SelectionKey.OP_READ); //得到 username username = socketChannel.getLocalAddress().toString().substring(1); System.out.println(username + \" is ok...\"); } //向服务器发送消息 public void sendInfo(String info) { info = username + \" 说：\" + info; try { socketChannel.write(ByteBuffer.wrap(info.getBytes())); } catch (IOException e) { e.printStackTrace(); } } //读取从服务器端回复的消息 public void readInfo() { try { int readChannels = selector.select(); if (readChannels > 0) {//有可以用的通道 Iterator iterator = selector.selectedKeys().iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); if (key.isReadable()) { //得到相关的通道 SocketChannel sc = (SocketChannel) key.channel(); //得到一个 Buffer ByteBuffer buffer = ByteBuffer.allocate(1024); //读取 sc.read(buffer); //把读到的缓冲区的数据转成字符串 String msg = new String(buffer.array()); System.out.println(msg.trim()); } } iterator.remove(); //删除当前的 selectionKey,防止重复操作 } else { //System.out.println(\"没有可以用的通道...\"); } } catch (Exception e) { e.printStackTrace(); } } public static void main(String[] args) throws Exception { //启动我们客户端 GroupChatClient chatClient = new GroupChatClient(); //启动一个线程,每个 3 秒，读取从服务器发送数据 new Thread() { public void run() { while (true) { chatClient.readInfo(); try { Thread.currentThread().sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } } } }.start(); //发送数据给服务器端 Scanner scanner = new Scanner(System.in); while (scanner.hasNextLine()) { String s = scanner.nextLine(); chatClient.sendInfo(s); } } } 3.10. Java AIO 基本介绍 JDK7 引入了 AsynchronousI/O，即 AIO。在进行 I/O 编程中，常用到两种模式：Reactor 和 Proactor。Java 的 NIO 就是 Reactor，当有事件触发时，服务器端得到通知，进行相应的处理 AIO 即 NIO2.0，叫做异步不阻塞的 IO。AIO 引入异步通道的概念，采用了 Proactor 模式，简化了程序编写，有效的请求才启动线程，它的特点是先由操作系统完成后才通知服务端程序启动线程去处理，一般适用于连接数较多且连接时间较长的应用 目前 AIO 还没有广泛应用，Netty 也是基于 NIO，而不是 AIO，因此我们就不详解 AIO 了，有兴趣的同学可以参考《Java新一代网络编程模型AIO原理及Linux系统AIO介绍》 3.11. BIO、NIO、AIO 对比表 BIO NIO AIO IO模型 同步阻塞 同步非阻塞（多路复用） 异步非阻塞 编程难度 简单 复杂 复杂 可靠性 差 好 好 吞吐量 低 高 高 举例说明 同步阻塞：到理发店理发，就一直等理发师，直到轮到自己理发。 同步非阻塞：到理发店理发，发现前面有其它人理发，给理发师说下，先干其他事情，一会过来看是否轮到自己. 异步非阻塞：给理发师打电话，让理发师上门服务，自己干其它事情，理发师自己来家给你理发 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"7.Netty/2.Netty实战.html":{"url":"7.Netty/2.Netty实战.html","title":"2.Netty实战","keywords":"","body":"1. Netty 概述1.1. 原生 NIO 存在的问题1.2. Netty 的优点1.3. Netty 版本说明2. Netty 高性能架构设计2.1. 线程模型基本介绍2.2. 传统阻塞 I/O 服务模型2.2.1. 工作原理图2.2.2. 模型特点2.2.3. 问题分析2.3. Reactor 模式2.3.1. 针对传统阻塞 I/O 服务模型的 2 个缺点，解决方案：2.3.2. I/O 复用结合线程池，就是 Reactor 模式基本设计思想，如图2.3.3. Reactor 模式中核心组成2.3.4. Reactor 模式分类2.4. 单 Reactor 单线程2.4.1. 方案说明2.4.2. 方案优缺点分析2.5. 单 Reactor 多线程2.5.1. 方案说明2.5.2. 方案优缺点分析2.6. 主从 Reactor 多线程2.6.1. 工作原理图2.6.2. 方案优缺点说明2.7. Reactor 模式小结2.7.1. 3 种模式用生活案例来理解2.7.2. Reactor 模式具有如下的优点2.8. Netty 模型2.8.1. 工作原理示意图1 - 简单版2.8.2. 工作原理示意图2 - 进阶版2.8.3. 工作原理示意图3 - 详细版2.8.4. Netty 快速入门实例 - TCP 服务2.8.5. 任务队列中的 Task 有 3 种典型使用场景2.8.6. 方案再说明2.9. 异步模型2.9.1. 基本介绍2.9.2. Future 说明2.9.3. 工作原理示意图2.9.4. Future-Listener 机制2.10. 快速入门实例 - HTTP服务2.10.1. TestServer2.10.2. TestServerInitializer2.10.3. TestHttpServerHandler3. Netty 核心模块组件3.1. Bootstrap、ServerBootstrap3.2. Future、ChannelFuture3.3. Channel3.4. Selector3.5. ChannelHandler 及其实现类3.6. Pipeline 和 ChannelPipeline3.7. ChannelHandlerContext3.8. ChannelOption3.9. EventLoopGroup 和其实现类 NioEventLoopGroup3.10. Unpooled 类3.11. Netty 应用实例-群聊系统3.11.1. GroupChatServer3.11.2. GroupChatServerHandler3.11.3. GroupChatClient3.11.4. GroupChatClientHandler3.12. Netty 心跳检测机制案例3.12.1. MyServer3.12.2. MyServerHandler3.13. Netty 通过 WebSocket 编程实现服务器和客户端长连接3.13.1. MyServer3.13.2. MyTextWebSocketFrameHandler3.13.3. hello.html1. Netty 概述 1.1. 原生 NIO 存在的问题 NIO 的类库和 API 繁杂，使用麻烦：需要熟练掌握 Selector、ServerSocketChannel、SocketChannel、ByteBuffer等。 需要具备其他的额外技能：要熟悉 Java 多线程编程，因为 NIO 编程涉及到 Reactor 模式，你必须对多线程和网络编程非常熟悉，才能编写出高质量的 NIO 程序。 开发工作量和难度都非常大：例如客户端面临断连重连、网络闪断、半包读写、失败缓存、网络拥塞和异常流的处理等等。 JDK NIO 的 Bug：例如臭名昭著的 Epoll Bug，它会导致 Selector 空轮询，最终导致 CPU100%。直到 JDK1.7 版本该问题仍旧存在，没有被根本解决。 1.2. Netty 的优点 Netty 对 JDK 自带的 NIO 的 API 进行了封装，解决了上述问题。 设计优雅：适用于各种传输类型的统一 API 阻塞和非阻塞 Socket；基于灵活且可扩展的事件模型，可以清晰地分离关注点；高度可定制的线程模型-单线程，一个或多个线程池。 使用方便：详细记录的 Javadoc，用户指南和示例；没有其他依赖项，JDK5（Netty3.x）或 6（Netty4.x）就足够了。 高性能、吞吐量更高：延迟更低；减少资源消耗；最小化不必要的内存复制。 安全：完整的 SSL/TLS 和 StartTLS 支持。 社区活跃、不断更新：社区活跃，版本迭代周期短，发现的 Bug 可以被及时修复，同时，更多的新功能会被加入。 1.3. Netty 版本说明 Netty 版本分为 Netty 3.x 和 Netty 4.x、Netty 5.x 因为 Netty 5 出现重大 bug，已经被官网废弃了，目前推荐使用的是 Netty 4.x的稳定版本 目前在官网可下载的版本 Netty 3.x、Netty 4.0.x 和 Netty 4.1.x 在本套课程中，我们讲解 Netty4.1.x 版本 Netty 下载地址：https://bintray.com/netty/downloads/netty/ 2. Netty 高性能架构设计 2.1. 线程模型基本介绍 不同的线程模式，对程序的性能有很大影响，为了搞清 Netty 线程模式，我们来系统的讲解下各个线程模式，最后看看 Netty 线程模型有什么优越性。 目前存在的线程模型有：传统阻塞 I/O 服务模型 和Reactor 模式 根据 Reactor 的数量和处理资源池线程的数量不同，有 3 种典型的实现 单 Reactor 单线程； 单 Reactor多线程； 主从 Reactor多线程 Netty 线程模式（Netty 主要基于主从 Reactor 多线程模型做了一定的改进，其中主从 Reactor 多线程模型有多个 Reactor） 2.2. 传统阻塞 I/O 服务模型 2.2.1. 工作原理图 黄色的框表示对象，蓝色的框表示线程 白色的框表示方法（API） 2.2.2. 模型特点 采用阻塞 IO 模式获取输入的数据 每个连接都需要独立的线程完成数据的输入，业务处理，数据返回 2.2.3. 问题分析 当并发数很大，就会创建大量的线程，占用很大系统资源 连接创建后，如果当前线程暂时没有数据可读，该线程会阻塞在 Handler对象中的read 操作，导致上面的处理线程资源浪费 2.3. Reactor 模式 2.3.1. 针对传统阻塞 I/O 服务模型的 2 个缺点，解决方案： 基于 I/O 复用模型：多个连接共用一个阻塞对象ServiceHandler，应用程序只需要在一个阻塞对象等待，无需阻塞等待所有连接。当某个连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理。 Reactor 在不同书中的叫法： 反应器模式 分发者模式（Dispatcher） 通知者模式（notifier） 基于线程池复用线程资源：不必再为每个连接创建线程，将连接完成后的业务处理任务分配给线程进行处理，一个线程可以处理多个连接的业务。（解决了当并发数很大时，会创建大量线程，占用很大系统资源） 基于 I/O 复用模型：多个客户端进行连接，先把连接请求给ServiceHandler。多个连接共用一个阻塞对象ServiceHandler。假设，当C1连接没有数据要处理时，C1客户端只需要阻塞于ServiceHandler，C1之前的处理线程便可以处理其他有数据的连接，不会造成线程资源的浪费。当C1连接再次有数据时，ServiceHandler根据线程池的空闲状态，将请求分发给空闲的线程来处理C1连接的任务。（解决了线程资源浪费的那个问题） 2.3.2. I/O 复用结合线程池，就是 Reactor 模式基本设计思想，如图 对上图说明： Reactor 模式，通过一个或多个输入同时传递给服务处理器（ServiceHandler）的模式（基于事件驱动） 服务器端程序处理传入的多个请求,并将它们同步分派到相应的处理线程，因此 Reactor 模式也叫 Dispatcher 模式 Reactor 模式使用 IO 复用监听事件，收到事件后，分发给某个线程（进程），这点就是网络服务器高并发处理关键 原先有多个Handler阻塞，现在只用一个ServiceHandler阻塞 2.3.3. Reactor 模式中核心组成 Reactor（也就是那个ServiceHandler）：Reactor 在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理线程来对 IO 事件做出反应。它就像公司的电话接线员，它接听来自客户的电话并将线路转移到适当的联系人； Handlers（处理线程EventHandler）：处理线程执行 I/O 事件要完成的实际事件，类似于客户想要与之交谈的公司中的实际官员。Reactor 通过调度适当的处理线程来响应 I/O 事件，处理程序执行非阻塞操作。 2.3.4. Reactor 模式分类 根据 Reactor 的数量和处理资源池线程的数量不同，有 3 种典型的实现 单 Reactor 单线程 单 Reactor 多线程 主从 Reactor 多线程 2.4. 单 Reactor 单线程 原理图，并使用 NIO 群聊系统验证 2.4.1. 方案说明 Select 是前面 I/O 复用模型介绍的标准网络编程 API，可以实现应用程序通过一个阻塞对象监听多路连接请求 Reactor 对象通过 Select 监控客户端请求事件，收到事件后通过 Dispatch 进行分发 如果是建立连接请求事件，则由 Acceptor 通过 Accept 处理连接请求，然后创建一个 Handler 对象处理连接完成后的后续业务处理 如果不是建立连接事件，则 Reactor 会分发调用连接对应的 Handler 来响应 Handler 会完成 Read → 业务处理 → Send 的完整业务流程 结合实例：服务器端用一个线程通过多路复用搞定所有的 IO 操作（包括连接，读、写等），编码简单，清晰明了，但是如果客户端连接数量较多，将无法支撑，前面的 NIO 案例就属于这种模型。 2.4.2. 方案优缺点分析 优点：模型简单，没有多线程、进程通信、竞争的问题，全部都在一个线程中完成 缺点：性能问题，只有一个线程，无法完全发挥多核 CPU 的性能。Handler在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈 缺点：可靠性问题，线程意外终止，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障 使用场景：客户端的数量有限，业务处理非常快速，比如 Redis 在业务处理的时间复杂度 O(1) 的情况 2.5. 单 Reactor 多线程 2.5.1. 方案说明 Reactor 对象通过 Select 监控客户端请求事件，收到事件后，通过 Dispatch 进行分发 如果是建立连接请求，则由 Acceptor 通过 accept 处理连接请求，然后创建一个 Handler 对象处理完成连接后的各种事件 如果不是连接请求，则由 Reactor 分发调用连接对应的 handler 来处理（也就是说连接已经建立，后续客户端再来请求，那基本就是数据请求了，直接调用之前为这个连接创建好的handler来处理） handler 只负责响应事件，不做具体的业务处理（这样不会使handler阻塞太久），通过 read 读取数据后，会分发给后面的 worker 线程池的某个线程处理业务。【业务处理是最费时的，所以将业务处理交给线程池去执行】 worker 线程池会分配独立线程完成真正的业务，并将结果返回给 handler handler 收到响应后，通过 send 将结果返回给 client 2.5.2. 方案优缺点分析 优点：可以充分的利用多核 cpu 的处理能力 缺点：多线程数据共享和访问比较复杂。Reactor 承担所有的事件的监听和响应，它是单线程运行，在高并发场景容易出现性能瓶颈。也就是说Reactor主线程承担了过多的事 2.6. 主从 Reactor 多线程 2.6.1. 工作原理图 针对单 Reactor 多线程模型中，Reactor 在单线程中运行，高并发场景下容易成为性能瓶颈，可以让 Reactor 在多线程中运行 SubReactor是可以有多个的，如果只有一个SubReactor的话那和单 Reactor 多线程就没什么区别了。 Reactor 主线程 MainReactor 对象通过 select 监听连接事件，收到事件后，通过 Acceptor 处理连接事件 当 Acceptor 处理连接事件后，MainReactor 将连接分配给 SubReactor subreactor 将连接加入到连接队列进行监听，并创建 handler 进行各种事件处理 当有新事件发生时，subreactor 就会调用对应的 handler 处理 handler 通过 read 读取数据，分发给后面的 worker 线程处理 worker 线程池分配独立的 worker 线程进行业务处理，并返回结果 handler 收到响应的结果后，再通过 send 将结果返回给 client Reactor 主线程可以对应多个 Reactor 子线程，即 MainRecator 可以关联多个 SubReactor 2.6.2. 方案优缺点说明 优点：父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。 优点：父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。 缺点：编程复杂度较高 结合实例：这种模型在许多项目中广泛使用，包括 Nginx 主从 Reactor 多进程模型，Memcached 主从多线程，Netty 主从多线程模型的支持 2.7. Reactor 模式小结 2.7.1. 3 种模式用生活案例来理解 单 Reactor 单线程，前台接待员和服务员是同一个人，全程为顾客服 单 Reactor 多线程，1 个前台接待员，多个服务员，接待员只负责接待 主从 Reactor 多线程，多个前台接待员，多个服务生 2.7.2. Reactor 模式具有如下的优点 响应快，不必为单个同步时间所阻塞，虽然 Reactor 本身依然是同步的（比如你第一个SubReactor阻塞了，我可以调下一个 SubReactor为客户端服务） 可以最大程度的避免复杂的多线程及同步问题，并且避免了多线程/进程的切换开销 扩展性好，可以方便的通过增加 Reactor 实例个数来充分利用 CPU 资源 复用性好，Reactor 模型本身与具体事件处理逻辑无关，具有很高的复用性 2.8. Netty 模型 讲解netty的时候采用的是先写代码体验一下，再细讲里面的原理。前面看不懂的可以先不用纠结，先往后面看，后面基本都会讲清楚 2.8.1. 工作原理示意图1 - 简单版 Netty 主要基于主从 Reactors 多线程模型（如图）做了一定的改进，其中主从 Reactor 多线程模型有多个 Reactor 对上图说明 BossGroup 线程维护 Selector，只关注 Accecpt 当接收到 Accept 事件，获取到对应的 SocketChannel，封装成 NIOScoketChannel 并注册到 Worker 线程（事件循环），并进行维护 当 Worker 线程监听到 Selector 中通道发生自己感兴趣的事件后，就进行处理（就由 handler），注意 handler 已经加入到通道 2.8.2. 工作原理示意图2 - 进阶版 BossGroup有点像主Reactor 可以有多个，WorkerGroup则像SubReactor一样可以有多个。 2.8.3. 工作原理示意图3 - 详细版 Netty 抽象出两组线程池 ，BossGroup 专门负责接收客户端的连接，WorkerGroup 专门负责网络的读写 BossGroup 和 WorkerGroup 类型都是 NioEventLoopGroup NioEventLoopGroup 相当于一个事件循环组，这个组中含有多个事件循环，每一个事件循环是 NioEventLoop NioEventLoop 表示一个不断循环的执行处理任务的线程，每个 NioEventLoop 都有一个 Selector，用于监听绑定在其上的 socket 的网络通讯 NioEventLoopGroup 可以有多个线程，即可以含有多个 NioEventLoop 每个 BossGroup下面的NioEventLoop 循环执行的步骤有 3 步 轮询 accept 事件 处理 accept 事件，与 client 建立连接，生成 NioScocketChannel，并将其注册到某个 workerGroup NIOEventLoop 上的 Selector 继续处理任务队列的任务，即 runAllTasks 每个 WorkerGroup NIOEventLoop 循环执行的步骤 轮询 read，write 事件 处理 I/O 事件，即 read，write 事件，在对应 NioScocketChannel 处理 处理任务队列的任务，即 runAllTasks 每个 Worker NIOEventLoop 处理业务时，会使用 pipeline（管道），pipeline 中包含了 channel（通道），即通过 pipeline 可以获取到对应通道，管道中维护了很多的处理器。（这个点目前只是简单的讲，后面重点说） 2.8.4. Netty 快速入门实例 - TCP 服务 实例要求：使用 IDEA 创建 Netty 项目 Netty 服务器在 6668 端口监听，客户端能发送消息给服务器\"hello,服务器~\" 服务器可以回复消息给客户端\"hello,客户端~\" 目的：对 Netty 线程模型有一个初步认识，便于理解 Netty 模型理论 编写服务端 编写客户端 对 netty 程序进行分析，看看 netty 模型特点 说明：创建 Maven 项目，并引入 Netty 包 代码如下 NettyServer package com.atguigu.netty.simple; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.*; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; public class NettyServer { public static void main(String[] args) throws Exception { //创建BossGroup 和 WorkerGroup //说明 //1. 创建两个线程组 bossGroup 和 workerGroup //2. bossGroup 只是处理连接请求 , 真正的和客户端业务处理，会交给 workerGroup完成 //3. 两个都是无限循环 //4. bossGroup 和 workerGroup 含有的子线程(NioEventLoop)的个数 // 默认实际 cpu核数 * 2 EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); //8 try { //创建服务器端的启动对象，配置参数 ServerBootstrap bootstrap = new ServerBootstrap(); //使用链式编程来进行设置 bootstrap.group(bossGroup, workerGroup) //设置两个线程组 .channel(NioServerSocketChannel.class) //使用NioSocketChannel 作为服务器的通道实现 .option(ChannelOption.SO_BACKLOG, 128) // 设置线程队列等待连接个数 .childOption(ChannelOption.SO_KEEPALIVE, true) //设置保持活动连接状态 // .handler(null) // 该 handler对应 bossGroup , childHandler 对应 workerGroup .childHandler(new ChannelInitializer() {//创建一个通道初始化对象(匿名对象) //给pipeline 设置处理器 @Override protected void initChannel(SocketChannel ch) throws Exception { System.out.println(\"客户socketchannel hashcode=\" + ch.hashCode()); //可以使用一个集合管理 SocketChannel， 再推送消息时，可以将业务加入到各个channel 对应的 NIOEventLoop 的 taskQueue 或者 scheduleTaskQueue ch.pipeline().addLast(new NettyServerHandler()); } }); // 给我们的workerGroup 的 EventLoop 对应的管道设置处理器 System.out.println(\".....服务器 is ready...\"); //绑定一个端口并且同步生成了一个 ChannelFuture 对象（也就是立马返回这样一个对象） //启动服务器(并绑定端口) ChannelFuture cf = bootstrap.bind(6668).sync(); //给cf 注册监听器，监控我们关心的事件 cf.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (cf.isSuccess()) { System.out.println(\"监听端口 6668 成功\"); } else { System.out.println(\"监听端口 6668 失败\"); } } }); //对关闭通道事件 进行监听 cf.channel().closeFuture().sync(); }finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } NettyServerHandler package com.atguigu.netty.simple; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.Channel; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundHandlerAdapter; import io.netty.channel.ChannelPipeline; import io.netty.util.CharsetUtil; import java.util.concurrent.TimeUnit; /* 说明 1. 我们自定义一个Handler 需要继承netty 规定好的某个HandlerAdapter(规范) 2. 这时我们自定义一个Handler , 才能称为一个handler */ public class NettyServerHandler extends ChannelInboundHandlerAdapter { //读取数据事件(这里我们可以读取客户端发送的消息) /* 1. ChannelHandlerContext ctx:上下文对象, 含有 管道pipeline , 通道channel, 地址 2. Object msg: 就是客户端发送的数据 默认Object */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\"服务器读取线程 \" + Thread.currentThread().getName() + \" channle =\" + ctx.channel()); System.out.println(\"server ctx =\" + ctx); System.out.println(\"看看channel 和 pipeline的关系\"); Channel channel = ctx.channel(); ChannelPipeline pipeline = ctx.pipeline(); //本质是一个双向链表 //将 msg 转成一个 ByteBuf //ByteBuf 是 Netty 提供的，不是 NIO 的 ByteBuffer. ByteBuf buf = (ByteBuf) msg; System.out.println(\"客户端发送消息是:\" + buf.toString(CharsetUtil.UTF_8)); System.out.println(\"客户端地址:\" + channel.remoteAddress()); } //数据读取完毕 @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { //writeAndFlush 是 write + flush //将数据写入到缓存，并刷新 //一般讲，我们对这个发送的数据进行编码 ctx.writeAndFlush(Unpooled.copiedBuffer(\"hello, 客户端~(>^ω^ NettyClient package com.atguigu.netty.simple; import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; public class NettyClient { public static void main(String[] args) throws Exception { //客户端需要一个事件循环组 EventLoopGroup group = new NioEventLoopGroup(); try { //创建客户端启动对象 //注意客户端使用的不是 ServerBootstrap 而是 Bootstrap Bootstrap bootstrap = new Bootstrap(); //设置相关参数 bootstrap.group(group) //设置线程组 .channel(NioSocketChannel.class) // 设置客户端通道的实现类(反射) .handler(new ChannelInitializer() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new NettyClientHandler()); //加入自己的处理器 } }); System.out.println(\"客户端 ok..\"); //启动客户端去连接服务器端 //关于 ChannelFuture 要分析，涉及到netty的异步模型 ChannelFuture channelFuture = bootstrap.connect(\"127.0.0.1\", 6668).sync(); //对关闭通道事件 进行监听 channelFuture.channel().closeFuture().sync(); }finally { group.shutdownGracefully(); } } } NettyClientHandler package com.atguigu.netty.simple; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundHandlerAdapter; import io.netty.util.CharsetUtil; public class NettyClientHandler extends ChannelInboundHandlerAdapter { //当通道就绪就会触发该方法 @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { System.out.println(\"client \" + ctx); ctx.writeAndFlush(Unpooled.copiedBuffer(\"hello, server: (>^ω^ 2.8.5. 任务队列中的 Task 有 3 种典型使用场景 用户程序自定义的普通任务【举例说明】 用户自定义定时任务 非当前 Reactor 线程调用 Channel 的各种方法 例如在推送系统的业务线程里面，根据用户的标识，找到对应的 Channel 引用，然后调用 Write 类方法向该用户推送消息，就会进入到这种场景。最终的 Write 会提交到任务队列中后被异步消费 前两种的代码举例： package com.atguigu.netty.simple; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundHandlerAdapter; import io.netty.util.CharsetUtil; import java.util.concurrent.TimeUnit; /** * 说明 * 1. 我们自定义一个Handler 需要继续netty 规定好的某个HandlerAdapter(规范) * 2. 这时我们自定义一个Handler , 才能称为一个handler */ public class NettyServerHandler extends ChannelInboundHandlerAdapter { //读取数据实际(这里我们可以读取客户端发送的消息) /** * 1. ChannelHandlerContext ctx:上下文对象, 含有 管道pipeline , 通道channel, 地址 * 2. Object msg: 就是客户端发送的数据 默认Object */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { // 比如这里我们有一个非常耗时长的业务-> 异步执行 -> 提交该channel 对应的 // NIOEventLoop 的 taskQueue中, // 解决方案1 用户程序自定义的普通任务 ctx.channel().eventLoop().execute(new Runnable() { @Override public void run() { try { Thread.sleep(5 * 1000); ctx.writeAndFlush(Unpooled.copiedBuffer(\"hello, 客户端~(>^ω^^ω^^ω^^ω^ 2.8.6. 方案再说明 Netty 抽象出两组线程池，BossGroup 专门负责接收客户端连接，WorkerGroup 专门负责网络读写操作。 NioEventLoop 表示一个不断循环执行处理任务的线程，每个 NioEventLoop 都有一个 Selector，用于监听绑定在其上的 socket网络通道。 NioEventLoop 内部采用串行化设计，从消息的 读取->解码->处理->编码->发送，始终由 IO 线程 NioEventLoop 负责 NioEventLoopGroup 下包含多个 NioEventLoop 每个 NioEventLoop 中包含有一个 Selector，一个 taskQueue 每个 NioEventLoop 的 Selector 上可以注册监听多个 NioChannel 每个 NioChannel 只会绑定在唯一的 NioEventLoop 上 每个 NioChannel 都绑定有一个自己的 ChannelPipeline 2.9. 异步模型 2.9.1. 基本介绍 异步的概念和同步相对。当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的组件在完成后，通过状态、通知和回调来通知调用者。 Netty 中的 I/O 操作是异步的，包括 Bind、Write、Connect 等操作会首先简单的返回一个 ChannelFuture。 调用者并不能立刻获得结果，而是通过 Future-Listener 机制，用户可以方便的主动获取或者通过通知机制获得 IO 操作结果。 Netty 的异步模型是建立在 future 和 callback 的之上的。callback 就是回调。重点说 Future，它的核心思想是：假设一个方法 fun，计算过程可能非常耗时，等待 fun 返回显然不合适。那么可以在调用 fun 的时候，立马返回一个 Future，后续可以通过 Future 去监控方法 fun 的处理过程（即：Future-Listener 机制） 2.9.2. Future 说明 表示异步的执行结果,可以通过它提供的方法来检测执行是否完成，比如检索计算等等。 ChannelFuture 是一个接口：public interface ChannelFuture extends Future 我们可以添加监听器，当监听的事件发生时，就会通知到监听器。 2.9.3. 工作原理示意图 下面第一张图就是管道，中间会经过多个handler 说明： 在使用 Netty 进行编程时，拦截操作和转换出入站数据只需要您提供 callback 或利用 future 即可。这使得链式操作简单、高效，并有利于编写可重用的、通用的代码。 Netty 框架的目标就是让你的业务逻辑从网络基础应用编码中分离出来、解脱出来。 2.9.4. Future-Listener 机制 这里看不懂的可以看笔者的并发系列-JUC部分 当 Future 对象刚刚创建时，处于非完成状态，调用者可以通过返回的 ChannelFuture 来获取操作执行的状态，注册监听函数来执行完成后的操作。 常见有如下操作 通过 isDone 方法来判断当前操作是否完成； 通过 isSuccess 方法来判断已完成的当前操作是否成功； 通过 getCause 方法来获取已完成的当前操作失败的原因； 通过 isCancelled 方法来判断已完成的当前操作是否被取消； 通过 addListener 方法来注册监听器，当操作已完成（isDone方法返回完成），将会通知指定的监听器；如果 Future 对象已完成，则通知指定的监听器 举例说明 演示：绑定端口是异步操作，当绑定操作处理完，将会调用相应的监听器处理逻辑 //绑定一个端口并且同步,生成了一个ChannelFuture对象 //启动服务器(并绑定端口) ChannelFuture cf = bootstrap.bind(6668).sync(); //给cf注册监听器，监控我们关心的事件 cf.addListener(new ChannelFutureListener() { @Override public void operationComplete (ChannelFuture future) throws Exception { if (cf.isSuccess()) { System.out.println(\"监听端口6668成功\"); } else { System.out.println(\"监听端口6668失败\"); } } }); 2.10. 快速入门实例 - HTTP服务 实例要求：使用 IDEA 创建 Netty 项目 Netty 服务器在 6668 端口监听，浏览器发出请求 http://localhost:6668/ 服务器可以回复消息给客户端\"Hello!我是服务器5\",并对特定请求资源进行过滤。 目的：Netty 可以做 Http 服务开发，并且理解 Handler 实例和客户端及其请求的关系。 看老师代码演示 2.10.1. TestServer package com.atguigu.netty.http; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.nio.NioServerSocketChannel; public class TestServer { public static void main(String[] args) throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(bossGroup, workerGroup).channel(NioServerSocketChannel.class).childHandler(new TestServerInitializer()); ChannelFuture channelFuture = serverBootstrap.bind(6668).sync(); channelFuture.channel().closeFuture().sync(); }finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } 2.10.2. TestServerInitializer package com.atguigu.netty.http; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.socket.SocketChannel; import io.netty.handler.codec.http.HttpServerCodec; public class TestServerInitializer extends ChannelInitializer { @Override protected void initChannel(SocketChannel ch) throws Exception { //向管道加入处理器 //得到管道 ChannelPipeline pipeline = ch.pipeline(); //加入一个netty 提供的httpServerCodec codec =>[coder - decoder] //HttpServerCodec 说明 //1. HttpServerCodec 是netty 提供的处理http的 编-解码器 pipeline.addLast(\"MyHttpServerCodec\",new HttpServerCodec()); //2. 增加一个自定义的handler pipeline.addLast(\"MyTestHttpServerHandler\", new TestHttpServerHandler()); System.out.println(\"ok~~~~\"); } } 2.10.3. TestHttpServerHandler package com.atguigu.netty.http; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import io.netty.handler.codec.http.*; import io.netty.util.CharsetUtil; import java.net.URI; /* 说明 1. SimpleChannelInboundHandler 是 ChannelInboundHandlerAdapter 2. HttpObject 客户端和服务器端相互通讯的数据被封装成 HttpObject */ public class TestHttpServerHandler extends SimpleChannelInboundHandler { //channelRead0 读取客户端数据 @Override protected void channelRead0(ChannelHandlerContext ctx, HttpObject msg) throws Exception { System.out.println(\"对应的channel=\" + ctx.channel() + \" pipeline=\" + ctx .pipeline() + \" 通过pipeline获取channel\" + ctx.pipeline().channel()); System.out.println(\"当前ctx的handler=\" + ctx.handler()); //判断 msg 是不是 httprequest请求 if(msg instanceof HttpRequest) { System.out.println(\"ctx 类型=\"+ctx.getClass()); System.out.println(\"pipeline hashcode\" + ctx.pipeline().hashCode() + \" TestHttpServerHandler hash=\" + this.hashCode()); System.out.println(\"msg 类型=\" + msg.getClass()); System.out.println(\"客户端地址\" + ctx.channel().remoteAddress()); //获取到 HttpRequest httpRequest = (HttpRequest) msg; //获取uri, 过滤指定的资源 URI uri = new URI(httpRequest.uri()); if(\"/favicon.ico\".equals(uri.getPath())) { System.out.println(\"请求了 favicon.ico, 不做响应\"); return; } //回复信息给浏览器 [http协议] ByteBuf content = Unpooled.copiedBuffer(\"hello, 我是服务器\", CharsetUtil.UTF_8); //构造一个http的相应，即 httpresponse FullHttpResponse response = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK, content); response.headers().set(HttpHeaderNames.CONTENT_TYPE, \"text/plain\"); response.headers().set(HttpHeaderNames.CONTENT_LENGTH, content.readableBytes()); //将构建好 response返回 ctx.writeAndFlush(response); } } } 3. Netty 核心模块组件 各种东西看不懂，可以先看第三话，第三话我自认为用通俗的语言讲的还算清楚。 3.1. Bootstrap、ServerBootstrap Bootstrap 意思是引导，一个 Netty 应用通常由一个 Bootstrap 开始，主要作用是配置整个 Netty 程序，串联各个组件，Netty 中 Bootstrap 类是客户端程序的启动引导类，ServerBootstrap 是服务端启动引导类。 常见的方法有 public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup)，该方法用于服务器端，用来设置两个 EventLoop public B group(EventLoopGroup group)，该方法用于客户端，用来设置一个 EventLoop public B channel(Class channelClass)，该方法用来设置一个服务器端的通道实现 public B option(ChannelOption option, T value)，用来给 ServerChannel 添加配置 public ServerBootstrap childOption(ChannelOption childOption, T value)，用来给接收到的通道添加配置 public ServerBootstrap childHandler(ChannelHandler childHandler)，该方法用来设置业务处理类（自定义的handler） public ChannelFuture bind(int inetPort)，该方法用于服务器端，用来设置占用的端口号 public ChannelFuture connect(String inetHost, int inetPort)，该方法用于客户端，用来连接服务器端 3.2. Future、ChannelFuture Netty 中所有的 IO 操作都是异步的，不能立刻得知消息是否被正确处理。但是可以过一会等它执行完成或者直接注册一个监听，具体的实现就是通过 Future 和 ChannelFutures，他们可以注册一个监听，当操作执行成功或失败时监听会自动触发注册的监听事件 常见的方法有 Channel channel()，返回当前正在进行 IO 操作的通道 ChannelFuture sync()，等待异步操作执行完毕 3.3. Channel Netty 网络通信的组件，能够用于执行网络 I/O 操作。 通过 Channel 可获得当前网络连接的通道的状态 通过 Channel 可获得网络连接的配置参数（例如接收缓冲区大小） Channel 提供异步的网络 I/O 操作(如建立连接，读写，绑定端口)，异步调用意味着任何 I/O 调用都将立即返回，并且不保证在调用结束时所请求的 I/O 操作已完成 调用立即返回一个 ChannelFuture 实例，通过注册监听器到 ChannelFuture 上，可以 I/O 操作成功、失败或取消时回调通知调用方 支持关联 I/O 操作与对应的处理程序 不同协议、不同的阻塞类型的连接都有不同的 Channel 类型与之对应，常用的 Channel 类型： NioSocketChannel，异步的客户端 TCP Socket 连接。 NioServerSocketChannel，异步的服务器端 TCP Socket 连接。 NioDatagramChannel，异步的 UDP 连接。 NioSctpChannel，异步的客户端 Sctp 连接。 NioSctpServerChannel，异步的 Sctp 服务器端连接，这些通道涵盖了 UDP 和 TCP 网络 IO 以及文件 IO。 3.4. Selector Netty 基于 Selector 对象实现 I/O 多路复用，通过 Selector 一个线程可以监听多个连接的 Channel 事件。 当向一个 Selector 中注册 Channel 后，Selector 内部的机制就可以自动不断地查询（Select）这些注册的 Channel 是否有已就绪的 I/O 事件（例如可读，可写，网络连接完成等），这样程序就可以很简单地使用一个线程高效地管理多个 Channel 3.5. ChannelHandler 及其实现类 ChannelHandler 是一个接口，处理 I/O 事件或拦截 I/O 操作，并将其转发到其 ChannelPipeline（业务处理链）中的下一个处理程序。 ChannelHandler 本身并没有提供很多方法，因为这个接口有许多的方法需要实现，方便使用期间，可以继承它的子类 ChannelHandler 及其实现类一览图（后） 我们经常需要自定义一个 Handler 类去继承 ChannelInboundHandlerAdapter，然后通过重写相应方法实现业务逻辑，我们接下来看看一般都需要重写哪些方法 3.6. Pipeline 和 ChannelPipeline ChannelPipeline 是一个重点： ChannelPipeline 是一个 Handler 的集合，它负责处理和拦截 inbound 或者 outbound 的事件和操作，相当于一个贯穿 Netty 的链。（也可以这样理解：ChannelPipeline 是保存 ChannelHandler 的 List，用于处理或拦截 Channel 的入站事件和出站操作） ChannelPipeline 实现了一种高级形式的拦截过滤器模式，使用户可以完全控制事件的处理方式，以及 Channel 中各个的 ChannelHandler 如何相互交互 在 Netty 中每个 Channel 都有且仅有一个 ChannelPipeline 与之对应，它们的组成关系如下 常用方法 ChannelPipeline addFirst(ChannelHandler... handlers)，把一个业务处理类（handler）添加到链中的第一个位置ChannelPipeline addLast(ChannelHandler... handlers)，把一个业务处理类（handler）添加到链中的最后一个位置 想要更清楚的了解pipeline，可以对之前的代码进行debug，看一下pipeline里究竟有什么东西。 从head看一下debug TestServerInitializer和HttpServerCodec这些东西本身也是handler 一般来说事件从客户端往服务器走我们称为出站，反之则是入站。 3.7. ChannelHandlerContext 保存 Channel 相关的所有上下文信息，同时关联一个 ChannelHandler 对象 即 ChannelHandlerContext 中包含一个具体的事件处理器 ChannelHandler，同时 ChannelHandlerContext 中也绑定了对应的 pipeline 和 Channel 的信息，方便对 ChannelHandler 进行调用。 常用方法 ChannelFuture close()，关闭通道 ChannelOutboundInvoker flush()，刷新 ChannelFuture writeAndFlush(Object msg)，将数据写到 ChannelPipeline 中当前 ChannelHandler 的下一个 ChannelHandler 开始处理（出站） 3.8. ChannelOption Netty 在创建 Channel 实例后，一般都需要设置 ChannelOption 参数。 ChannelOption 参数如下： 3.9. EventLoopGroup 和其实现类 NioEventLoopGroup EventLoopGroup 是一组 EventLoop 的抽象，Netty 为了更好的利用多核 CPU 资源，一般会有多个 EventLoop 同时工作，每个 EventLoop 维护着一个 Selector 实例。 EventLoopGroup 提供 next 接口，可以从组里面按照一定规则获取其中一个 EventLoop 来处理任务。在 Netty 服务器端编程中，我们一般都需要提供两个 EventLoopGroup，例如：BossEventLoopGroup 和 WorkerEventLoopGroup。 通常一个服务端口即一个 ServerSocketChannel 对应一个 Selector 和一个 EventLoop 线程。BossEventLoop 负责接收客户端的连接并将 SocketChannel 交给 WorkerEventLoopGroup 来进行 IO 处理，如下图所示 常用方法 public NioEventLoopGroup()，构造方法 public Future shutdownGracefully()，断开连接，关闭线程 3.10. Unpooled 类 Netty 提供一个专门用来操作缓冲区（即 Netty 的数据容器）的工具类 常用方法如下所示 举例说明 Unpooled 获取 Netty 的数据容器 ByteBuf 的基本使用 案例 1 package com.atguigu.netty.buf; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; public class NettyByteBuf01 { public static void main(String[] args) { //创建一个ByteBuf //说明 //1. 创建 对象，该对象包含一个数组arr , 是一个byte[10] //2. 在netty 的buffer中，不需要使用flip 进行反转 // 底层维护了 readerindex 和 writerIndex //3. 通过 readerindex 和 writerIndex 和 capacity， 将buffer分成三个区域 // 0---readerindex 已经读取的区域 // readerindex---writerIndex ， 可读的区域 // writerIndex -- capacity, 可写的区域 ByteBuf buffer = Unpooled.buffer(10); for (int i = 0; i 案例 2 package com.atguigu.netty.buf; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import java.nio.charset.Charset; public class NettyByteBuf02 { public static void main(String[] args) { //创建ByteBuf ByteBuf byteBuf = Unpooled.copiedBuffer(\"hello,world!\", Charset.forName(\"utf-8\")); //使用相关的方法 if (byteBuf.hasArray()) { // true byte[] content = byteBuf.array(); //将 content 转成字符串 System.out.println(new String(content, Charset.forName(\"utf-8\"))); System.out.println(\"byteBuf=\" + byteBuf); System.out.println(byteBuf.arrayOffset()); // 0 System.out.println(byteBuf.readerIndex()); // 0 System.out.println(byteBuf.writerIndex()); // 12 System.out.println(byteBuf.capacity()); // 36 //System.out.println(byteBuf.readByte()); // System.out.println(byteBuf.getByte(0)); // 104 int len = byteBuf.readableBytes(); //可读的字节数 12 System.out.println(\"len=\" + len); //使用for取出各个字节 for (int i = 0; i 3.11. Netty 应用实例-群聊系统 实例要求： 编写一个 Netty 群聊系统，实现服务器端和客户端之间的数据简单通讯（非阻塞） 实现多人群聊 服务器端：可以监测用户上线，离线，并实现消息转发功能 客户端：通过 channel 可以无阻塞发送消息给其它所有用户，同时可以接受其它用户发送的消息（有服务器转发得到） 目的：进一步理解 Netty 非阻塞网络编程机制 代码如下： 3.11.1. GroupChatServer package com.atguigu.netty.groupchat; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.*; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.codec.string.StringDecoder; import io.netty.handler.codec.string.StringEncoder; public class GroupChatServer { private int port; //监听端口 public GroupChatServer(int port) { this.port = port; } //编写run方法，处理客户端的请求 public void run() throws Exception{ //创建两个线程组 EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); //8个NioEventLoop try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, true) .childHandler(new ChannelInitializer() { @Override protected void initChannel(SocketChannel ch) throws Exception { //获取到pipeline ChannelPipeline pipeline = ch.pipeline(); //向pipeline加入解码器 pipeline.addLast(\"decoder\", new StringDecoder()); //向pipeline加入编码器 pipeline.addLast(\"encoder\", new StringEncoder()); //加入自己的业务处理handler pipeline.addLast(new GroupChatServerHandler()); } }); System.out.println(\"netty 服务器启动\"); ChannelFuture channelFuture = b.bind(port).sync(); //监听关闭 channelFuture.channel().closeFuture().sync(); }finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public static void main(String[] args) throws Exception { new GroupChatServer(7000).run(); } } 3.11.2. GroupChatServerHandler package com.atguigu.netty.groupchat; import io.netty.channel.Channel; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import io.netty.channel.group.ChannelGroup; import io.netty.channel.group.DefaultChannelGroup; import io.netty.util.concurrent.GlobalEventExecutor; import java.text.SimpleDateFormat; import java.util.ArrayList; import java.util.HashMap; import java.util.List; import java.util.Map; public class GroupChatServerHandler extends SimpleChannelInboundHandler { //这样写还要自己遍历Channel //public static List channels = new ArrayList(); //使用一个hashmap 管理私聊（私聊本案例并未实现，只是提供个思路） //public static Map channels = new HashMap(); //定义一个channle 组，管理所有的channel //GlobalEventExecutor.INSTANCE) 是全局的事件执行器，是一个单例 private static ChannelGroup channelGroup = new DefaultChannelGroup(GlobalEventExecutor.INSTANCE); SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); //handlerAdded 表示连接建立，一旦连接，第一个被执行 //将当前channel 加入到 channelGroup @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception { Channel channel = ctx.channel(); //将该客户加入聊天的信息推送给其它在线的客户端 //该方法会将 channelGroup 中所有的channel 遍历，并发送消息，我们不需要自己遍历 channelGroup.writeAndFlush(\"[客户端]\" + channel.remoteAddress() + \" 加入聊天\" + sdf.format(new java.util.Date()) + \" \\n\"); channelGroup.add(channel); //私聊如何实现 // channels.put（\"userid100\",channel）; } //断开连接, 将xx客户离开信息推送给当前在线的客户 @Override public void handlerRemoved(ChannelHandlerContext ctx) throws Exception { Channel channel = ctx.channel(); channelGroup.writeAndFlush(\"[客户端]\" + channel.remoteAddress() + \" 离开了\\n\"); System.out.println(\"channelGroup size\" + channelGroup.size()); } //表示channel 处于活动状态, 提示 xx上线 @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { //这个是给服务端看的，客户端上面已经提示xxx加入群聊了 System.out.println(ctx.channel().remoteAddress() + \" 上线了~\"); } //表示channel 处于不活动状态, 提示 xx离线了 @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception { System.out.println(ctx.channel().remoteAddress() + \" 离线了~\"); } //读取数据，转发给在线的每一个客户端 @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception { //获取到当前channel Channel channel = ctx.channel(); //这时我们遍历channelGroup, 根据不同的情况，回送不同的消息 channelGroup.forEach(ch -> { if(channel != ch) { //不是当前的channel,转发消息 ch.writeAndFlush(\"[客户]\" + channel.remoteAddress() + \" 发送了消息\" + msg + \"\\n\"); }else {//回显自己发送的消息给自己 ch.writeAndFlush(\"[自己]发送了消息\" + msg + \"\\n\"); } }); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { //关闭通道 ctx.close(); } } 3.11.3. GroupChatClient package com.atguigu.netty.groupchat; import io.netty.bootstrap.Bootstrap; import io.netty.channel.*; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; import io.netty.handler.codec.string.StringDecoder; import io.netty.handler.codec.string.StringEncoder; import java.util.Scanner; public class GroupChatClient { //属性 private final String host; private final int port; public GroupChatClient(String host, int port) { this.host = host; this.port = port; } public void run() throws Exception{ EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap bootstrap = new Bootstrap() .group(group) .channel(NioSocketChannel.class) .handler(new ChannelInitializer() { @Override protected void initChannel(SocketChannel ch) throws Exception { //得到pipeline ChannelPipeline pipeline = ch.pipeline(); //加入相关handler pipeline.addLast(\"decoder\", new StringDecoder()); pipeline.addLast(\"encoder\", new StringEncoder()); //加入自定义的handler pipeline.addLast(new GroupChatClientHandler()); } }); ChannelFuture channelFuture = bootstrap.connect(host, port).sync(); //得到channel Channel channel = channelFuture.channel(); System.out.println(\"-------\" + channel.localAddress()+ \"--------\"); //客户端需要输入信息，创建一个扫描器 Scanner scanner = new Scanner(System.in); while (scanner.hasNextLine()) { String msg = scanner.nextLine(); //通过channel 发送到服务器端 channel.writeAndFlush(msg + \"\\r\\n\"); } }finally { group.shutdownGracefully(); } } public static void main(String[] args) throws Exception { new GroupChatClient(\"127.0.0.1\", 7000).run(); } } 3.11.4. GroupChatClientHandler package com.atguigu.netty.groupchat; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; public class GroupChatClientHandler extends SimpleChannelInboundHandler { //从服务器拿到的数据 @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception { System.out.println(msg.trim()); } } 3.12. Netty 心跳检测机制案例 实例要求： 编写一个 Netty 心跳检测机制案例,当服务器超过 3 秒没有读时，就提示读空闲 当服务器超过 5 秒没有写操作时，就提示写空闲 实现当服务器超过 7 秒没有读或者写操作时，就提示读写空闲 代码如下： 3.12.1. MyServer package com.atguigu.netty.heartbeat; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.logging.LogLevel; import io.netty.handler.logging.LoggingHandler; import io.netty.handler.timeout.IdleStateHandler; import java.util.concurrent.TimeUnit; public class MyServer { public static void main(String[] args) throws Exception{ //创建两个线程组 EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); //8个NioEventLoop try { ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(bossGroup, workerGroup); serverBootstrap.channel(NioServerSocketChannel.class); //在bossGroup增加一个日志处理器 serverBootstrap.handler(new LoggingHandler(LogLevel.INFO)); serverBootstrap.childHandler(new ChannelInitializer() { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); //加入一个netty 提供 IdleStateHandler /* 说明 1. IdleStateHandler 是netty 提供的处理空闲状态的处理器 2. long readerIdleTime : 表示多长时间没有读, 就会发送一个心跳检测包检测是否连接 3. long writerIdleTime : 表示多长时间没有写, 就会发送一个心跳检测包检测是否连接 4. long allIdleTime : 表示多长时间没有读写, 就会发送一个心跳检测包检测是否连接 5. 文档说明 triggers an {@link IdleStateEvent} when a {@link Channel} has not performed read, write, or both operation for a while. 6. 当 IdleStateEvent 触发后 , 就会传递给管道 的下一个handler去处理，通过调用(触发) 下一个handler 的 userEventTiggered , 在该方法中去处理 IdleStateEvent(读空闲，写空闲，读写空闲) 7.handlerRemoved有时候是无法感知连接断掉，所以还是需要心跳包的检测来判断连接是否还有效 */ pipeline.addLast(new IdleStateHandler(3,5,7, TimeUnit.SECONDS)); //加入一个对空闲检测进一步处理的handler(自定义) pipeline.addLast(new MyServerHandler()); } }); //启动服务器 ChannelFuture channelFuture = serverBootstrap.bind(7000).sync(); channelFuture.channel().closeFuture().sync(); }finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } 3.12.2. MyServerHandler package com.atguigu.netty.heartbeat; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundHandlerAdapter; import io.netty.handler.timeout.IdleStateEvent; public class MyServerHandler extends ChannelInboundHandlerAdapter { /** * * @param ctx 上下文 * @param evt 事件 * @throws Exception */ @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception { if(evt instanceof IdleStateEvent) { //将 evt 向下转型 IdleStateEvent IdleStateEvent event = (IdleStateEvent) evt; String eventType = null; switch (event.state()) { case READER_IDLE: eventType = \"读空闲\"; break; case WRITER_IDLE: eventType = \"写空闲\"; break; case ALL_IDLE: eventType = \"读写空闲\"; break; } System.out.println(ctx.channel().remoteAddress() + \"--超时时间--\" + eventType); System.out.println(\"服务器做相应处理..\"); //如果发生空闲，我们关闭通道 // ctx.channel().close(); } } } 3.13. Netty 通过 WebSocket 编程实现服务器和客户端长连接 实例要求： Http 协议是无状态的，浏览器和服务器间的请求响应一次，下一次会重新创建连接。 要求：实现基于 WebSocket 的长连接的全双工的交互 改变 Http 协议多次请求的约束，实现长连接了，服务器可以发送消息给浏览器 客户端浏览器和服务器端会相互感知，比如服务器关闭了，浏览器会感知，同样浏览器关闭了，服务器会感知 运行界面 3.13.1. MyServer package com.atguigu.netty.websocket; import com.atguigu.netty.heartbeat.MyServerHandler; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.codec.http.HttpObjectAggregator; import io.netty.handler.codec.http.HttpServerCodec; import io.netty.handler.codec.http.websocketx.WebSocketServerProtocolHandler; import io.netty.handler.logging.LogLevel; import io.netty.handler.logging.LoggingHandler; import io.netty.handler.stream.ChunkedWriteHandler; import io.netty.handler.timeout.IdleStateHandler; import java.util.concurrent.TimeUnit; public class MyServer { public static void main(String[] args) throws Exception{ //创建两个线程组 EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); //8个NioEventLoop try { ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(bossGroup, workerGroup); serverBootstrap.channel(NioServerSocketChannel.class); serverBootstrap.handler(new LoggingHandler(LogLevel.INFO)); serverBootstrap.childHandler(new ChannelInitializer() { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); //因为基于http协议，使用http的编码和解码器 pipeline.addLast(new HttpServerCodec()); //http是以块方式写，添加ChunkedWriteHandler处理器 pipeline.addLast(new ChunkedWriteHandler()); /* 说明 1. http数据在传输过程中是分段, HttpObjectAggregator ，就是可以将多个段聚合 2. 这就就是为什么，当浏览器发送大量数据时，就会发出多次http请求 */ pipeline.addLast(new HttpObjectAggregator(8192)); /* 说明 1. 对应websocket ，它的数据是以 帧(frame) 形式传递 2. 可以看到WebSocketFrame 下面有六个子类 3. 浏览器请求时 ws://localhost:7000/hello 表示请求的uri 4. WebSocketServerProtocolHandler 核心功能是将 http协议升级为 ws协议 , 保持长连接 5. 是通过一个 状态码 101 */ pipeline.addLast(new WebSocketServerProtocolHandler(\"/hello\")); //自定义的handler ，处理业务逻辑 pipeline.addLast(new MyTextWebSocketFrameHandler()); } }); //启动服务器 ChannelFuture channelFuture = serverBootstrap.bind(7000).sync(); channelFuture.channel().closeFuture().sync(); }finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } 3.13.2. MyTextWebSocketFrameHandler package com.atguigu.netty.websocket; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import io.netty.handler.codec.http.websocketx.TextWebSocketFrame; import java.time.LocalDateTime; //这里 TextWebSocketFrame 类型，表示一个文本帧(frame) public class MyTextWebSocketFrameHandler extends SimpleChannelInboundHandler{ @Override protected void channelRead0(ChannelHandlerContext ctx, TextWebSocketFrame msg) throws Exception { System.out.println(\"服务器收到消息 \" + msg.text()); //回复消息 ctx.channel().writeAndFlush(new TextWebSocketFrame(\"服务器时间\" + LocalDateTime.now() + \" \" + msg.text())); } //当web客户端连接后， 触发方法 @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception { //id 表示唯一的值，LongText 是唯一的 ShortText 不是唯一 System.out.println(\"handlerAdded 被调用\" + ctx.channel().id().asLongText()); System.out.println(\"handlerAdded 被调用\" + ctx.channel().id().asShortText()); } @Override public void handlerRemoved(ChannelHandlerContext ctx) throws Exception { System.out.println(\"handlerRemoved 被调用\" + ctx.channel().id().asLongText()); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { System.out.println(\"异常发生 \" + cause.getMessage()); ctx.close(); //关闭连接 } } 3.13.3. hello.html Title var socket; //判断当前浏览器是否支持websocket if(window.WebSocket) { //go on socket = new WebSocket(\"ws://localhost:7000/hello2\"); //相当于channelReado, ev 收到服务器端回送的消息 socket.onmessage = function (ev) { var rt = document.getElementById(\"responseText\"); rt.value = rt.value + \"\\n\" + ev.data; } //相当于连接开启(感知到连接开启) socket.onopen = function (ev) { var rt = document.getElementById(\"responseText\"); rt.value = \"连接开启了..\" } //相当于连接关闭(感知到连接关闭) socket.onclose = function (ev) { var rt = document.getElementById(\"responseText\"); rt.value = rt.value + \"\\n\" + \"连接关闭了..\" } } else { alert(\"当前浏览器不支持websocket\") } //发送消息到服务器 function send(message) { if(!window.socket) { //先判断socket是否创建好 return; } if(socket.readyState == WebSocket.OPEN) { //通过socket 发送消息 socket.send(message) } else { alert(\"连接没有开启\"); } } 可以看到并不是发一次数据，连接就关闭了，而是可以继续发送。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"7.Netty/3.Netty实现rpc.html":{"url":"7.Netty/3.Netty实现rpc.html","title":"3.Netty实现rpc","keywords":"","body":"1. Google Protobuf1.1. 编码和解码的基本介绍1.2. Netty 本身的编码解码的机制和问题分析1.3. Protobuf1.4. Protobuf 快速入门实例1.4.1. Student.proto1.4.2. NettyServer1.4.3. NettyServerHandler1.4.4. NettyClient1.4.5. NettyClientHandler1.5. Protobuf 快速入门实例 21.5.1. proto1.5.2. NettyServer1.5.3. NettyServerHandler1.5.4. NettyClient1.5.5. NettyClientHandler2. Netty 编解码器和 Handler 调用机制2.1. 基本说明2.2. 编码解码器2.3. 解码器 - ByteToMessageDecoder2.4. Netty的handler链的调用机制2.4.1. MyServer2.4.2. MyServerInitializer2.4.3. MyServerHandler2.4.4. MyClient2.4.5. MyClientInitializer2.4.6. MyClientHandler2.4.7. MyByteToLongDecoder2.4.8. MyLongToByteEncoder2.4.9. 效果2.4.10. 出站入站2.5. ByteToMessageDecoder的小细节2.6. 解码器 - ReplayingDecoder2.7. 其它编解码器2.8. Log4j 整合到 Netty3. TCP 粘包和拆包及解决方案3.1. TCP 粘包和拆包基本介绍3.2. TCP 粘包和拆包现象实例3.2.1. MyServer3.2.2. MyServerInitializer3.2.3. MyServerHandler3.2.4. MyClient3.2.5. MyClientInitializer3.2.6. MyClientHandler3.2.7. 效果3.3. TCP 粘包和拆包解决方案3.3.1. MessageProtocol3.3.2. MyServer3.3.3. MyServerInitializer3.3.4. MyServerHandler3.3.5. MyClient3.3.6. MyClientInitializer3.3.7. MyClientHandler3.3.8. MyMessageDecoder3.3.9. MyMessageEncoder3.3.10. 效果4. 用 Netty 自己实现简单的RPC4.1. RPC 基本介绍4.2. 我们的RPC 调用流程图4.3. 己实现 Dubbo RPC（基于 Netty）4.3.1. 需求说明4.3.2. 设计说明4.3.3. 代码4.3.4. 调用过程4.3.5. 效果1. Google Protobuf 1.1. 编码和解码的基本介绍 编写网络应用程序时，因为数据在网络中传输的都是二进制字节码数据，在发送数据时就需要编码，接收数据时就需要解码[示意图] codec（编解码器）的组成部分有两个：decoder（解码器）和 encoder（编码器）。encoder 负责把业务数据转换成字节码数据，decoder 负责把字节码数据转换成业务数据 1.2. Netty 本身的编码解码的机制和问题分析 Netty 自身提供了一些 codec(编解码器) Netty 提供的编码器 StringEncoder：对字符串数据进行编码。 ObjectEncoder：对Java对象进行编码。 Netty 提供的解码器 StringDecoder,对字符串数据进行解码 ObjectDecoder，对 Java 对象进行解码 Netty 本身自带的 ObjectDecoder 和 ObjectEncoder 可以用来实现 POJO 对象或各种业务对象的编码和解码，底层使用的仍是Java序列化技术,而Java序列化技术本身效率就不高，存在如下问题 无法跨语言 序列化后的体积太大，是二进制编码的5倍多。 序列化性能太低 引出新的解决方案[Google 的 Protobuf] 1.3. Protobuf Protobuf 基本介绍和使用示意图 Protobuf 是 Google 发布的开源项目，全称 Google Protocol Buffers，是一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化。它很适合做数据存储或 RPC [远程过程调用 remote procedure call ]数据交换格式。目前很多公司 从http + json 转向tcp + protobuf，效率会更高。 参考文档：https://developers.google.com/protocol-buffers/docs/proto 语言指南 Protobuf 是以 message 的方式来管理数据的. 支持跨平台、跨语言，即[客户端和服务器端可以是不同的语言编写的]（支持目前绝大多数语言，例如 C++、C#、Java、python 等） 高性能，高可靠性 使用 protobuf 编译器能自动生成代码，Protobuf 是将类的定义使用 .proto 文件进行描述。说明，在 idea 中编写 .proto 文件时，会自动提示是否下载 .ptoto 编写插件.可以让语法高亮。 然后通过 protoc.exe 编译器根据 .proto 自动生成 .java 文件 protobuf 使用示意图 1.4. Protobuf 快速入门实例 编写程序，使用 Protobuf 完成如下功能 客户端可以发送一个 StudentPoJo 对象到服务器(通过 Protobuf 编码) 服务端能接收 StudentPoJo 对象，并显示信息(通过 Protobuf 解码) com.google.protobuf protobuf-java 3.6.1 1.4.1. Student.proto syntax = \"proto3\"; //版本 option java_outer_classname = \"StudentPOJO\";//生成的外部类名，同时也是文件名 //protobuf 使用message 管理数据 message Student { //会在 StudentPOJO 外部类生成一个内部类 Student， 他是真正发送的POJO对象 int32 id = 1; // Student 类中有 一个属性 名字为 id 类型为int32(protobuf类型) 1表示属性序号，不是值 string name = 2; } 编译 protoc.exe --java_out=.Student.proto 将生成的 StudentPOJO 放入到项目使用 生成的StudentPOJO代码太长就不贴在这里了 1.4.2. NettyServer package com.atguigu.netty.codec; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.*; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.codec.protobuf.ProtobufDecoder; public class NettyServer { public static void main(String[] args) throws Exception { //创建BossGroup 和 WorkerGroup //说明 //1. 创建两个线程组 bossGroup 和 workerGroup //2. bossGroup 只是处理连接请求 , 真正的和客户端业务处理，会交给 workerGroup完成 //3. 两个都是无限循环 //4. bossGroup 和 workerGroup 含有的子线程(NioEventLoop)的个数 // 默认实际 cpu核数 * 2 EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); //8 try { //创建服务器端的启动对象，配置参数 ServerBootstrap bootstrap = new ServerBootstrap(); //使用链式编程来进行设置 bootstrap.group(bossGroup, workerGroup) //设置两个线程组 .channel(NioServerSocketChannel.class) //使用NioSocketChannel 作为服务器的通道实现 .option(ChannelOption.SO_BACKLOG, 128) // 设置线程队列得到连接个数 .childOption(ChannelOption.SO_KEEPALIVE, true) //设置保持活动连接状态 // .handler(null) // 该 handler对应 bossGroup , childHandler 对应 workerGroup .childHandler(new ChannelInitializer() {//创建一个通道初始化对象(匿名对象) //给pipeline 设置处理器 @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); //在pipeline加入ProtoBufDecoder //指定对哪种对象进行解码 pipeline.addLast(\"decoder\", new ProtobufDecoder(StudentPOJO.Student.getDefaultInstance())); pipeline.addLast(new NettyServerHandler()); } }); // 给我们的workerGroup 的 EventLoop 对应的管道设置处理器 System.out.println(\".....服务器 is ready...\"); //绑定一个端口并且同步, 生成了一个 ChannelFuture 对象 //启动服务器(并绑定端口) ChannelFuture cf = bootstrap.bind(6668).sync(); //给cf 注册监听器，监控我们关心的事件 cf.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (cf.isSuccess()) { System.out.println(\"监听端口 6668 成功\"); } else { System.out.println(\"监听端口 6668 失败\"); } } }); //对关闭通道进行监听 cf.channel().closeFuture().sync(); }finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } 1.4.3. NettyServerHandler package com.atguigu.netty.codec; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.*; import io.netty.util.CharsetUtil; /* 说明 1. 我们自定义一个Handler 需要继续netty 规定好的某个HandlerAdapter(规范) 2. 这时我们自定义一个Handler , 才能称为一个handler */ //public class NettyServerHandler extends ChannelInboundHandlerAdapter { public class NettyServerHandler extends SimpleChannelInboundHandler { //读取数据实际(这里我们可以读取客户端发送的消息) /* 1. ChannelHandlerContext ctx:上下文对象, 含有 管道pipeline , 通道channel, 地址 2. Object msg: 就是客户端发送的数据 默认Object */ @Override public void channelRead0(ChannelHandlerContext ctx, StudentPOJO.Student msg) throws Exception { //读取从客户端发送的StudentPojo.Student System.out.println(\"客户端发送的数据 id=\" + msg.getId() + \" 名字=\" + msg.getName()); } //数据读取完毕 @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { //writeAndFlush 是 write + flush //将数据写入到缓存，并刷新 //一般讲，我们对这个发送的数据进行编码 ctx.writeAndFlush(Unpooled.copiedBuffer(\"hello, 客户端~(>^ω^ 1.4.4. NettyClient package com.atguigu.netty.codec; import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; import io.netty.handler.codec.protobuf.ProtobufEncoder; public class NettyClient { public static void main(String[] args) throws Exception { //客户端需要一个事件循环组 EventLoopGroup group = new NioEventLoopGroup(); try { //创建客户端启动对象 //注意客户端使用的不是 ServerBootstrap 而是 Bootstrap Bootstrap bootstrap = new Bootstrap(); //设置相关参数 bootstrap.group(group) //设置线程组 .channel(NioSocketChannel.class) // 设置客户端通道的实现类(反射) .handler(new ChannelInitializer() { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); //在pipeline中加入 ProtoBufEncoder pipeline.addLast(\"encoder\", new ProtobufEncoder()); pipeline.addLast(new NettyClientHandler()); //加入自己的处理器 } }); System.out.println(\"客户端 ok..\"); //启动客户端去连接服务器端 //关于 ChannelFuture 要分析，涉及到netty的异步模型 ChannelFuture channelFuture = bootstrap.connect(\"127.0.0.1\", 6668).sync(); //给关闭通道进行监听 channelFuture.channel().closeFuture().sync(); }finally { group.shutdownGracefully(); } } } 1.4.5. NettyClientHandler package com.atguigu.netty.codec; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundHandlerAdapter; import io.netty.util.CharsetUtil; public class NettyClientHandler extends ChannelInboundHandlerAdapter { //当通道就绪就会触发该方法 @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { //发生一个Student 对象到服务器 StudentPOJO.Student student = StudentPOJO.Student.newBuilder().setId(4).setName(\"智多星 吴用\").build(); //Teacher , Member ,Message ctx.writeAndFlush(student); } //当通道有读取事件时，会触发 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\"服务器回复的消息:\" + buf.toString(CharsetUtil.UTF_8)); System.out.println(\"服务器的地址： \"+ ctx.channel().remoteAddress()); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); } } 1.5. Protobuf 快速入门实例 2 编写程序，使用 Protobuf 完成如下功能 客户端可以随机发送 StudentPoJo / WorkerPoJo 对象到服务器(通过 Protobuf 编码) 服务端能接收 StudentPoJo / WorkerPoJo 对象(需要判断是哪种类型)，并显示信息(通过 Protobuf 解码) 1.5.1. proto syntax = \"proto3\"; option optimize_for = SPEED; // 加快解析 option java_package=\"com.atguigu.netty.codec2\"; //指定生成到哪个包下 option java_outer_classname=\"MyDataInfo\"; // 外部类名, 文件名 /* 1.protobuf 可以使用message 管理其他的message。最终决定使用哪一个message作为传输对象 2.假设你某个项目需要传输20个对象，你不可能新建20个proto文件吧。此时你就可以 在一个文件里定义20个message，最后再用一个总的message（比方说这里的MyMessage） 来决定在实际传输时真正需要传输哪一个对象 3.因为你实际传输的时候大部分情况传输的都是一个对象，所以下面用oneof进行了限制 4.是否可以传多个对象呢？我个人认为是可以的，比如可以通过map(目前我也不太了解proto的语法) */ message MyMessage { //定义一个枚举类型,DataType如果是0则表示一个Student对象实例，DataType这个名称自定义 enum DataType { StudentType = 0; //在proto3 要求enum的编号从0开始 WorkerType = 1; } //用data_type 来标识传的是哪一个枚举类型，这里才真正开始定义MyMessage的数据类型 DataType data_type = 1; //所有后面的数字都只是编号而已 /* 1.oneof关键字 表示每次枚举类型进行传输时，限制最多只能传输一个对象。 dataBody名称也是自定义的 2.为什么这里的序号是2呢？因为上面DataType data_type = 1 占了第一个序号了 3.MyMessage里真正出现的类型只有两个 ①DataType类型 ②Student类型或者Worker类型（这两个在真正传输的时候只会有一个出现） */ oneof dataBody { Student student = 2; //注意这后面的数字也都只是编号而已 Worker worker = 3; } } message Student { int32 id = 1;//Student类的属性 string name = 2; // } message Worker { string name=1; int32 age=2; } 1.5.2. NettyServer package com.atguigu.netty.codec2; import com.atguigu.netty.codec.StudentPOJO; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.*; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.codec.protobuf.ProtobufDecoder; public class NettyServer { public static void main(String[] args) throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); //8 try { //创建服务器端的启动对象，配置参数 ServerBootstrap bootstrap = new ServerBootstrap(); //使用链式编程来进行设置 bootstrap.group(bossGroup, workerGroup) //设置两个线程组 .channel(NioServerSocketChannel.class) //使用NioSocketChannel 作为服务器的通道实现 .option(ChannelOption.SO_BACKLOG, 128) // 设置线程队列得到连接个数 .childOption(ChannelOption.SO_KEEPALIVE, true) //设置保持活动连接状态 // .handler(null) // 该 handler对应 bossGroup , childHandler 对应 workerGroup .childHandler(new ChannelInitializer() {//创建一个通道初始化对象(匿名对象) //给pipeline 设置处理器 @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); //在pipeline加入ProtoBufDecoder //指定对哪种对象进行解码 pipeline.addLast(\"decoder\", new ProtobufDecoder(MyDataInfo.MyMessage.getDefaultInstance())); pipeline.addLast(new NettyServerHandler()); } }); // 给我们的workerGroup 的 EventLoop 对应的管道设置处理器 System.out.println(\".....服务器 is ready...\"); //绑定一个端口并且同步, 生成了一个 ChannelFuture 对象 //启动服务器(并绑定端口) ChannelFuture cf = bootstrap.bind(6668).sync(); //给cf 注册监听器，监控我们关心的事件 cf.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (cf.isSuccess()) { System.out.println(\"监听端口 6668 成功\"); } else { System.out.println(\"监听端口 6668 失败\"); } } }); //对关闭通道进行监听 cf.channel().closeFuture().sync(); }finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } 1.5.3. NettyServerHandler package com.atguigu.netty.codec2; import com.atguigu.netty.codec.StudentPOJO; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import io.netty.util.CharsetUtil; //public class NettyServerHandler extends ChannelInboundHandlerAdapter { public class NettyServerHandler extends SimpleChannelInboundHandler { //读取数据实际(这里我们可以读取客户端发送的消息) /* 1. ChannelHandlerContext ctx:上下文对象, 含有 管道pipeline , 通道channel, 地址 2. Object msg: 就是客户端发送的数据 默认Object */ @Override public void channelRead0(ChannelHandlerContext ctx, MyDataInfo.MyMessage msg) throws Exception { //根据dataType 来显示不同的信息 MyDataInfo.MyMessage.DataType dataType = msg.getDataType(); if(dataType == MyDataInfo.MyMessage.DataType.StudentType) { MyDataInfo.Student student = msg.getStudent(); System.out.println(\"学生id=\" + student.getId() + \" 学生名字=\" + student.getName()); } else if(dataType == MyDataInfo.MyMessage.DataType.WorkerType) { MyDataInfo.Worker worker = msg.getWorker(); System.out.println(\"工人的名字=\" + worker.getName() + \" 年龄=\" + worker.getAge()); } else { System.out.println(\"传输的类型不正确\"); } } //数据读取完毕 @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { //writeAndFlush 是 write + flush //将数据写入到缓存，并刷新 //一般讲，我们对这个发送的数据进行编码 ctx.writeAndFlush(Unpooled.copiedBuffer(\"hello, 客户端~(>^ω^ 1.5.4. NettyClient package com.atguigu.netty.codec2; import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; import io.netty.handler.codec.protobuf.ProtobufEncoder; public class NettyClient { public static void main(String[] args) throws Exception { //客户端需要一个事件循环组 EventLoopGroup group = new NioEventLoopGroup(); try { //创建客户端启动对象 //注意客户端使用的不是 ServerBootstrap 而是 Bootstrap Bootstrap bootstrap = new Bootstrap(); //设置相关参数 bootstrap.group(group) //设置线程组 .channel(NioSocketChannel.class) // 设置客户端通道的实现类(反射) .handler(new ChannelInitializer() { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); //在pipeline中加入 ProtoBufEncoder pipeline.addLast(\"encoder\", new ProtobufEncoder()); pipeline.addLast(new NettyClientHandler()); //加入自己的处理器 } }); System.out.println(\"客户端 ok..\"); //启动客户端去连接服务器端 //关于 ChannelFuture 要分析，涉及到netty的异步模型 ChannelFuture channelFuture = bootstrap.connect(\"127.0.0.1\", 6668).sync(); //给关闭通道进行监听 channelFuture.channel().closeFuture().sync(); }finally { group.shutdownGracefully(); } } } 1.5.5. NettyClientHandler package com.atguigu.netty.codec2; import com.atguigu.netty.codec.StudentPOJO; import io.netty.buffer.ByteBuf; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundHandlerAdapter; import io.netty.util.CharsetUtil; import java.util.Random; public class NettyClientHandler extends ChannelInboundHandlerAdapter { //当通道就绪就会触发该方法 @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { //随机的发送Student 或者 Workder 对象 int random = new Random().nextInt(3); MyDataInfo.MyMessage myMessage = null; if(0 == random) { //发送Student 对象 myMessage = MyDataInfo.MyMessage.newBuilder().setDataType(MyDataInfo.MyMessage.DataType.StudentType).setStudent(MyDataInfo.Student.newBuilder().setId(5).setName(\"玉麒麟 卢俊义\").build()).build(); } else { // 发送一个Worker 对象 myMessage = MyDataInfo.MyMessage.newBuilder().setDataType(MyDataInfo.MyMessage.DataType.WorkerType).setWorker(MyDataInfo.Worker.newBuilder().setAge(20).setName(\"老李\").build()).build(); } ctx.writeAndFlush(myMessage); } //当通道有读取事件时，会触发 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\"服务器回复的消息:\" + buf.toString(CharsetUtil.UTF_8)); System.out.println(\"服务器的地址： \"+ ctx.channel().remoteAddress()); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); } } 2. Netty 编解码器和 Handler 调用机制 2.1. 基本说明 Netty 的组件设计：Netty 的主要组件有 Channel、EventLoop、ChannelFuture、ChannelHandler、ChannelPipe 等 ChannelHandler 充当了处理入站和出站数据的应用程序逻辑的容器。例如，实现 ChannelInboundHandler 接口（或 ChannelInboundHandlerAdapter），你就可以接收入站事件和数据，这些数据会被业务逻辑处理。当要给客户端发送响应时，也可以从 ChannelInboundHandler 冲刷数据。业务逻辑通常写在一个或者多个 ChannelInboundHandler 中。ChannelOutboundHandler 原理一样，只不过它是用来处理出站数据的 ChannelPipeline 提供了 ChannelHandler 链的容器。以客户端应用程序为例，如果事件的运动方向是从客户端到服务端的，那么我们称这些事件为出站的，即客户端发送给服务端的数据会通过 pipeline 中的一系列 ChannelOutboundHandler，并被这些 Handler 处理，反之则称为入站的 出站，入站如果搞不清楚，看下面的Netty的handler链的调用机制，通过一个例子和图讲清楚 2.2. 编码解码器 当 Netty 发送或者接受一个消息的时候，就将会发生一次数据转换。入站消息会被解码：从字节转换为另一种格式（比如 java 对象）；如果是出站消息，它会被编码成字节。 Netty 提供一系列实用的编解码器，他们都实现了 ChannelInboundHadnler 或者 ChannelOutboundHandler 接口。在这些类中，channelRead 方法已经被重写了。以入站为例，对于每个从入站 Channel 读取的消息，这个方法会被调用。随后，它将调用由解码器所提供的 decode() 方法进行解码，并将已经解码的字节转发给 ChannelPipeline 中的下一个 ChannelInboundHandler。 2.3. 解码器 - ByteToMessageDecoder 关系继承图 由于不可能知道远程节点是否会一次性发送一个完整的信息，tcp 有可能出现粘包拆包的问题，这个类会对入站数据进行缓冲，直到它准备好被处理.【后面有说TCP的粘包和拆包问题】 一个关于 ByteToMessageDecoder 实例分析 2.4. Netty的handler链的调用机制 实例要求: 使用自定义的编码器和解码器来说明 Netty 的 handler 调用机制 客户端发送 long -> 服务器 服务端发送 long -> 客户端 读者可以看下这个图，带着这个图去看下面的例子。 2.4.1. MyServer package com.atguigu.netty.inboundhandlerandoutboundhandler; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.nio.NioServerSocketChannel; public class MyServer { public static void main(String[] args) throws Exception{ EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(bossGroup,workerGroup).channel(NioServerSocketChannel.class).childHandler(new MyServerInitializer()); //自定义一个初始化类 ChannelFuture channelFuture = serverBootstrap.bind(7000).sync(); channelFuture.channel().closeFuture().sync(); }finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } 2.4.2. MyServerInitializer package com.atguigu.netty.inboundhandlerandoutboundhandler; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.socket.SocketChannel; public class MyServerInitializer extends ChannelInitializer { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline();//一会下断点 //入站的handler进行解码 MyByteToLongDecoder pipeline.addLast(new MyByteToLongDecoder()); //出站的handler进行编码 pipeline.addLast(new MyLongToByteEncoder()); //自定义的handler 处理业务逻辑 pipeline.addLast(new MyServerHandler()); System.out.println(\"xx\"); } } 2.4.3. MyServerHandler package com.atguigu.netty.inboundhandlerandoutboundhandler; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; public class MyServerHandler extends SimpleChannelInboundHandler { @Override protected void channelRead0(ChannelHandlerContext ctx, Long msg) throws Exception { System.out.println(\"从客户端\" + ctx.channel().remoteAddress() + \" 读取到long \" + msg); //给客户端发送一个long ctx.writeAndFlush(98765L); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); } } 2.4.4. MyClient package com.atguigu.netty.inboundhandlerandoutboundhandler; import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.nio.NioSocketChannel; public class MyClient { public static void main(String[] args) throws Exception{ EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group).channel(NioSocketChannel.class) .handler(new MyClientInitializer()); //自定义一个初始化类 ChannelFuture channelFuture = bootstrap.connect(\"localhost\", 7000).sync(); channelFuture.channel().closeFuture().sync(); }finally { group.shutdownGracefully(); } } } 2.4.5. MyClientInitializer package com.atguigu.netty.inboundhandlerandoutboundhandler; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.socket.SocketChannel; public class MyClientInitializer extends ChannelInitializer { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); //加入一个出站的handler 对数据进行一个编码 pipeline.addLast(new MyLongToByteEncoder()); //这时一个入站的解码器(入站handler ) pipeline.addLast(new MyByteToLongDecoder()); //加入一个自定义的handler ， 处理业务 pipeline.addLast(new MyClientHandler()); } } 2.4.6. MyClientHandler package com.atguigu.netty.inboundhandlerandoutboundhandler; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import io.netty.util.CharsetUtil; import java.nio.charset.Charset; public class MyClientHandler extends SimpleChannelInboundHandler { @Override protected void channelRead0(ChannelHandlerContext ctx, Long msg) throws Exception { System.out.println(\"服务器的ip=\" + ctx.channel().remoteAddress()); System.out.println(\"收到服务器消息=\" + msg); } //重写channelActive 发送数据 @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { System.out.println(\"MyClientHandler 发送数据\"); //ctx.writeAndFlush(Unpooled.copiedBuffer(\"\")) ctx.writeAndFlush(123456L); //发送的是一个long } } 2.4.7. MyByteToLongDecoder package com.atguigu.netty.inboundhandlerandoutboundhandler; import io.netty.buffer.ByteBuf; import io.netty.channel.ChannelHandlerContext; import io.netty.handler.codec.ByteToMessageDecoder; import java.util.List; public class MyByteToLongDecoder extends ByteToMessageDecoder { /** * * decode 会根据接收的数据，被调用多次, 直到确定没有新的元素被添加到list * , 或者是ByteBuf 没有更多的可读字节为止 * 如果list out 不为空，就会将list的内容传递给下一个 channelinboundhandler处理, * 该处理器的方法也会被调用多次 * * @param ctx 上下文对象 * @param in 入站的 ByteBuf * @param out List 集合，将解码后的数据传给下一个handler * @throws Exception */ @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List out) throws Exception { System.out.println(\"MyByteToLongDecoder 被调用\"); //因为 long 8个字节, 需要判断有8个字节，才能读取一个long if(in.readableBytes() >= 8) { out.add(in.readLong()); } } } 2.4.8. MyLongToByteEncoder package com.atguigu.netty.inboundhandlerandoutboundhandler; import io.netty.buffer.ByteBuf; import io.netty.channel.ChannelHandlerContext; import io.netty.handler.codec.MessageToByteEncoder; public class MyLongToByteEncoder extends MessageToByteEncoder { //编码方法 @Override protected void encode(ChannelHandlerContext ctx, Long msg, ByteBuf out) throws Exception { System.out.println(\"MyLongToByteEncoder encode 被调用\"); System.out.println(\"msg=\" + msg); out.writeLong(msg); } } 2.4.9. 效果 2.4.10. 出站入站 关于出站入站，很多人可能有点迷糊 1）客户端有出站入站，服务端也有出站入站 2）以客户端为例，如果有服务端传送的数据到达客户端，那么对于客户端来说就是入站； 如果客户端传送数据到服务端，那么对于客户端来说就是出站； 同理，对于服务端来说，也是一样的，有数据来就是入站，有数据输出就是出站 3）为什么服务端和客户端的Serverhandler都是继承SimpleChannelInboundHandler，而没有ChannelOutboundHandler出站类？ 实际上当我们在handler中调用ctx.writeAndFlush()方法后，就会将数据交给ChannelOutboundHandler进行出站处理，只是我们没有去定义出站类而已，若有需求可以自己去实现ChannelOutboundHandler出站类 4）总结就是客户端和服务端都有出站和入站的操作 服务端发数据给客户端：服务端--->出站--->Socket通道--->入站--->客户端 ​ 客户端发数据给服务端：客户端--->出站--->Socket通道--->入站--->服务端 ​ 下面是Netty官方源码给的图，我个人觉的不是太好理解，上面的图好理解一些 2.5. ByteToMessageDecoder的小细节 package com.atguigu.netty.inboundhandlerandoutboundhandler; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import io.netty.util.CharsetUtil; import java.nio.charset.Charset; public class MyClientHandler extends SimpleChannelInboundHandler { @Override protected void channelRead0(ChannelHandlerContext ctx, Long msg) throws Exception { System.out.println(\"服务器的ip=\" + ctx.channel().remoteAddress()); System.out.println(\"收到服务器消息=\" + msg); } //重写channelActive 发送数据 @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { System.out.println(\"MyClientHandler 发送数据\"); //分析 //1. \"abcdabcdabcdabcd\" 是 16个字节 ctx.writeAndFlush(Unpooled.copiedBuffer(\"abcdabcdabcdabcd\",CharsetUtil.UTF_8)); } } package com.atguigu.netty.inboundhandlerandoutboundhandler; import io.netty.buffer.ByteBuf; import io.netty.channel.ChannelHandlerContext; import io.netty.handler.codec.ByteToMessageDecoder; import java.util.List; public class MyByteToLongDecoder extends ByteToMessageDecoder { /** * * decode 会根据接收的数据，被调用多次, 直到确定没有新的元素被添加到list * , 或者是ByteBuf 没有更多的可读字节为止 * 如果list out 不为空，就会将list的内容传递给下一个 channelinboundhandler处理, * 该处理器的方法也会被调用多次 * * @param ctx 上下文对象 * @param in 入站的 ByteBuf * @param out List 集合，将解码后的数据传给下一个handler * @throws Exception */ @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List out) throws Exception { System.out.println(\"MyByteToLongDecoder 被调用\"); //因为 long 8个字节, 需要判断有8个字节，才能读取一个long if(in.readableBytes() >= 8) { out.add(in.readLong()); } } } 由于发送的字符串是16字节，根据上面注释说的内容，decode会被调用两次 如下图验证结果： 同时又引出了一个小问题 当我们MyClientHandler传一个Long时，会调用我们的MyLongToByteEncoder的编码器。那么控制台就会打印这样一句话：MyLongToByteEncoder encode 被调用。但是这里并没有调用编码器，这是为什么呢？ MyClientHandler这个处理器的后一个处理器是MyLongToByteEncoder MyLongToByteEncoder的父类是MessageToByteEncoder，在MessageToByteEncoder中有下面的一个方法 @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception { ByteBuf buf = null; try { //这里会判断当前msg 是不是应该处理的类型，如果是就处理，不是就跳过encode if (acceptOutboundMessage(msg)) { @SuppressWarnings(\"unchecked\") I cast = (I) msg; buf = allocateBuffer(ctx, cast, preferDirect); try { encode(ctx, cast, buf); } finally { ReferenceCountUtil.release(cast); } if (buf.isReadable()) { ctx.write(buf, promise); } else { buf.release(); ctx.write(Unpooled.EMPTY_BUFFER, promise); } buf = null; } else { ctx.write(msg, promise); } } catch (EncoderException e) { throw e; } catch (Throwable e) { throw new EncoderException(e); } finally { if (buf != null) { buf.release(); } } } ​ 当我们以这样的形式发送数据 ctx.writeAndFlush(Unpooled.copiedBuffer(\"abcdabcdabcdabcd\",CharsetUtil.UTF_8)); ![](../img/n12.png\" /> 这两个类型并不匹配，也就不会走编码器。因此我们编写 Encoder 是要注意传入的数据类型和处理的数据类型一致 结论： 不论解码器 handler 还是编码器 handler 即接收的消息类型必须与待处理的消息类型一致，否则该 handler 不会被执行 在解码器进行数据解码时，需要判断缓存区（ByteBuf）的数据是否足够，否则接收到的结果会期望结果可能不一致。 2.6. 解码器 - ReplayingDecoder public abstract class ReplayingDecoder extends ByteToMessageDecoder ReplayingDecoder 扩展了 ByteToMessageDecoder 类，使用这个类，我们不必调用 readableBytes() 方法，也就不用判断还有没有足够的数据来读取。参数 S 指定了用户状态管理的类型，其中 Void 代表不需要状态管理 应用实例：使用 ReplayingDecoder 编写解码器，对前面的案例进行简化[案例演示] package com.atguigu.netty.inboundhandlerandoutboundhandler; import io.netty.buffer.ByteBuf; import io.netty.channel.ChannelHandlerContext; import io.netty.handler.codec.ReplayingDecoder; import java.util.List; public class MyByteToLongDecoder2 extends ReplayingDecoder { @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List out) throws Exception { System.out.println(\"MyByteToLongDecoder2 被调用\"); //在 ReplayingDecoder 不需要判断数据是否足够读取，内部会进行处理判断 out.add(in.readLong()); } } ReplayingDecoder 使用方便，但它也有一些局限性： 并不是所有的 ByteBuf 操作都被支持，如果调用了一个不被支持的方法，将会抛出一个 UnsupportedOperationException。 ReplayingDecoder 在某些情况下可能稍慢于 ByteToMessageDecoder，例如网络缓慢并且消息格式复杂时，消息会被拆成了多个碎片，速度变慢 2.7. 其它编解码器 LineBasedFrameDecoder：这个类在 Netty 内部也有使用，它使用行尾控制字符（\\n或者\\r\\n）作为分隔符来解析数据。 DelimiterBasedFrameDecoder：使用自定义的特殊字符作为消息的分隔符。 HttpObjectDecoder：一个 HTTP 数据的解码器 LengthFieldBasedFrameDecoder：通过指定长度来标识整包消息，这样就可以自动的处理黏包和半包消息。 2.8. Log4j 整合到 Netty 在 Maven 中添加对 Log4j 的依赖在 pom.xml log4j log4j 1.2.17 org.slf4j slf4j-api 1.7.25 org.slf4j slf4j-log4j12 1.7.25 test org.slf4j slf4j-simple 1.7.25 test 配置 Log4j，在 resources/log4j.properties log4j.rootLogger=DEBUG,stdout log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=[%p]%C{1}-%m%n 演示整合 3. TCP 粘包和拆包及解决方案 3.1. TCP 粘包和拆包基本介绍 TCP 是面向连接的，面向流的，提供高可靠性服务。收发两端（客户端和服务器端）都要有一一成对的 socket，因此，发送端为了将多个发给接收端的包，更有效的发给对方，使用了优化方法（Nagle 算法），将多次间隔较小且数据量小的数据，合并成一个大的数据块，然后进行封包。这样做虽然提高了效率，但是接收端就难于分辨出完整的数据包了，因为面向流的通信是无消息保护边界的 由于 TCP 无消息保护边界,需要在接收端处理消息边界问题，也就是我们所说的粘包、拆包问题,看一张图 TCP 粘包、拆包图解 假设客户端分别发送了两个数据包 D1 和 D2 给服务端，由于服务端一次读取到字节数是不确定的，故可能存在以下四种情况： 服务端分两次读取到了两个独立的数据包，分别是 D1 和 D2，没有粘包和拆包 服务端一次接受到了两个数据包，D1 和 D2 粘合在一起，称之为 TCP 粘包 服务端分两次读取到了数据包，第一次读取到了完整的 D1 包和 D2 包的部分内容，第二次读取到了 D2 包的剩余内容，这称之为 TCP 拆包 服务端分两次读取到了数据包，第一次读取到了 D1 包的部分内容 D1_1，第二次读取到了 D1 包的剩余部分内容 D1_2 和完整的 D2 包。 3.2. TCP 粘包和拆包现象实例 在编写 Netty 程序时，如果没有做处理，就会发生粘包和拆包的问题 看一个具体的实例： 3.2.1. MyServer package com.atguigu.netty.tcp; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.nio.NioServerSocketChannel; public class MyServer { public static void main(String[] args) throws Exception{ EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(bossGroup,workerGroup).channel(NioServerSocketChannel.class).childHandler(new MyServerInitializer()); //自定义一个初始化类 ChannelFuture channelFuture = serverBootstrap.bind(7000).sync(); channelFuture.channel().closeFuture().sync(); }finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } 3.2.2. MyServerInitializer package com.atguigu.netty.tcp; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.socket.SocketChannel; public class MyServerInitializer extends ChannelInitializer { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new MyServerHandler()); } } 3.2.3. MyServerHandler package com.atguigu.netty.tcp; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import java.nio.charset.Charset; import java.util.UUID; public class MyServerHandler extends SimpleChannelInboundHandler{ private int count; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { //cause.printStackTrace(); ctx.close(); } @Override protected void channelRead0(ChannelHandlerContext ctx, ByteBuf msg) throws Exception { byte[] buffer = new byte[msg.readableBytes()]; msg.readBytes(buffer); //将buffer转成字符串 String message = new String(buffer, Charset.forName(\"utf-8\")); System.out.println(\"服务器接收到数据 \" + message); System.out.println(\"服务器接收到消息量=\" + (++this.count)); //服务器回送数据给客户端, 回送一个随机id , ByteBuf responseByteBuf = Unpooled.copiedBuffer(UUID.randomUUID().toString() + \" \", Charset.forName(\"utf-8\")); ctx.writeAndFlush(responseByteBuf); } } 3.2.4. MyClient package com.atguigu.netty.tcp; import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.nio.NioSocketChannel; public class MyClient { public static void main(String[] args) throws Exception{ EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group).channel(NioSocketChannel.class) .handler(new MyClientInitializer()); //自定义一个初始化类 ChannelFuture channelFuture = bootstrap.connect(\"localhost\", 7000).sync(); channelFuture.channel().closeFuture().sync(); }finally { group.shutdownGracefully(); } } } 3.2.5. MyClientInitializer package com.atguigu.netty.tcp; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.socket.SocketChannel; public class MyClientInitializer extends ChannelInitializer { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new MyClientHandler()); } } 3.2.6. MyClientHandler package com.atguigu.netty.tcp; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import java.nio.charset.Charset; public class MyClientHandler extends SimpleChannelInboundHandler { private int count; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { //使用客户端发送10条数据 hello,server 编号 for(int i= 0; i 3.2.7. 效果 第一次运行： Client Server 第二次运行： Client Server 可以看到第一次运行时，服务器一次性将10个数据都接收了，第二次运行时分六次接收的，这就很形象的看出了TCP的粘包现象。 3.3. TCP 粘包和拆包解决方案 常用方案：使用自定义协议+编解码器来解决 关键就是要解决服务器端每次读取数据长度的问题，这个问题解决，就不会出现服务器多读或少读数据的问题，从而避免的 TCP 粘包、拆包。 看一个具体的实例 要求客户端发送 5 个 Message 对象，客户端每次发送一个 Message 对象 服务器端每次接收一个 Message，分 5 次进行解码，每读取到一个 Message，会回复一个 Message 对象给客户端。 3.3.1. MessageProtocol package com.atguigu.netty.protocoltcp; //协议包 public class MessageProtocol { private int len; //关键 private byte[] content; public int getLen() { return len; } public void setLen(int len) { this.len = len; } public byte[] getContent() { return content; } public void setContent(byte[] content) { this.content = content; } } 3.3.2. MyServer package com.atguigu.netty.protocoltcp; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.nio.NioServerSocketChannel; public class MyServer { public static void main(String[] args) throws Exception{ EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(bossGroup,workerGroup).channel(NioServerSocketChannel.class).childHandler(new MyServerInitializer()); //自定义一个初始化类 ChannelFuture channelFuture = serverBootstrap.bind(7000).sync(); channelFuture.channel().closeFuture().sync(); }finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } 3.3.3. MyServerInitializer package com.atguigu.netty.protocoltcp; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.socket.SocketChannel; public class MyServerInitializer extends ChannelInitializer { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new MyMessageDecoder());//解码器 pipeline.addLast(new MyMessageEncoder());//编码器 pipeline.addLast(new MyServerHandler()); } } 3.3.4. MyServerHandler package com.atguigu.netty.protocoltcp; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import java.nio.charset.Charset; import java.util.UUID; //处理业务的handler public class MyServerHandler extends SimpleChannelInboundHandler{ private int count; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { //cause.printStackTrace(); ctx.close(); } @Override protected void channelRead0(ChannelHandlerContext ctx, MessageProtocol msg) throws Exception { //接收到数据，并处理 int len = msg.getLen(); byte[] content = msg.getContent(); System.out.println(\"服务器接收到信息如下\"); System.out.println(\"长度=\" + len); System.out.println(\"内容=\" + new String(content, Charset.forName(\"utf-8\"))); System.out.println(\"服务器接收到消息包数量=\" + (++this.count)); //回复消息 System.out.println(\"服务端开始回复消息------\"); String responseContent = UUID.randomUUID().toString(); int responseLen = responseContent.getBytes(\"utf-8\").length; byte[] responseContent2 = responseContent.getBytes(\"utf-8\"); //构建一个协议包 MessageProtocol messageProtocol = new MessageProtocol(); messageProtocol.setLen(responseLen); messageProtocol.setContent(responseContent2); ctx.writeAndFlush(messageProtocol); } } 3.3.5. MyClient package com.atguigu.netty.protocoltcp; import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.nio.NioSocketChannel; public class MyClient { public static void main(String[] args) throws Exception{ EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group).channel(NioSocketChannel.class) .handler(new MyClientInitializer()); //自定义一个初始化类 ChannelFuture channelFuture = bootstrap.connect(\"localhost\", 7000).sync(); channelFuture.channel().closeFuture().sync(); }finally { group.shutdownGracefully(); } } } 3.3.6. MyClientInitializer package com.atguigu.netty.protocoltcp; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.socket.SocketChannel; public class MyClientInitializer extends ChannelInitializer { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new MyMessageEncoder()); //加入编码器 pipeline.addLast(new MyMessageDecoder()); //加入解码器 pipeline.addLast(new MyClientHandler()); } } 3.3.7. MyClientHandler package com.atguigu.netty.protocoltcp; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import java.nio.charset.Charset; public class MyClientHandler extends SimpleChannelInboundHandler { private int count; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { //使用客户端发送10条数据 \"今天天气冷，吃火锅\" 编号 for(int i = 0; i 3.3.8. MyMessageDecoder package com.atguigu.netty.protocoltcp; import io.netty.buffer.ByteBuf; import io.netty.channel.ChannelHandlerContext; import io.netty.handler.codec.ReplayingDecoder; import java.util.List; public class MyMessageDecoder extends ReplayingDecoder { @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List out) throws Exception { System.out.println(); System.out.println(); System.out.println(\"MyMessageDecoder decode 被调用\"); //需要将得到二进制字节码-> MessageProtocol 数据包(对象) int length = in.readInt(); byte[] content = new byte[length]; in.readBytes(content); //封装成 MessageProtocol 对象，放入 out， 传递下一个handler业务处理 MessageProtocol messageProtocol = new MessageProtocol(); messageProtocol.setLen(length); messageProtocol.setContent(content); //放入out传给下一个hanlder进行处理 out.add(messageProtocol); } } 3.3.9. MyMessageEncoder package com.atguigu.netty.protocoltcp; import io.netty.buffer.ByteBuf; import io.netty.channel.ChannelHandlerContext; import io.netty.handler.codec.MessageToByteEncoder; public class MyMessageEncoder extends MessageToByteEncoder { @Override protected void encode(ChannelHandlerContext ctx, MessageProtocol msg, ByteBuf out) throws Exception { System.out.println(\"MyMessageEncoder encode 方法被调用\"); out.writeInt(msg.getLen()); out.writeBytes(msg.getContent()); } } 3.3.10. 效果 Client输出 MyMessageEncoder encode 方法被调用 MyMessageEncoder encode 方法被调用 MyMessageEncoder encode 方法被调用 MyMessageEncoder encode 方法被调用 MyMessageEncoder encode 方法被调用 //下面是客户端开始一个一个的收到服务端的回复 MyMessageDecoder decode 被调用 客户端接收到消息如下 长度=36 内容=1b5286dd-0fc2-4f62-9bf7-d5fad84179b5 客户端接收消息数量=1 MyMessageDecoder decode 被调用 客户端接收到消息如下 长度=36 内容=653d18cb-ab72-4163-8b95-09c94ecac873 客户端接收消息数量=2 MyMessageDecoder decode 被调用 客户端接收到消息如下 长度=36 内容=3be6e403-91bb-4437-ada8-6cdb9eb7ef00 客户端接收消息数量=3 MyMessageDecoder decode 被调用 客户端接收到消息如下 长度=36 内容=94c8f306-fd9c-455a-956c-16698ce4150b 客户端接收消息数量=4 MyMessageDecoder decode 被调用 客户端接收到消息如下 长度=36 内容=7890de9c-0fa2-4317-8de1-1d464315fa1b 客户端接收消息数量=5 Server输出 MyMessageDecoder decode 被调用 服务器接收到信息如下 长度=27 内容=今天天气冷，吃火锅 服务器接收到消息包数量=1 服务端开始回复消息------ MyMessageEncoder encode 方法被调用 MyMessageDecoder decode 被调用 服务器接收到信息如下 长度=27 内容=今天天气冷，吃火锅 服务器接收到消息包数量=2 服务端开始回复消息------ MyMessageEncoder encode 方法被调用 MyMessageDecoder decode 被调用 服务器接收到信息如下 长度=27 内容=今天天气冷，吃火锅 服务器接收到消息包数量=3 服务端开始回复消息------ MyMessageEncoder encode 方法被调用 MyMessageDecoder decode 被调用 服务器接收到信息如下 长度=27 内容=今天天气冷，吃火锅 服务器接收到消息包数量=4 服务端开始回复消息------ MyMessageEncoder encode 方法被调用 MyMessageDecoder decode 被调用 服务器接收到信息如下 长度=27 内容=今天天气冷，吃火锅 服务器接收到消息包数量=5 服务端开始回复消息------ MyMessageEncoder encode 方法被调用 无论运行几次，Server都是分5次接收的，这样就解决了TCP粘包问题。 4. 用 Netty 自己实现简单的RPC 4.1. RPC 基本介绍 RPC（Remote Procedure Call）—远程过程调用，是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程 两个或多个应用程序都分布在不同的服务器上，它们之间的调用都像是本地方法调用一样(如图) 过程： 调用者(Caller)，调用远程API(Remote API) 调用远程API会通过一个RPC代理(RpcProxy) RPC代理再去调用RpcInvoker(这个是PRC的调用者) RpcInvoker通过RPC连接器(RpcConnector) RPC连接器用两台机器规定好的PRC协议(RpcProtocol)把数据进行编码 接着RPC连接器通过RpcChannel通道发送到对方的PRC接收器(RpcAcceptor) PRC接收器通过PRC协议进行解码拿到数据 然后将数据传给RpcProcessor RpcProcessor再传给RpcInvoker RpcInvoker调用Remote API 最后推给被调用者(Callee) 常见的 RPC 框架有：比较知名的如阿里的 Dubbo、Google 的 gRPC、Go 语言的 rpcx、Apache 的 thrift，Spring 旗下的 SpringCloud。 4.2. 我们的RPC 调用流程图 RPC 调用流程说明 服务消费方（client）以本地调用方式调用服务 client stub 接收到调用后负责将方法、参数等封装成能够进行网络传输的消息体 client stub 将消息进行编码并发送到服务端 server stub 收到消息后进行解码 server stub 根据解码结果调用本地的服务 本地服务执行并将结果返回给 server stub server stub 将返回导入结果进行编码并发送至消费方 client stub 接收到消息并进行解码 服务消费方（client）得到结果 小结：RPC 的目标就是将 2 - 8 这些步骤都封装起来，用户无需关心这些细节，可以像调用本地方法一样即可完成远程服务调用 4.3. 己实现 Dubbo RPC（基于 Netty） 4.3.1. 需求说明 Dubbo 底层使用了 Netty 作为网络通讯框架，要求用 Netty 实现一个简单的 RPC 框架 模仿 Dubbo，消费者和提供者约定接口和协议，消费者远程调用提供者的服务，提供者返回一个字符串，消费者打印提供者返回的数据。底层网络通信使用 Netty 4.1.20 4.3.2. 设计说明 创建一个接口，定义抽象方法。用于消费者和提供者之间的约定。 创建一个提供者，该类需要监听消费者的请求，并按照约定返回数据。 创建一个消费者，该类需要透明的调用自己不存在的方法，内部需要使用 Netty 请求提供者返回数据 开发的分析图 ![](../img/n24.png\" /> 4.3.3. 代码 封装的RPC 可以把这块代码理解成封装的dubbo NettyServer package com.atguigu.netty.dubborpc.netty; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.codec.string.StringDecoder; import io.netty.handler.codec.string.StringEncoder; public class NettyServer { public static void startServer(String hostName, int port) { startServer0(hostName,port); } //编写一个方法，完成对NettyServer的初始化和启动 private static void startServer0(String hostname, int port) { EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(bossGroup,workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer() { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new StringDecoder()); pipeline.addLast(new StringEncoder()); pipeline.addLast(new NettyServerHandler()); //业务处理器 } } ); ChannelFuture channelFuture = serverBootstrap.bind(hostname, port).sync(); System.out.println(\"服务提供方开始提供服务~~\"); channelFuture.channel().closeFuture().sync(); }catch (Exception e) { e.printStackTrace(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } NettyServerHandler package com.atguigu.netty.dubborpc.netty; import com.atguigu.netty.dubborpc.customer.ClientBootstrap; import com.atguigu.netty.dubborpc.provider.HelloServiceImpl; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundHandlerAdapter; //服务器这边handler比较简单 public class NettyServerHandler extends ChannelInboundHandlerAdapter { @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\"---服务端开始收到来自客户单的消息---\"); //获取客户端发送的消息，并调用服务 System.out.println(\"原始消息：\" + msg); /* 1.客户端在调用服务器的api 时，我们需要定义一个协议，比如我们要求 每次发消息是都 必须以某个字符串开头 \"HelloService#hello#你好\" 2.Dubbo注册在Zookeeper里时，这种就是类的全路径字符串，你用IDEA的zookeeper插件 就可以清楚地看到 */ if(msg.toString().startsWith(ClientBootstrap.providerName)) { String result = new HelloServiceImpl().hello(msg.toString().substring(msg.toString().lastIndexOf(\"#\") + 1)); ctx.writeAndFlush(result); } } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { ctx.close(); } } NettyClientHandler package com.atguigu.netty.dubborpc.netty; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundHandlerAdapter; import java.util.concurrent.Callable; public class NettyClientHandler extends ChannelInboundHandlerAdapter implements Callable { private ChannelHandlerContext context;//上下文 private String result; //返回的结果 private String para; //客户端调用方法时，传入的参数 //与服务器的连接创建后，就会被调用, 这个方法是第一个被调用(1) @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { System.out.println(\" channelActive 被调用 \"); context = ctx; //因为我们在其它方法会使用到 ctx } //收到服务器的数据后，调用方法 (4) // @Override public synchronized void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\" channelRead 被调用 \"); result = msg.toString(); notify(); //唤醒等待的线程 } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { ctx.close(); } //被代理对象调用, 发送数据给服务器，-> wait -> 等待被唤醒(channelRead) -> 返回结果 (3)-》5 @Override public synchronized Object call() throws Exception { System.out.println(\" call1 被调用 \"); context.writeAndFlush(para); //进行wait wait(); //等待channelRead 方法获取到服务器的结果后，唤醒 System.out.println(\" call2 被调用 \"); return result; //服务方返回的结果 } //(2) void setPara(String para) { System.out.println(\" setPara \"); this.para = para; } } NettyClient package com.atguigu.netty.dubborpc.netty; import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.ChannelPipeline; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; import io.netty.handler.codec.string.StringDecoder; import io.netty.handler.codec.string.StringEncoder; import java.lang.reflect.Proxy; import java.util.concurrent.Executor; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class NettyClient { //创建线程池 private static ExecutorService executor = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors()); private static NettyClientHandler client; private int count = 0; //编写方法使用代理模式，获取一个代理对象 public Object getBean(final Class serivceClass, final String providerName) { return Proxy.newProxyInstance(Thread.currentThread().getContextClassLoader(), new Class[]{serivceClass}, (proxy, method, args) -> { System.out.println(\"(proxy, method, args) 进入....\" + (++count) + \" 次\"); //{} 部分的代码，客户端每调用一次 hello, 就会进入到该代码 if (client == null) { initClient(); } //设置要发给服务器端的信息 //providerName：协议头，args[0]：就是客户端要发送给服务端的数据 client.setPara(providerName + args[0]); // return executor.submit(client).get(); }); } //初始化客户端 private static void initClient() { client = new NettyClientHandler(); //创建EventLoopGroup NioEventLoopGroup group = new NioEventLoopGroup(); Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler( new ChannelInitializer() { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new StringDecoder()); pipeline.addLast(new StringEncoder()); pipeline.addLast(client); } } ); try { bootstrap.connect(\"127.0.0.1\", 7000).sync(); } catch (Exception e) { e.printStackTrace(); } } } 接口 package com.atguigu.netty.dubborpc.publicinterface; //这个是接口，是服务提供方和 服务消费方都需要 public interface HelloService { String hello(String mes); } 服务端(provider) HelloServiceImpl package com.atguigu.netty.dubborpc.provider; import com.atguigu.netty.dubborpc.publicinterface.HelloService; public class HelloServiceImpl implements HelloService{ private static int count = 0; //当有消费方调用该方法时， 就返回一个结果 @Override public String hello(String mes) { System.out.println(\"收到客户端消息=\" + mes); System.out.println(); //根据mes 返回不同的结果 if(mes != null) { return \"你好客户端, 我已经收到你的消息。消息为：[\" + mes + \"] ，第\" + (++count) + \" 次 \\n\"; } else { return \"你好客户端, 我已经收到你的消息 \"; } } } ServerBootstrap package com.atguigu.netty.dubborpc.provider; import com.atguigu.netty.dubborpc.netty.NettyServer; //ServerBootstrap 会启动一个服务提供者，就是 NettyServer public class ServerBootstrap { public static void main(String[] args) { //代码代填.. NettyServer.startServer(\"127.0.0.1\", 7000); } } 客户端(消费者) package com.atguigu.netty.dubborpc.customer; import com.atguigu.netty.dubborpc.netty.NettyClient; import com.atguigu.netty.dubborpc.publicinterface.HelloService; public class ClientBootstrap { //这里定义协议头 public static final String providerName = \"HelloService#hello#\"; public static void main(String[] args) throws Exception{ //创建一个消费者 NettyClient customer = new NettyClient(); //创建代理对象 HelloService service = (HelloService) customer.getBean(HelloService.class, providerName); for (;; ) { Thread.sleep(2 * 1000); //通过代理对象调用服务提供者的方法(服务) String res = service.hello(\"你好 dubbo~\"); System.out.println(\"调用的结果 res= \" + res); } } } 4.3.4. 调用过程 ClientBootstrap#main发起调用 走到下面这一行代码后 HelloService service = (HelloService) customer.getBean(HelloService.class, providerName); 调用NettyClient#getBean，在此方法里与服务端建立链接。 于是就执行NettyClientHandler#channelActive 接着回到NettyClient#getBean调用NettyClientHandler#setPara，调用完之后再回到NettyClient#getBean，用线程池提交任务 因为用线程池提交了任务，就准备执行NettyClientHandler#call线程任务 在NettyClientHandler#call中发送数据给服务提供者 context.writeAndFlush(para); 由于还没收到服务提供者的数据结果，所以wait住 来到了服务提供者这边，从Socket通道中收到了数据，所以执行NettyServerHandler#channelRead，然后因为此方法中执行了 String result = new HelloServiceImpl().hello(msg.toString().substring(msg.toString().lastIndexOf(\"#\") + 1)); 就去HelloServiceImpl#hello中执行业务逻辑，返回数据给NettyServerHandler#channelRead，NettyServerHandler#channelRead再把数据发给客户端 NettyClientHandler#channelRead收到服务提供者发来的数据，唤醒之前wait的线程 所以之前wait的线程从NettyClientHandler#call苏醒，返回result给NettyClient#getBean NettyClient#getBeanget()到数据，ClientBootstrap#main中的此函数调用返回，得到服务端提供的数据。 String res = service.hello(\"你好 dubbo~\"); 13.至此，一次RPC调用结束。 4.3.5. 效果 ClientBootstrap打印 (proxy, method, args) 进入....1 次 setPara channelActive 被调用 call1 被调用 channelRead 被调用 call2 被调用 调用的结果 res= 你好客户端, 我已经收到你的消息。消息为：[你好 dubbo~] ，第1 次 (proxy, method, args) 进入....2 次 setPara call1 被调用 channelRead 被调用 call2 被调用 调用的结果 res= 你好客户端, 我已经收到你的消息。消息为：[你好 dubbo~] ，第2 次 (proxy, method, args) 进入....3 次 setPara call1 被调用 channelRead 被调用 call2 被调用 调用的结果 res= 你好客户端, 我已经收到你的消息。消息为：[你好 dubbo~] ，第3 次 (proxy, method, args) 进入....4 次 setPara call1 被调用 channelRead 被调用 call2 被调用 调用的结果 res= 你好客户端, 我已经收到你的消息。消息为：[你好 dubbo~] ，第4 次 (proxy, method, args) 进入....5 次 setPara call1 被调用 channelRead 被调用 call2 被调用 调用的结果 res= 你好客户端, 我已经收到你的消息。消息为：[你好 dubbo~] ，第5 次 ServerBootstrap打印 服务提供方开始提供服务~~ ---服务端开始收到来自客户单的消息--- 原始消息：HelloService#hello#你好 dubbo~ 收到客户端消息=你好 dubbo~ ---服务端开始收到来自客户单的消息--- 原始消息：HelloService#hello#你好 dubbo~ 收到客户端消息=你好 dubbo~ ---服务端开始收到来自客户单的消息--- 原始消息：HelloService#hello#你好 dubbo~ 收到客户端消息=你好 dubbo~ ---服务端开始收到来自客户单的消息--- 原始消息：HelloService#hello#你好 dubbo~ 收到客户端消息=你好 dubbo~ ---服务端开始收到来自客户单的消息--- 原始消息：HelloService#hello#你好 dubbo~ 收到客户端消息=你好 dubbo~ 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"8.大数据相关/flink/1.docker部署flink.html":{"url":"8.大数据相关/flink/1.docker部署flink.html","title":"1.docker部署flink","keywords":"","body":"1.1. docker部署单机flink1.1.1. 拉取镜像flink1.1.2. 创建docker-compose.yml1.1.3. 生成启动1.1.4. 查看日志1.1.5. 查看进程1.1.6. 复制出配置文件1.1.7. 进入容器1.1. docker部署单机flink 1.1.1. 拉取镜像flink docker pull flink 相关端口 The Web Client is on port 8081 JobManager RPC port 6123 TaskManagers RPC port 6122 TaskManagers Data port 6121 1.1.2. 创建docker-compose.yml version: \"2.1\" services: jobmanager: image: flink expose: - \"6123\" ports: - \"8081:8081\" command: jobmanager environment: - JOB_MANAGER_RPC_ADDRESS=jobmanager taskmanager: image: flink expose: - \"6121\" - \"6122\" depends_on: - jobmanager command: taskmanager links: - \"jobmanager:jobmanager\" environment: - JOB_MANAGER_RPC_ADDRESS=jobmanager 1.1.3. 生成启动 cd /opt/flink/ docker-compose build docker-compose up -d --force-recreate docker-compose down docker-compose restart 1.1.4. 查看日志 docker logs --tail=\"500\" flink_jobmanager_1 docker logs -f flink_taskmanager_1 1.1.5. 查看进程 netstat -anltp|grep 8081 1.1.6. 复制出配置文件 docker cp flink_jobmanager_1:/opt/flink/conf/ /opt/flink/conf_bak/ 1.1.7. 进入容器 docker exec -it --user root flink_jobmanager_1 /bin/bash 浏览器上查看页面dashboard http://192.168.0.1:8081 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"8.大数据相关/flink/2.运行时架构.html":{"url":"8.大数据相关/flink/2.运行时架构.html","title":"2.运行时架构","keywords":"","body":"1.1. Flink运行时组件1.1.1. 作业管理器 (JobManager)1.1.2. 任务管理器 (TaskManager)1.1.3. 资源管理器(ResourceManager)1.1.4. 分发器(Dispatcher)1.2. 任务提交流程1.1. Flink运行时组件 1.1.1. 作业管理器 (JobManager) 控制一个应用程序执行的主进程，也就是说，每个应用程序都会被一个不同的 JobManager所控制执行。 JobManager会先接收到要执行的应用程序，这个应用程序会包括：作业图 (JobGraph)、逻辑数据流图(logical dataflow graph)和打包了所有的类、 库和其它资源的AR包。 JobManager会把JobGraph转换成一个物理层面的数据流图，这个图被叫做\"执 行图”(ExecutionGraph),包含了所有可以并发执行的任务。 JobManager会向资源管理器(ResourceManager)请求执行任务必要的资源， 也就是任务管理器(TaskManager)上的插槽(slot)。一旦它获取到了足够的 资源，就会将执行图分发到真正运行它们的TaskManager.上。而在运行过程中， JobManagera会负责所有需要中央协调的操作，比如说检查点(checkpoints)的 协调。 1.1.2. 任务管理器 (TaskManager) Flink中的工作进程。通常在Flink中会有多个TaskManageri运行，每一个 TaskManager都包含了一定数量的插槽(slots)。插槽的数量限制了 TaskManager能够执行的任务数量。 启动之后，TaskManager会向资源管理器注册它的插槽；收到资源管理 器的指令后，TaskManager就会将一个或者多个插槽提供给 JobManager调用。JobManager就可以向插槽分配任务(tasks)来执 行了。 在执行过程中，一个TaskManageri可以跟其它运行同一应用程序的 TaskManager交换数据。 1.1.3. 资源管理器(ResourceManager) 主要负责管理任务管理器 (TaskManager）的插槽(slot), TaskManger插槽是Flink中定义的处理资源单元。 FIik为不同的环境和资源管理工具提供了不同资源管理器，比如YARN Mesos、K8s,以及standalone部署。 当JobManager申请插槽资源时，ResourceManager会将有空闲插槽的 TaskManager分配给JobManager。如果ResourceManager没有足够的 插槽来满足JobManager的请求，它还可以向资源提供平台发起会话， 以提供启动TaskManageri进程的容器。 1.1.4. 分发器(Dispatcher) 可以跨作业运行，它为应用提交提供了REST接口。 当一个应用被提交执行时，分发器就会启动并将应用移交给一个 JobManager。 Dispatchert也会启动一个Web Ul,用来方便地展示和监控作业执 行的信息。 Dispatcher在架构中可能并不是必需的，这取决于应用提交运行 的方式。 1.2. 任务提交流程 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"8.大数据相关/hive/hive基础.html":{"url":"8.大数据相关/hive/hive基础.html","title":"hive基础","keywords":"","body":"1.1. hive概念1.1.1. hive架构1.1.2. hive 和 hadoop的关系1.1.3. hive和普通关系型数据库的区别1.1.4. hive元数据库1.1. hive概念 Hive 是建立在 Hadoop 上的数据仓库基础构架。它提供了一系列的工具，可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在 Hadoop 中的大规模数据的机制。Hive 定义了简单的类 SQL 查询语言，称为 QL，它允许熟悉 SQL 的用户查询数据。同时，这个语言也允许熟悉 MapReduce 开发者的开发自定义的 mapper 和 reducer 来处理内建的 mapper 和 reducer 无法完成的复杂的分析工作。 1.1.1. hive架构 Hive 的结构可以分为以下几部分： 用户接口：包括 CLI, Client, WUI 元数据存储。通常是存储在关系数据库如 mysql, derby 中 解释器、编译器、优化器、执行器 Hadoop：用 HDFS 进行存储，利用MapReduce 进行计算 用户接口主要有三个：CLI，Client和 WUI。其中最常用的是 CLI，Cli 启动的时候，会同时启动一个 Hive 副本。Client 是 Hive 的客户端，用户连接至 Hive Server。在启动 Client 模式的时候，需要指出 Hive Server 所在节点，并且在该节点启动 Hive Server。 WUI 是通过浏览器访问 Hive。 Hive 将元数据存储在数据库中，如 mysql、derby。Hive 中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。 解释器、编译器、优化器完成 HQL 查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在 HDFS 中，并在随后有 MapReduce 调用执行。 Hive 的数据存储在 HDFS 中，大部分的查询由 MapReduce 完成（包含 的查询，比如 select from tbl 不会生成 MapRedcue 任务）。 1.1.2. hive 和 hadoop的关系 Hive构建在 Hadoop 之上， HQL 中对查询语句的解释、优化、生成查询计划是由 Hive 完成的 所有的数据都是存储在 Hadoop 中 查询计划被转化为 MapReduce 任务，在 Hadoop 中执行（有些查询没有 MR 任务，如：select * from table） Hadoop和Hive都是用UTF-8编码的 1.1.3. hive和普通关系型数据库的区别 查询语言。由于 SQL 被广泛的应用在数据仓库中，因此，专门针对 Hive 的特性设计了类 SQL 的查询语言 HQL。熟悉 SQL 开发的开发者可以很方便的使用 Hive 进行开发。 数据存储位置。Hive 是建立在Hadoop 之上的，所有 Hive 的数据都是存储在HDFS 中的。而数据库则可以将数据保存在块设备或者本地文件系统中。 数据格式。Hive 中没有定义专门的数据格式，数据格式可以由用户指定，用户定义数据格式需要指定三个属性：列分隔符（通常为空格、\"\\t\"、\"\\x001″）、行分隔符（\"\\n\"）以及读取文件数据的方法（Hive 中默认有三个文件格式 TextFile，SequenceFile 以及 RCFile）。由于在加载数据的过程中，不需要从用户数据格式到 Hive 定义的数据格式的转换，因此，Hive 在加载的过程中不会对数据本身进行任何修改，而只是将数据内容复制或者移动到相应的 HDFS 目录中。而在数据库中，不同的数据库有不同的存储引擎，定义了自己的数据格式。所有数据都会按照一定的组织存储，因此，数据库加载数据的过程会比较耗时。 数据更新。由于 Hive 是针对数据仓库应用设计的，而数据仓库的内容是读多写少的。因此，Hive 中不支持对数据的改写和添加，所有的数据都是在加载的时候中确定好的。而数据库中的数据通常是需要经常进行修改的，因此可以使用 INSERT INTO … VALUES 添加数据，使用 UPDATE… SET 修改数据。 索引。hive中的索引功能是有限的，hive中没有关系数据库中的建的概念，但是还是可以对某一些字段建立索引。之前已经说过，Hive 在加载数据的过程中不会对数据进行任何处理，甚至不会对数据进行扫描，因此也没有对数据中的某些 Key 建立索引。Hive 要访问数据中满足条件的特定值时，需要暴力扫描整个数据，因此访问延迟较高。由于 MapReduce 的引入， Hive 可以并行访问数据，因此即使没有索引，对于大数据量的访问，Hive 仍然可以体现出优势。数据库中，通常会针对一个或者几个列建立索引，因此对于少量的特定条件的数据的访问，数据库可以有很高的效率，较低的延迟。由于数据的访问延迟较高，决定了Hive 不适合在线数据查询。 执行。Hive 中大多数查询的执行是通过 Hadoop 提供的 MapReduce 来实现的（类似 select * from tbl 的查询不需要 MapReduce）。而数据库通常有自己的执行引擎。 执行延迟。之前提到，Hive 在查询数据的时候，由于没有索引，需要扫描整个表，因此延迟较高。另外一个导致 Hive 执行延迟高的因素是 MapReduce 框架。由于 MapReduce 本身具有较高的延迟，因此在利用 MapReduce 执行 Hive 查询时，也会有较高的延迟。相对的，数据库的执行延迟较低。当然，这个低是有条件的，即数据规模较小，当数据规模大到超过数据库的处理能力的时候，Hive 的并行计算显然能体现出优势。 可扩展性。由于 Hive 是建立在 Hadoop 之上的，因此 Hive 的可扩展性是和 Hadoop 的可扩展性是一致的（世界上最大的 Hadoop 集群在 Yahoo!，2009年的规模在4000 台节点左右）。而数据库由于 ACID 语义的严格限制，扩展行非常有限。目前最先进的并行数据库 Oracle 在理论上的扩展能力也只有 100 台左右。 数据规模。由于 Hive 建立在集群上并可以利用 MapReduce 进行并行计算，因此可以支持很大规模的数据；对应的，数据库可以支持的数据规模较小。 1.1.4. hive元数据库 Hive 将元数据存储在 RDBMS 中,一般常用的有MYSQL和DERBY。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"8.大数据相关/实时数仓/随记1.html":{"url":"8.大数据相关/实时数仓/随记1.html","title":"随记1","keywords":"","body":"随记1.md 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"x.问题总结/多线程使用不当OOM排查.html":{"url":"x.问题总结/多线程使用不当OOM排查.html","title":"多线程使用不当OOM排查","keywords":"","body":"1.1.1. 事故描述1.1.2. 事故根本原因1.1.3. 探寻问题根源1.1.4. 事故核心1.1.1. 事故描述 线上代码出现oom 1.1.2. 事故根本原因 事故代码模拟： public static void test() throws InterruptedException, ExecutionException { Executor executor = Executors.newFixedThreadPool(3); CompletionService service = new ExecutorCompletionService<>(executor); service.submit(new Callable() { @Override public String call() throws Exception { return \"HelloWorld--\" + Thread.currentThread().getName(); } }); } 正确写法 public static void test() throws InterruptedException, ExecutionException { Executor executor = Executors.newFixedThreadPool(3); CompletionService service = new ExecutorCompletionService<>(executor); service.submit(new Callable() { @Override public String call() throws Exception { return \"HelloWorld--\" + Thread.currentThread().getName(); } }); service.take().get(); } 一行代码引发的血案，而且不容易被发现。因为 OOM 是一个内存缓慢增长的过程，稍微粗心大意就会忽略。如果是这个代码块的调用量少的话，很可能几天甚至几个月后暴雷。 操作人回滚或者重启服务器确实是最快的方式。但是如果不是事后快速分析出 OOM 的代码，而且不巧回滚的版本也是带 OOM 代码的，就比较悲催了。如刚才所说，流量小了、回滚或者重启都可以释放内存；但是流量大的情况下，除非回滚到正常的版本，否则 GG。 1.1.3. 探寻问题根源 为了更好的理解 ExecutorCompletionService 的 “套路”，我们用 ExecutorService 来作为对比，可以让我们更好地清楚什么场景下用 ExecutorCompletionService。 先看 ExecutorService 代码 public static void test1() throws Exception{ ExecutorService executorService = Executors.newCachedThreadPool(); ArrayList> futureArrayList = new ArrayList<>(); System.out.println(\"公司让你通知大家聚餐 你开车去接人\"); Future future10 = executorService.submit(() -> { System.out.println(\"总裁：我在家上大号 我最近拉肚子比较慢 要蹲1个小时才能出来 你等会来接我吧\"); TimeUnit.SECONDS.sleep(10); System.out.println(\"总裁：1小时了 我上完大号了。你来接吧\"); return \"总裁上完大号了\"; }); futureArrayList.add(future10); Future future3 = executorService.submit(() -> { System.out.println(\"研发：我在家上大号 我比较快 要蹲3分钟就可以出来 你等会来接我吧\"); TimeUnit.SECONDS.sleep(3); System.out.println(\"研发：3分钟 我上完大号了。你来接吧\"); return \"研发上完大号了\"; }); futureArrayList.add(future3); Future future6 = executorService.submit(() -> { System.out.println(\"中层管理：我在家上大号 要蹲10分钟就可以出来 你等会来接我吧\"); TimeUnit.SECONDS.sleep(6); System.out.println(\"中层管理：10分钟 我上完大号了。你来接吧\"); return \"中层管理上完大号了\"; }); futureArrayList.add(future6); TimeUnit.SECONDS.sleep(1); System.out.println(\"都通知完了,等着接吧。\"); try { for (Future future : futureArrayList) { String returnStr = future.get(); System.out.println(returnStr + \"，你去接他\"); } Thread.currentThread().join(); } catch (Exception e) { e.printStackTrace(); } } 三个任务，每个任务执行时间分别是 10s、3s、6s 。通过 JDK 线程池的 submit 提交这三个 Callable 类型的任务。 第一步：主线程把三个任务提交到线程池里面去，把对应返回的 Future 放到 List 里面存起来，然后执行“都通知完了,等着接吧。”这行输出语句； 第二步：在循环里面执行 future.get() 操作，阻塞等待。 最后结果如下： 公司让你通知大家聚餐 你开车去接人 总裁：我在家上大号 我最近拉肚子比较慢 要蹲1个小时才能出来 你等会来接我吧 研发：我在家上大号 我比较快 要蹲3分钟就可以出来 你等会来接我吧 中层管理：我在家上大号 要蹲10分钟就可以出来 你等会来接我吧 都通知完了,等着接吧。 研发：3分钟 我上完大号了。你来接吧 中层管理：10分钟 我上完大号了。你来接吧 总裁：1小时了 我上完大号了。你来接吧 总裁上完大号了，你去接他 研发上完大号了，你去接他 中层管理上完大号了，你去接他 先通知到总裁，也是先接总裁 足足等了 1 个小时，接到总裁后再去接研发和中层管理，尽管他们早就完事儿了，也得等总裁上完厕所~~ 耗时最久的-10s 异步任务最先进入 list 执行。所以在循环过程中获取这个 10 s的任务结果的时候，get 操作会一直阻塞，直到 10s 异步任务执行完毕。即使 3s、5s 的任务早就执行完了也得阻塞，等待 10s 任务执行完。 看到这里，尤其是做网关业务的同学可能会产生共鸣。一般来说，网关 RPC 会调用下游 N 多个接口，如下图： 如果都按照 ExecutorService 这种方式，并且恰巧前几个任务调用的接口耗时比较久，同时阻塞等待，那就比较悲催了。所以 ExecutorCompletionService 应景而出。它作为任务线程的合理管控者，“任务规划师”的称号名副其实。 相同场景 ExecutorCompletionService 代码： public static void test2() throws Exception { ExecutorService executorService = Executors.newCachedThreadPool(); ExecutorCompletionService completionService = new ExecutorCompletionService<>(executorService); System.out.println(\"公司让你通知大家聚餐 你开车去接人\"); completionService.submit(() -> { System.out.println(\"总裁：我在家上大号 我最近拉肚子比较慢 要蹲1个小时才能出来 你等会来接我吧\"); TimeUnit.SECONDS.sleep(10); System.out.println(\"总裁：1小时了 我上完大号了。你来接吧\"); return \"总裁上完大号了\"; }); completionService.submit(() -> { System.out.println(\"研发：我在家上大号 我比较快 要蹲3分钟就可以出来 你等会来接我吧\"); TimeUnit.SECONDS.sleep(3); System.out.println(\"研发：3分钟 我上完大号了。你来接吧\"); return \"研发上完大号了\"; }); completionService.submit(() -> { System.out.println(\"中层管理：我在家上大号 要蹲10分钟就可以出来 你等会来接我吧\"); TimeUnit.SECONDS.sleep(6); System.out.println(\"中层管理：10分钟 我上完大号了。你来接吧\"); return \"中层管理上完大号了\"; }); TimeUnit.SECONDS.sleep(1); System.out.println(\"都通知完了,等着接吧。\"); //提交了3个异步任务） for (int i = 0; i 结果如下： 公司让你通知大家聚餐 你开车去接人 总裁：我在家上大号 我最近拉肚子比较慢 要蹲1个小时才能出来 你等会来接我吧 研发：我在家上大号 我比较快 要蹲3分钟就可以出来 你等会来接我吧 中层管理：我在家上大号 要蹲10分钟就可以出来 你等会来接我吧 都通知完了,等着接吧。 研发：3分钟 我上完大号了。你来接吧 研发上完大号了，你去接他 中层管理：10分钟 我上完大号了。你来接吧 中层管理上完大号了，你去接他 总裁：1小时了 我上完大号了。你来接吧 总裁上完大号了，你去接他 这次就相对高效了一些。虽然先通知的总裁，但是根据大家上大号的速度，谁先拉完先去接谁，不用等待上大号最久的总裁了（现实生活里建议采用第一种，不等总裁的后果 emmm 哈哈哈）。 两段代码的差异非常小 获取结果的时候 ExecutorCompletionService 使用了： completionService.take().get(); 为什么要用 take() 然后再 get() 呢？ 我们看看源码： ExecutorCompletionService 构造过程中会构建一个阻塞队列 this.completionQueue = new LinkedBlockingQueue>(); public Future submit(Runnable task, V result) { if (task == null) throw new NullPointerException(); RunnableFuture f = newTaskFor(task, result); executor.execute(new QueueingFuture(f)); return f; } QueueingFuture。到底作用是啥，我们继续跟进去看： QueueingFuture 继承自 FutureTask，而且红线部分标注的位置，重写了 done() 方法； 把 task 放到 completionQueue 队列里面。当任务执行完成后，task 就会被放到队列里面去了； 此时此刻，completionQueue 队列里面的 task 都是已经 done() 完成了的 task。而这个 task 就是我们拿到的一个个的 future 结果； 如果调用 completionQueue 的 task 方法，会阻塞等待任务。等到的一定是完成了的 future，我们调用 .get() 方法 就能立马获得结果。 看到这里，相信大家伙都应该多少明白点了： 我们在使用 ExecutorService submit 提交任务后需要关注每个任务返回的 future。然而 CompletionService 对这些 future 进行了追踪，并且重写了 done 方法，让你等的 completionQueue 队列里面一定是完成了的 task； 作为网关 RPC 层，我们不用因为某一个接口的响应慢拖累所有的请求，可以在处理最快响应的业务场景里使用 CompletionService。 1.1.4. 事故核心 只有调用了 ExecutorCompletionService 下面的 3 个方法的任意一个时，阻塞队列中的 task 执行结果才会从队列中移除掉，释放堆内存。 由于该业务不需要使用任务的返回值，没有调用 take、poll 方法，从而导致没有释放堆内存。堆内存会随着调用量的增加一直增长。 所以，业务场景中不需要使用任务返回值的，别没事儿使用 CompletionService。假如使用了，记得一定要从阻塞队列中移除掉 task 执行结果，避免 OOM！ 上线前 严格的代码 review 习惯，一定要交给 back 人去看，毕竟自己写的代码自己是看不出问题的，相信每个程序猿都有这个自信； 上线记录：备注好上一个可回滚的包版本（给自己留一个后路）； 上线前确认回滚后，业务是否可降级。如果不可降级，一定要严格拉长这次上线的监控周期。 上线后 持续关注内存增长情况（这部分极容易被忽略，大家对内存的重视度不如 CPU 使用率）； 持续关注 CPU 使用率增长情况 GC 情况、线程数是否增长、是否有频繁的 Full GC 等； 关注服务性能报警，TP99、999 、MAX 是否出现明显的增高。 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "},"x.问题总结/父子线程公用线程池线上事故.html":{"url":"x.问题总结/父子线程公用线程池线上事故.html","title":"父子线程公用线程池线上事故","keywords":"","body":"1.1.1. 现象1.1.2. 原因1.1.3. 场景复现1.1.4. 解决方案1.1.5. 需要注意点1.1.6. qps为什么激增后才出现问题？1.1.7. 接口上线的时候压测为什么没有出现问题？1.1.1. 现象 算法并发调用线上接口，qps飙升达到平时的千倍，接口耗时增加维持在1000ms左右，并且qps下降后，接口耗时还是1000ms没有得到恢复，机器的cpu，内存等指标都正常 1.1.2. 原因 父子线程共用线程池，线程数被全占用，子线程get()方法没有设置超时时间，导致子线程拿不到线程，一直阻塞，等待线程释放，而父线程get()方法超时时间为1000ms，超时后，虽然抛出异常，但是其实线程还在阻塞等待子线程结果 1.1.3. 场景复现 首先创建一个仅包含一个核心线程的线程池 private static final ExecutorService common = new ThreadPoolExecutor(1, 1, 10, TimeUnit.MILLISECONDS, new LinkedBlockingQueue<>(),new ThreadFactory() { private AtomicInteger threadId = new AtomicInteger(1); @Override public Thread newThread(Runnable r) { return new Thread(r, \"common-\" + threadId.getAndIncrement()); } }); 调用父线程，设置超时时间 public static void main(String[] args) { try { CompletableFuture completableFuture = CompletableFuture.supplyAsync(()-> { Father(); return null; },common); completableFuture.get(); // completableFuture.get(1000,TimeUnit.MILLISECONDS); }catch (Exception e){ System.out.println(\"father 超时\"); } common.execute(()-> System.out.println(\"线程池恢复\")); } 调用子线程，不设置超时时间 private static void Father(){ try { System.out.println(\"Father start\"); CompletableFuture completableFuture = CompletableFuture.supplyAsync(()-> { Son(); return null; },common); completableFuture.get(); }catch (Exception e){ System.out.println(\"子超时\"); } System.out.println(\"Father end\"); } private static void Son() { System.out.println(\"Son start\"); } 结果： Father start father 超时 可以看到father超时后，线程并没有释放，还在等待子线程结束，但是由于父线程不释放，子线程又无法执行，形成死循环 后续进来的请求，都会超时，无法恢复，只能重启服务，这就解释了为什么流量下降后接口耗时还是1000ms 调用子线程，打开超时时间 private static void Father(){ try { System.out.println(\"Father start\"); CompletableFuture completableFuture = CompletableFuture.supplyAsync(()-> { Son(); return null; },common); completableFuture.get(); }catch (Exception e){ System.out.println(\"子超时\"); } System.out.println(\"Father end\"); } private static void Son() { System.out.println(\"Son start\"); } 结果： Father start father 超时 子超时 Father end Son start 活动线程 可以看到，子线程加上超时时间后，超时后父线程可以执行后续逻辑直到线程释放，这个时候子线程会继续执行自己的逻辑，线程池可以自愈，资源可以得到释放 1.1.4. 解决方案 线程池资源隔离 子线程get()方法设置超时时间 尽量不要使用嵌套线程 1.1.5. 需要注意点 虽然对get()方法设置超时时间，但是线程仍然不会释放，会继续执行自己的逻辑，所以get方法虽然抛出超时异常，如果线程池线程数用尽，别的线程仍旧拿不到线程，需要等待超时线程执行结束 1.1.6. qps为什么激增后才出现问题？ qps低的时候，核心线程数并没有打满，就算打满别的线程释放也可以很快结束死循环，aps高的情况下很快核心线程全部都被父线程所持有，全部被阻塞，导致出现一系列问题 1.1.7. 接口上线的时候压测为什么没有出现问题？ 接口上线的时候压测并没有子线程的逻辑，子线程逻辑为后续添加，并且疏忽大意没有给get()超时时间 使用知识共享 署名-相同方式共享 4.0协议发布            updated 2022-07-18 15:10:06 "}}